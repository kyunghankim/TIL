```python
# Beautifulsoup
from bs4 import BeautifulSoup
```


```python
html="""                 
<html><body>
<h1>스크래핑</h1>
<p>웹 페이지 분석</p>
<p>원하는 부분 추출</p>
</body> </html>
"""                                 
# html 을 만들어 주고 분석함
soup=BeautifulSoup(html,'html.parser')          # <- BeautifulSoup 객체를 만듬
#html 문서 분석  
p1=soup.html.body.p               # 가장 먼저 만나는 p태그가 나옴(2번째 안나옴)
#보통 형제 태그라고 부름
print(p1.next_sibling)      # <- next sibling을 하면 p태그 오른쪽에 enter를 참조
print(p1.next_sibling.next_sibling) 
h1=soup.html.body.h1
p1=p1.next_sibling
p2=p1.next_sibling.next_sibling
h1.string
p1.string
p2.string
```

    
    
    <p>원하는 부분 추출</p>
    




    '\n'




```python
#find함수 : id를 이용하여 직접 접근
# id란 특정 텍스트, 특저 영역을 구분하기 위한 목적으로 id를 부여함
```


```python
html="""                 
<html><body>
<h1 id="title">스크래핑</h1>
<p id="body">웹 페이지 분석</p>
<p>원하는 부분 추출</p>
</body> </html>
"""                     
```


```python
soup=BeautifulSoup(html,'html.parser') 
print(soup.find(id="title"))
title=soup.find(id="title")
body=soup.find(id="body")
print("title="+title.string)
print("body="+body.string)
```

    <h1 id="title">스크래핑</h1>
    title=스크래핑
    body=웹 페이지 분석
    


```python
# find_all(): # 여러개의 태그를 한번에 추출
html="""
<html><body>
<ul>
<li><a href="http://www.naver.com">naver</a></li>   
<li><a href="http://www.daum.com">daum</a></li>
</ul>
</body></html>
"""
# a 태그는 이 링크를 실행해서 사이트로 가게 됨(파이참 실행시)
# ul 태그를 쓰면 순서 없이 앞에 점으로 나열하게 됨
# 반대로 ol면 (ordered list)라 숫자로 순서 생김 
# href= hyper referrence 약자
# a태그는 annchor의 의미(고저이키기 위해 닻을 내림)
```


```python
soup=BeautifulSoup(html, "html.parser")
links=soup.find_all("a")                      # a태그를 전부 검색
for a in links:
#    if 'href' in a.attrs:            <- a.attrs에 href가 있으면 이라는 의미
    href=a.attrs['href']                 # attribute로 href를 입력
    text=a.string
    print(text,"->",href)
    #print(href)
soup
```

    naver -> http://www.naver.com
    daum -> http://www.daum.com
    




    
    <html><body>
    <ul>
    <li><a href="http://www.naver.com">naver</a></li>
    <li><a href="http://www.daum.com">daum</a></li>
    </ul>
    </body></html>




```python
#기상청 기상예보에서 특정 내용을 추출
```


```python
import urllib.request as req
```


```python
url="https://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp"
```


```python
res=req.urlopen(url)
res
soup=BeautifulSoup(res,'html.parser')  
#title 검색
print(soup.title.string )       # <- 태그를 통해서 title을 바로 뽑아도 됨(유일하다면)
print(soup.find("title"))       # find에서 바로 title 치고 들어가도 됨 
soup.wf
soup.find("wf").string
# 오후 숙제: 영문, 숫자 등 특수문자 모두 제거(한글 제외)

```

    기상청 육상 중기예보
    <title>기상청 육상 중기예보</title>
    




    '기압골의 영향으로 6일부터 8일 사이에 전국에 비 또는 눈이 오겠고, 제주도는 10~11일에도 비가 오겠습니다. <br />한편, 동풍의 영향으로 9일은 강원영동에 비 또는 눈이 오겠습니다. 그 밖의 날은 고기압의 가장자리에 들어 가끔 구름많겠습니다.<br />기온은 평년(최저기온: -12~0℃, 최고기온: 0~8℃)보다 높겠습니다.<br />강수량은 평년(0~3mm)보다 많겠습니다.'




```python
# css 선택자(크롬->개발자도구->객체선택->copy selector) 사용하기
#soup.select_one(선택지): 선택자로 지정된 요소 하나를 추출
#soup.select(선택지): 선택자로 지정된 여러개의 요소를 추출
```


```python
html="""
<html>
     <body>
         <div id="myid">
             <h1>2020년</h1>
             <ul class='day'>
                 <li>월요일<li>
                 <li>화요일<li>
                 <li>수요일<li> 
              </ul>
         </div>
     </body>
</html>
"""
```


```python
soup=BeautifulSoup(html,'html.parser')
print(soup.select_one("h1"))    #중복이 안되면 바로 나오는데 다른게 있으면 div#myid
print(soup.select_one("div#myid h1"))  #태그를 지정할 때 띄어쓰기 후 h1
print(soup.select_one("div#myid > h1"))  # > 로도 사용 가능 
print(soup.select_one("div#myid h1").string) 
print(soup.select_one("div#myid >ul")) 
print(soup.select_one("div#myid >ul.day"))  #class속성으로도 구분 함
print(soup.select("div#myid >ul.day>li"))
```

    <h1>2020년</h1>
    <h1>2020년</h1>
    <h1>2020년</h1>
    2020년
    <ul class="day">
    <li>월요일<li>
    <li>화요일<li>
    <li>수요일<li>
    </li></li></li></li></li></li></ul>
    <ul class="day">
    <li>월요일<li>
    <li>화요일<li>
    <li>수요일<li>
    </li></li></li></li></li></li></ul>
    [<li>월요일<li>
    <li>화요일<li>
    <li>수요일<li>
    </li></li></li></li></li></li>]
    


```python
#print(soup.select("div#myid > ul.day > li"))
mylist=soup.select("div#myid > ul.day > li")
for a in mylist:
    print(a.string)
print(mylist)
```

    None
    [<li>월요일<li>
    <li>화요일<li>
    <li>수요일<li>
    </li></li></li></li></li></li>]
    


```python
# yahoo finance
```


```python
yhf="https://finance.yahoo.com/quote/005930.KS?p=005930.KS&.tsrc=fin-srch"
res=req.urlopen(yhf)
res
soup=BeautifulSoup(res,'html.parser') 
a=soup.select_one('#quote-header-info')  
print(a)
#quote-header-info > div.My\(6px\).Pos\(r\).smartphone_Mt\(6px\) > div > div > span.Trsdu\(0\.3s\).Fw\(b\).Fz\(36px\).Mb\(-4px\).D\(ib\)
```

    <div class="quote-header-section Cf Pos(r) Mb(5px) Maw($maxModuleWidth) Miw($minGridWidth) smartphone_Miw(ini) Miw(ini)!--tab768 Miw(ini)!--tab1024 Mstart(a) Mend(a) Px(20px) smartphone_Pb(0px) smartphone_Mb(0px)" data-reactid="2" data-test="quote-header" data-yaft-module="tdv2-applet-QuoteHeader" id="quote-header-info"><div class="W(100%) Bdts(s) Bdtw(7px) Bdtc($negativeColor)" data-reactid="3"></div><div class="Mt(15px)" data-reactid="4"><div class="D(ib) Mt(-5px) Mend(20px) Maw(56%)--tab768 Maw(52%) Ov(h) smartphone_Maw(85%) smartphone_Mend(0px)" data-reactid="5"><div class="D(ib) Mb(2px)" data-reactid="6"><h1 class="D(ib) Fz(16px) Lh(18px)" data-reactid="7">005930.KS - Samsung Electronics Co., Ltd.</h1></div><div class="C($tertiaryColor) Fz(12px)" data-reactid="8"><span data-reactid="9">KSE - KSE Delayed Price. Currency in KRW</span></div></div><div class="D(ib) Va(t) Mt(-8px) Mend(15px) smartphone_Mend(0px) smartphone_Fl(end) smartphone_Mt(0px)" data-reactid="10"></div><div class="D(ib) Fl(end) W(300px) Cl(end)--mobxl W(250px)--tab768" data-reactid="11"></div></div><div class="My(6px) Pos(r) smartphone_Mt(6px)" data-reactid="12"><div class="" data-reactid="13"><span class="Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)" data-reactid="14">55,400.00</span><div class="D(ib) Va(t)" data-reactid="15"><span class="Trsdu(0.3s) Fw(500) Fz(14px) C($dataRed)" data-reactid="16">-400.00 (-0.72%)</span><div class="Fw(n) C($tertiaryColor) Fz(12px) Mstart(10px) D(ib) Mstart(0)--mobpsm Mt(6px)--mobpsm" data-reactid="17" id="quote-market-notice"><span data-reactid="18">As of  12:24PM KST. Market open.</span></div></div></div></div></div>
    


```python
print(soup.select_one("#quote-header-info > div.My\(6px\).Pos\(r\).smartphone_Mt\(6px\) > div > div > span.Trsdu\(0\.3s\).Fw\(b\).Fz\(36px\).Mb\(-4px\).D\(ib\)")) 
```

    None
    


```python
soup.select_one("div > span")  
```




    <span data-reactid="31">No matching results for ''</span>




```python
from bs4 import BeautifulSoup
import urllib.request as req
ydj="https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC"
res=req.urlopen(ydj)
soup=BeautifulSoup(res,'html.parser')
mylist=soup.select("#mw-content-text > div > ul:nth-child(6) > li")
for a in mylist:
    print(a.get_text())
```

    하늘과 바람과 별과 시 (증보판)
    서시
    자화상
    소년
    눈 오는 지도
    돌아와 보는 밤
    병원
    새로운 길
    간판 없는 거리
    태초의 아침
    또 태초의 아침
    새벽이 올 때까지
    무서운 시간
    십자가
    바람이 불어
    슬픈 족속
    눈감고 간다
    또 다른 고향
    길
    별 헤는 밤
    


```python
mylist
```




    [<li><b><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C" title="하늘과 바람과 별과 시">하늘과 바람과 별과 시</a></b> (<a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C_(1955%EB%85%84)" title="하늘과 바람과 별과 시 (1955년)">증보판</a>)
     <ul><li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%84%9C%EC%8B%9C" title="하늘과 바람과 별과 시/서시">서시</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%9E%90%ED%99%94%EC%83%81" title="하늘과 바람과 별과 시/자화상">자화상</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%86%8C%EB%85%84" title="하늘과 바람과 별과 시/소년">소년</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%88%88_%EC%98%A4%EB%8A%94_%EC%A7%80%EB%8F%84" title="하늘과 바람과 별과 시/눈 오는 지도">눈 오는 지도</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%8F%8C%EC%95%84%EC%99%80_%EB%B3%B4%EB%8A%94_%EB%B0%A4" title="하늘과 바람과 별과 시/돌아와 보는 밤">돌아와 보는 밤</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%B3%91%EC%9B%90" title="하늘과 바람과 별과 시/병원">병원</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%83%88%EB%A1%9C%EC%9A%B4_%EA%B8%B8" title="하늘과 바람과 별과 시/새로운 길">새로운 길</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EA%B0%84%ED%8C%90_%EC%97%86%EB%8A%94_%EA%B1%B0%EB%A6%AC" title="하늘과 바람과 별과 시/간판 없는 거리">간판 없는 거리</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%ED%83%9C%EC%B4%88%EC%9D%98_%EC%95%84%EC%B9%A8" title="하늘과 바람과 별과 시/태초의 아침">태초의 아침</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%98%90_%ED%83%9C%EC%B4%88%EC%9D%98_%EC%95%84%EC%B9%A8" title="하늘과 바람과 별과 시/또 태초의 아침">또 태초의 아침</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%83%88%EB%B2%BD%EC%9D%B4_%EC%98%AC_%EB%95%8C%EA%B9%8C%EC%A7%80" title="하늘과 바람과 별과 시/새벽이 올 때까지">새벽이 올 때까지</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%AC%B4%EC%84%9C%EC%9A%B4_%EC%8B%9C%EA%B0%84" title="하늘과 바람과 별과 시/무서운 시간">무서운 시간</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%8B%AD%EC%9E%90%EA%B0%80" title="하늘과 바람과 별과 시/십자가">십자가</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%B0%94%EB%9E%8C%EC%9D%B4_%EB%B6%88%EC%96%B4" title="하늘과 바람과 별과 시/바람이 불어">바람이 불어</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EC%8A%AC%ED%94%88_%EC%A1%B1%EC%86%8D" title="하늘과 바람과 별과 시/슬픈 족속">슬픈 족속</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%88%88%EA%B0%90%EA%B3%A0_%EA%B0%84%EB%8B%A4" title="하늘과 바람과 별과 시/눈감고 간다">눈감고 간다</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%98%90_%EB%8B%A4%EB%A5%B8_%EA%B3%A0%ED%96%A5" title="하늘과 바람과 별과 시/또 다른 고향">또 다른 고향</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EA%B8%B8" title="하늘과 바람과 별과 시/길">길</a></li>
     <li><a href="/wiki/%ED%95%98%EB%8A%98%EA%B3%BC_%EB%B0%94%EB%9E%8C%EA%B3%BC_%EB%B3%84%EA%B3%BC_%EC%8B%9C/%EB%B3%84_%ED%97%A4%EB%8A%94_%EB%B0%A4" title="하늘과 바람과 별과 시/별 헤는 밤">별 헤는 밤</a></li></ul></li>]




```python
mylist=soup.select("#mw-content-text > div > ul:nth-child(6) > li a")
for a in mylist:
    print(a.string)
```

    하늘과 바람과 별과 시
    증보판
    서시
    자화상
    소년
    눈 오는 지도
    돌아와 보는 밤
    병원
    새로운 길
    간판 없는 거리
    태초의 아침
    또 태초의 아침
    새벽이 올 때까지
    무서운 시간
    십자가
    바람이 불어
    슬픈 족속
    눈감고 간다
    또 다른 고향
    길
    별 헤는 밤
    


```python
# 칠판 설명 
# li > a : li태그 내부에 있는 a태그
# li a : 모든 li태그 안에 있는 모든 a 태그
```


```python
html="""
<ul id='language'>
    <li id="bas">Basic</li>
    <li id="cpp">c++</li>
    <li id="ja">Java</li>
    <li id="py">Python</li>
    <li id="sp">Spark</li>    
</ul>
"""
```


```python
sel=BeautifulSoup(html,"html.parser")
print(sel)
print(sel.select_one("#py").string)
```

    
    <ul id="language">
    <li id="bas">Basic</li>
    <li id="cpp">c++</li>
    <li id="ja">Java</li>
    <li id="py">Python</li>
    <li id="sp">Spark</li>
    </ul>
    
    Python
    


```python
myFunc=lambda arg: print(sel.select_one(arg).string)
myFunc("#py")
myFunc("li#py")
myFunc("ul > li#py")
myFunc("#language #py")
myFunc("#language > #py")
myFunc("ul#language > li#py")
myFunc("li[id='py']")
myFunc("li:nth-of-type(4)")          #py가 4번째에 있어서
print(sel.select("li")[3].string)    #[3]까지 하면 <>까지 같이 나와서 .string함
print(sel.find_all("li"))            # <- 리스트로 나옴
print(sel.find_all("li")[3].string) 
```

    Python
    Python
    Python
    Python
    Python
    Python
    Python
    Python
    Python
    [<li id="bas">Basic</li>, <li id="cpp">c++</li>, <li id="ja">Java</li>, <li id="py">Python</li>, <li id="sp">Spark</li>]
    Python
    


```python
fp=open("fru-veg.html", encoding='utf-8')
fp
soup2=BeautifulSoup(fp,'html.parser')
soup2
```




    <!DOCTYPE html>
    
    <html lang="en">
    <head>
    <meta charset="utf-8"/>
    <title>Title</title>
    </head>
    <body>
    <div id="main-goods" role="page">
    <h1>과일과 야채</h1>
    <ul id="fr">
    <li class="red green" data-lo="ko">사과</li>
    <li class="purple" data-lo="us">포도</li>
    <li class="yellow" data-lo="us">레몬</li>
    <li class="yellow" data-lo="ko">오렌지</li>
    </ul>
    <ul id="ve">
    <li class="white green" data-lo="ko">무</li>
    <li class="red green" data-lo="us">파프리카</li>
    <li class="black" data-lo="us">가지</li>
    <li class="black" data-lo="ko">아보카도</li>
    <li class="white" data-lo="cn">연근</li>
    </ul>
    </div>
    </body>
    </html>




```python
#아보카도 추출하기
soup2.select_one("li")    # <- 첫번째 li인 사과가 나옴
soup2.select("li")   # li에 있는거 전부 나옴
#print(soup2.select_one("li:nth-of-type(6)").string)  <- 6번 부터 error뜸
print(soup2.select_one("#ve > li:nth-of-type(4)").string)       #  아보카도 나옴
```

    아보카도
    


```python

```


```python

```


```python

```


```python

```


```python

```
