{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN(Convolutional nueral network,합성곱):\n",
    "이미지에서 특징들을 추출해서 특징값을 input으로 하자!\n",
    "\n",
    "숫자의 사진이 회전이 되더라도 특징은 그대로이기 때문에 특징으로 하는 것 중요\n",
    "\n",
    "ex:          1단계특징                     2단계특징    3단계:분류\n",
    "[고양이사진] -> [동그라미,세모,부드러움,가로] -> 눈코입귀 등 -(조합)-> [고양이]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*위 단계 예:\n",
    "사진-> CNN{ [Convolutional Layer] -특징추출-> Neural Network} -(softmax)-> 고양:x%,개:y%       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*정리:Convolutional Layer란? 입력데이터로부터 특징을 추출하는 역할을 수행하는 계층\n",
    "    -필터: 특징을 추출하는 기능\n",
    "    -활성화 함수(Relu): 필터가 추출한 값을 비선형 값으로 변경해주는 함수\n",
    "*[Convolutional Layer]:[filter1 -> Relu\n",
    "                        filter2 -> Relu\n",
    "                        filter3 -> Relu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*입력:\n",
    "    [사진](64*64) => [Convolution Layer](64*64*10) =>\n",
    "    (있을수도 없을 수도)[Pooling Layer]:크기가 줄어듬(ex: 32*32*x)\n",
    "        =>[Convolution Layer2](32*32*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*Pooling Layer:특징의 대표값을 추출하기 때문에 압축의 효과를 누린다,연산량도 줄어듬\n",
    "    기본형태는 Conv -> Pooling -> Conv : 번갈아가면서 이지만 설계하기, 나름 다를수도 있음,\n",
    "    Pooling할 때 stride(보폭)도 정해줄 수 있고 크기도 정해줄 수 있음,보통 input_data의 크기의\n",
    "    약수로 정해주는 경우가 많지만 꼭 그렇지 않아도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*Pooling Layer(16*16)=(Flatening)=>[0,                       [0,  ->x%\n",
    "                                    1,                        1,  ->y%\n",
    "                                    ...   -Neural Network->  ...          =>출력:n\n",
    "                                    255]                     ,9]  ->z%\n",
    "장점:\n",
    "    1. 크기 감소, 속도 사응\n",
    "    2. 영역 대표적 특징\n",
    "    3. 위치나 각도 등의 변화에 대해 잘 적응하도록 수행하는 작업(여러방향에서 봐도 모델이 잘 작동)\n",
    "종류:\n",
    "    주로 많이쓰는건 Max pooling(그 영역을 대표하는 값을 압축해서 뽑겠다는 의미)\n",
    "    그외 mean pooling 등 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*filter: 어떤 특징이 해당 데이터에 있는지 확인하는 것(ex: 3*3에 있는지)\n",
    "    ex:\n",
    "        [물고기 사진] -filter: 특징1[(0,0,1,1,0,0)과같은] ->\n",
    "        [물고기 사진]의 일부 matrix와 합성곱을 함(특징이 있는 부분은 값이 커지게 됨) ->\n",
    "        sliding window: filter 크기만큼 한 matrix씩 옮겨가면서 합성곱을함->\n",
    "            특징이 있는 경우만 더 부각화 됨 p170~ 책 참조\n",
    "    => filter를 kernel(커널)이라고도 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*padding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*이전 모델에선 wx+b,w:weight b:bias,를 썼었음\n",
    "filter의 값이 w의 역할!, 처음에 filter 값을 random_normal로 주고 update해줌\n",
    ", bias를 마지막에 추가해서 data 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*입력: (4,4), \n",
    "    패딩:1, 스트라이드: 1, filter(3,3)=>\n",
    "출력?\n",
    "    H=(4+2*1-3)/1 +1 = 4 (2는 2*패딩,4는 입력의 x)\n",
    "    w=(4+2*1-3)/1 +1 = 4 (3은 filter의 y)   \n",
    "입력:(7,7)\n",
    "    패딩:0, 스트라이드: 2, filter(3,3)=>\n",
    "    H=(7+2*0-3)/2 +1 = 3\n",
    "    w=(7+2*0-3)/2 +1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*3차원데이터의 합성곱?(RGB)\n",
    "3차원 데이터에 합성곱이므로 filter도 3차원이어야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=np.array([[[[1],[2],[3]],\n",
    "          [[4],[5],[6]],\n",
    "         [[7],[8],[9]]]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 3, 3, 1) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4a91873ad8f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2682\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2683\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2684\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2685\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2686\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5679\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 690\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (1, 3, 3, 1) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image,cmap='Greys')\n",
    "#shape error나오는 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x231cfb3ef88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOLklEQVR4nO3df8ydZX3H8fdnFCpRZquF0ZQikjV2zi0RnyDqYpqpCTaGLpEl+IeC0TQ6yXTRZKgJJibL1D9cZjCSqkRYDJKJ0brUGAQcLguMSgqlNJWWZOFJG0CwRaJTyr7747nZzg7n6fP0Ovdzzim+X8nJuX9c576+XE0+ve5fNFWFJJ2s35t2AZJOTYaHpCaGh6QmhoekJoaHpCaGh6QmY4VHklckuS3Jw9332kXaPZdkT/fZOU6fkmZDxnnOI8kXgKeq6nNJrgHWVtXfjmj3TFW9bIw6Jc2YccPjALClqo4kWQ/8uKpeM6Kd4SG9yIwbHkeras3A+i+q6gWnLkmOA3uA48Dnquq7ixxvO7Ad4KUvfekbNm/e3Fzbi91zzz037RJm3rPPPjvtEmbevn37fl5VZ7f8dtVSDZL8CDh3xK5Pn0Q/51fV4SQXAnck2VtVh4YbVdUOYAfA3Nxc7d69+yS6+N1y9OjRaZcw8x577LFplzDzNm/e/J+tv10yPKrq7YvtS/JYkvUDpy2PL3KMw933I0l+DLweeEF4SDp1jHurdidwZbd8JfC94QZJ1iZZ3S2vA94CPDRmv5KmbNzw+BzwjiQPA+/o1kkyl+RrXZs/AnYnuR+4k4VrHoaHdIpb8rTlRKrqSeBtI7bvBj7YLf878Cfj9CNp9viEqaQmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCa9hEeSS5McSHIwyTUj9q9Ocku3/54kF/TRr6TpGTs8kpwGfBl4J/Ba4D1JXjvU7APAL6rqD4F/AD4/br+SpquPmcfFwMGqeqSqfgt8C9g21GYbcGO3/G3gbUnSQ9+SpqSP8NgAPDqwPt9tG9mmqo4Dx4BX9tC3pCnpIzxGzSCqoQ1JtifZnWT3E0880UNpklZKH+ExD2wcWD8POLxYmySrgJcDTw0fqKp2VNVcVc2dffbZPZQmaaX0ER73ApuSvDrJGcAVwM6hNjuBK7vly4E7quoFMw9Jp45V4x6gqo4nuRr4IXAacENV7UvyWWB3Ve0Evg78U5KDLMw4rhi3X0nTNXZ4AFTVLmDX0LZrB5b/C/jLPvqSNBt8wlRSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSk17CI8mlSQ4kOZjkmhH7r0ryRJI93eeDffQraXpWjXuAJKcBXwbeAcwD9ybZWVUPDTW9paquHrc/SbOhj5nHxcDBqnqkqn4LfAvY1sNxJc2wsWcewAbg0YH1eeCNI9q9O8lbgZ8Bf1NVjw43SLId2A5wzjnncPvtt/dQ3ovTgQMHpl3CzDt06NC0S3hR62PmkRHbamj9+8AFVfWnwI+AG0cdqKp2VNVcVc2tWbOmh9IkrZQ+wmMe2Diwfh5weLBBVT1ZVb/pVr8KvKGHfiVNUR/hcS+wKcmrk5wBXAHsHGyQZP3A6mXA/h76lTRFY1/zqKrjSa4GfgicBtxQVfuSfBbYXVU7gb9OchlwHHgKuGrcfiVNVx8XTKmqXcCuoW3XDix/EvhkH31Jmg0+YSqpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIalJL+GR5IYkjyd5cJH9SfKlJAeTPJDkoj76lTQ9fc08vgFceoL97wQ2dZ/twFd66lfSlPQSHlV1F/DUCZpsA26qBXcDa5Ks76NvSdMxqWseG4BHB9bnu23/T5LtSXYn2X306NEJlSapxaTCIyO21Qs2VO2oqrmqmluzZs0EypLUalLhMQ9sHFg/Dzg8ob4lrYBJhcdO4H3dXZdLgGNVdWRCfUtaAav6OEiSm4EtwLok88BngNMBqup6YBewFTgI/Ap4fx/9SpqeXsKjqt6zxP4CPtJHX5Jmg0+YSmpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIatJLeCS5IcnjSR5cZP+WJMeS7Ok+1/bRr6Tp6eUfuga+AVwH3HSCNj+pqnf11J+kKetl5lFVdwFP9XEsSaeGvmYey/GmJPcDh4FPVNW+4QZJtgPbAc4880yuu+66CZZ3atm7d++0S5h5hw4dmnYJL2qTCo/7gFdV1TNJtgLfBTYNN6qqHcAOgLVr19aEapPUYCJ3W6rq6ap6plveBZyeZN0k+pa0MiYSHknOTZJu+eKu3ycn0bekldHLaUuSm4EtwLok88BngNMBqup64HLgw0mOA78GrqgqT0ukU1gv4VFV71li/3Us3MqV9CLhE6aSmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKajB0eSTYmuTPJ/iT7knx0RJsk+VKSg0keSHLRuP1Kmq4+/qHr48DHq+q+JGcBP01yW1U9NNDmncCm7vNG4Cvdt6RT1Ngzj6o6UlX3dcu/BPYDG4aabQNuqgV3A2uSrB+3b0nT0+s1jyQXAK8H7hnatQF4dGB9nhcGjKRTSB+nLQAkeRlwK/Cxqnp6ePeIn9SIY2wHtgOceeaZfZUmaQX0MvNIcjoLwfHNqvrOiCbzwMaB9fOAw8ONqmpHVc1V1dzq1av7KE3SCunjbkuArwP7q+qLizTbCbyvu+tyCXCsqo6M27ek6enjtOUtwHuBvUn2dNs+BZwPUFXXA7uArcBB4FfA+3voV9IUjR0eVfVvjL6mMdimgI+M25ek2eETppKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKajB0eSTYmuTPJ/iT7knx0RJstSY4l2dN9rh23X0nTtaqHYxwHPl5V9yU5C/hpktuq6qGhdj+pqnf10J+kGTD2zKOqjlTVfd3yL4H9wIZxjytptqWq+jtYcgFwF/C6qnp6YPsW4FZgHjgMfKKq9o34/XZge7f6OuDB3orrxzrg59MuYoD1nNis1QOzV9Nrquqslh/2Fh5JXgb8K/B3VfWdoX2/D/x3VT2TZCvwj1W1aYnj7a6quV6K68ms1WQ9JzZr9cDs1TROPb3cbUlyOgszi28OBwdAVT1dVc90y7uA05Os66NvSdPRx92WAF8H9lfVFxdpc27XjiQXd/0+OW7fkqanj7stbwHeC+xNsqfb9ingfICquh64HPhwkuPAr4EraunzpR091Na3WavJek5s1uqB2aupuZ5eL5hK+t3hE6aSmhgekprMTHgkeUWS25I83H2vXaTdcwOPue9cgTouTXIgycEk14zYvzrJLd3+e7pnW1bUMmq6KskTA+PywRWs5YYkjycZ+QxOFnypq/WBJBetVC0nUdPEXo9Y5usaEx2jFXuFpKpm4gN8AbimW74G+Pwi7Z5ZwRpOAw4BFwJnAPcDrx1q81fA9d3yFcAtKzwuy6npKuC6Cf05vRW4CHhwkf1bgR8AAS4B7pmBmrYA/zKh8VkPXNQtnwX8bMSf10THaJk1nfQYzczMA9gG3Ngt3wj8xRRquBg4WFWPVNVvgW91dQ0arPPbwNuevw09xZompqruAp46QZNtwE214G5gTZL1U65pYmp5r2tMdIyWWdNJm6Xw+IOqOgIL/7HAOYu0e0mS3UnuTtJ3wGwAHh1Yn+eFg/y/barqOHAMeGXPdZxsTQDv7qbA306ycQXrWcpy6520NyW5P8kPkvzxJDrsTmlfD9wztGtqY3SCmuAkx6iP5zyWLcmPgHNH7Pr0SRzm/Ko6nORC4I4ke6vqUD8VMmoGMXwvezlt+rSc/r4P3FxVv0nyIRZmRn++gjWdyKTHZznuA15V//d6xHeBE74eMa7udY1bgY/VwHtez+8e8ZMVH6MlajrpMZrozKOq3l5Vrxvx+R7w2PNTt+778UWOcbj7fgT4MQsp2pd5YPBv7fNYeJFvZJskq4CXs7JT5iVrqqonq+o33epXgTesYD1LWc4YTlRN+PWIpV7XYApjtBKvkMzSactO4Mpu+Urge8MNkqxNsrpbXsfC063D/9+QcdwLbEry6iRnsHBBdPiOzmCdlwN3VHfFaYUsWdPQ+fJlLJzTTstO4H3dHYVLgGPPn45OyyRfj+j6OeHrGkx4jJZTU9MYTeIK9DKvCL8SuB14uPt+Rbd9Dvhat/xmYC8Ldxz2Ah9YgTq2snA1+hDw6W7bZ4HLuuWXAP8MHAT+A7hwAmOzVE1/D+zrxuVOYPMK1nIzcAR4loW/QT8AfAj4ULc/wJe7WvcCcxMYn6VqunpgfO4G3ryCtfwZC6cgDwB7us/WaY7RMms66THy8XRJTWbptEXSKcTwkNTE8JDUxPCQ1MTwkNTE8JDUxPCQ1OR/AFEBEl6VE8t1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# shape=(100 ,5,4,3) -> 100장의 사진, 마지막3은 RGB 칼라색상\n",
    "plt.imshow(image.reshape(3,3),cmap='Greys') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(2, 2, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "weight=tf.constant([[[[1.]],[[1.]]],\n",
    "                  [[[1.]],[[1.]]]])\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "conv2d = tf.nn.conv2d(image,weight,strides=[1,1,1,1],padding='VALID') #<- convolutional 2 demention\n",
    "#strides의 가운데 2개 몇줄만큼 이동하냐 의 변수, 2번째가 좌우, 3번째가 위아래\n",
    "conv2dimage=conv2d.eval() #<- 합성곱 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[12.],\n",
       "         [16.]],\n",
       "\n",
       "        [[24.],\n",
       "         [28.]]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2dimage.shape\n",
    "conv2dimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i , img in enumerate(conv2dimage):\n",
    "    print(img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(img.reshape(2,2),cmap='gray') #<- filter를 적용한 그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = tf.nn.conv2d(image,weight,strides=[1,1,1,1],padding='SAME')\n",
    "conv2dimage=conv2d.eval() #<-padding을 same으로 주어서 원래 크기를 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2dimage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i , img in enumerate(conv2dimage):\n",
    "    print(img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(img.reshape(3,3),cmap='gray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist 데이터 -> CNN 모델\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 퍼러미터: 모델의 성능에 변화를 주는 변수들\n",
    "lr=0.001\n",
    "epochs=15\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력층\n",
    "keep_prob=tf.placeholder(tf.float32) #<- 새로 추가됨\n",
    "x = tf.placeholder(tf.float32,[None,28*28])\n",
    "ximg = tf.reshape(x,[-1,28,28,1]) #<- -1의 의미는 None, tensorflow에선 None이라고 함,\n",
    "#-1도 None과 같은 의미로 쓰이는데 numpy에서 그렇게쓰임. 결과적으론 같은의미가 됨\n",
    "#2차원 구조를 4차원구조로 바꾸어줌\n",
    "y = tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32,[None,28*28])\n",
    "ximg = tf.reshape(x,[-1,28,28,1]) #<- -1의 의미는 None, tensorflow에선 None이라고 함,\n",
    "#-1도 None과 같은 의미로 쓰이는데 numpy에서 그렇게쓰임. 결과적으론 같은의미가 됨\n",
    "#2차원 구조를 4차원구조로 바꾸어줌\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#Hidden layer1: weight1=filter\n",
    "w1 = tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01)) #<-RBB channel이 아니기 때문에 1\n",
    "# (3,3)은 높이와 너비, 1은 채널의 개수, 32는 filter의 개수: 32개의 특징을 찾겠다\n",
    "#conv -> (?,28,28,32)\n",
    "# relu -> (?,28,28,32)\n",
    "#pool ->  (?,14,14,32)\n",
    "l1 = tf.nn.conv2d(ximg,w1,strides=[1,1,1,1],padding='SAME')\n",
    "l1 = tf.nn.relu(l1)\n",
    "l1=tf.nn.max_pool(l1,\n",
    "               ksize=[1,2,2,1],\n",
    "               strides=[1,2,2,1],padding='SAME') #<-(2,2): window의 크기가 (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 cost 0.38254\n",
      "epoch: 0002 cost 0.10074\n",
      "epoch: 0003 cost 0.07071\n",
      "epoch: 0004 cost 0.05589\n",
      "epoch: 0005 cost 0.04723\n",
      "epoch: 0006 cost 0.03914\n",
      "epoch: 0007 cost 0.03415\n",
      "epoch: 0008 cost 0.03003\n",
      "epoch: 0009 cost 0.02592\n",
      "epoch: 0010 cost 0.02378\n",
      "epoch: 0011 cost 0.02046\n",
      "epoch: 0012 cost 0.01857\n",
      "epoch: 0013 cost 0.01623\n",
      "epoch: 0014 cost 0.01455\n",
      "epoch: 0015 cost 0.01308\n",
      "accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32,[None,28*28])\n",
    "ximg = tf.reshape(x,[-1,28,28,1]) #<- -1의 의미는 None, tensorflow에선 None이라고 함,\n",
    "#-1도 None과 같은 의미로 쓰이는데 numpy에서 그렇게쓰임. 결과적으론 같은의미가 됨\n",
    "#2차원 구조를 4차원구조로 바꾸어줌\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#Hidden layer1: weight1=filter\n",
    "w1 = tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01)) #<-RBB channel이 아니기 때문에 1\n",
    "# (3,3)은 높이와 너비, 1은 채널의 개수, 32는 filter의 개수: 32개의 특징을 찾겠다\n",
    "#conv -> (?,28,28,32)\n",
    "# relu -> (?,28,28,32)\n",
    "#pool ->  (?,14,14,32)\n",
    "l1 = tf.nn.conv2d(ximg,w1,strides=[1,1,1,1],padding='SAME')\n",
    "l1 = tf.nn.relu(l1)\n",
    "l1=tf.nn.max_pool(l1,\n",
    "               ksize=[1,2,2,1],\n",
    "               strides=[1,2,2,1],padding='SAME') #<-(2,2): window의 크기가 (2,2)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))\n",
    "#conv -> (?,14,14,64)\n",
    "#relu -> (?,14,14,32)\n",
    "#pool ->  (?,7,7,32)\n",
    "#flat ->  (?,3136)\n",
    "l2= tf.nn.conv2d(l1,w2,strides=[1,1,1,1],padding='SAME')\n",
    "l2 = tf.nn.relu(l2)\n",
    "l2 = tf.nn.max_pool(l2,\n",
    "               ksize=[1,2,2,1],\n",
    "               strides=[1,2,2,1],padding='SAME') #<-(2,2): window의 크기가 (2,2)\n",
    "l2_flat = tf.reshape(l2,[-1,7*7*64]) #<- flatten함수도 있지만 reshape으로 해도 됨\n",
    "\n",
    "#마지막계층 FC 7*7*64 -> 10 output\n",
    "w3 = tf.get_variable(\"w3\",shape=[7*7*64,10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "#이 과정 그림으로 꼭 그려보기\n",
    "b=tf.Variable(tf.random_normal([10]))\n",
    "hf=tf.matmul(l2_flat,w3)+b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y))\n",
    "opt=tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avgCost = 0\n",
    "    totalBatch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(totalBatch): #<-한번 돌 때 마다 1 epoch수행됨\n",
    "        batchX,batchY = mnist.train.next_batch(batch_size) #<-batch_size만큼 data를 가져옴\n",
    "        fd={x:batchX,y:batchY}\n",
    "        cv,_=sess.run([cost,opt],feed_dict=fd)\n",
    "        avgCost+=cv/totalBatch\n",
    "    print(\"epoch:\",\"%04d\" %(epoch+1),\"cost\",\"{:.5f}\".format(avgCost))\n",
    "pred=tf.equal(tf.argmax(hf,1),tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "print(\"accuracy:\",sess.run(acc,\n",
    "                           feed_dict={x:mnist.test.images,y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"sub_2:0\", dtype=float32) must be from the same graph as Tensor(\"dropout/random_uniform:0\", shape=(?, 14, 14, 32), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-ddcf962be863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                strides=[1,2,2,1],padding='SAME') #<-(2,2): window의 크기가 (2,2)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(x, keep_prob, noise_shape, seed, name, rate)\u001b[0m\n\u001b[0;32m   4227\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You must provide a rate to dropout.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4229\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdropout_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mdropout_v2\u001b[1;34m(x, rate, noise_shape, seed, name)\u001b[0m\n\u001b[0;32m   4311\u001b[0m     \u001b[1;31m# NOTE: if (1.0 + rate) - 1 is equal to rate, then we want to consider that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4312\u001b[0m     \u001b[1;31m# float to be selected, hence we use a >= comparison.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4313\u001b[1;33m     \u001b[0mkeep_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_tensor\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4314\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mgreater_equal\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   4479\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4480\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 4481\u001b[1;33m         \"GreaterEqual\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   4482\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4483\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    365\u001b[0m       \u001b[1;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   5977\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5978\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5979\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5980\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5981\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   5912\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5913\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001b[1;32m-> 5914\u001b[1;33m                      (item, original_item))\n\u001b[0m\u001b[0;32m   5915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"sub_2:0\", dtype=float32) must be from the same graph as Tensor(\"dropout/random_uniform:0\", shape=(?, 14, 14, 32), dtype=float32)."
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32,[None,28*28])\n",
    "ximg = tf.reshape(x,[-1,28,28,1]) #<- -1의 의미는 None, tensorflow에선 None이라고 함,\n",
    "\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#Hidden layer1: weight1=filter\n",
    "w1 = tf.Variable(tf.random_normal([3,3,1,32],stddev=0.01)) #<-RBB channel이 아니기 때문에 1\n",
    "\n",
    "l1 = tf.nn.conv2d(ximg,w1,strides=[1,1,1,1],padding='SAME')\n",
    "l1 = tf.nn.relu(l1)\n",
    "l1=tf.nn.max_pool(l1,\n",
    "               ksize=[1,2,2,1],\n",
    "               strides=[1,2,2,1],padding='SAME') #<-(2,2): window의 크기가 (2,2)\n",
    "l1 = tf.nn.dropout(l1,keep_prob=keep_prob)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([3,3,32,64],stddev=0.01))\n",
    "\n",
    "l2= tf.nn.conv2d(l1,w2,strides=[1,1,1,1],padding='SAME')\n",
    "l2 = tf.nn.relu(l2)\n",
    "l2 = tf.nn.max_pool(l2,\n",
    "               ksize=[1,2,2,1],\n",
    "               strides=[1,2,2,1],padding='SAME') #<-(2,2): window의 크기가 (2,2)\n",
    "l2 = tf.nn.dropout(l2,keep_prob=keep_prob)\n",
    "l2_flat = tf.reshape(l2,[-1,7*7*64]) #<- flatten함수도 있지만 reshape으로 해도 됨\n",
    "\n",
    "w3 = tf.get_variable(\"w3\",shape=[7*7*64,10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "b=tf.Variable(tf.random_normal([10]))\n",
    "hf=tf.matmul(l2_flat,w3)+b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hf, labels=y))\n",
    "opt=tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avgCost = 0\n",
    "    totalBatch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(totalBatch): #<-한번 돌 때 마다 1 epoch수행됨\n",
    "        batchX,batchY = mnist.train.next_batch(batch_size) #<-batch_size만큼 data를 가져옴\n",
    "        fd={x:batchX,y:batchY,keep_prob:0.7}\n",
    "        cv,_=sess.run([cost,opt],feed_dict=fd)\n",
    "        avgCost+=cv/totalBatch\n",
    "    print(\"epoch:\",\"%04d\" %(epoch+1),\"cost\",\"{:.5f}\".format(avgCost))\n",
    "pred=tf.equal(tf.argmax(hf,1),tf.argmax(y,1))\n",
    "acc=tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "print(\"accuracy:\",sess.run(acc,\n",
    "                           feed_dict={x:mnist.test.images,\n",
    "                                      y:mnist.test.labels,\n",
    "                                      keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
