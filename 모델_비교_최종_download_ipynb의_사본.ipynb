{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "모델_비교_최종_download_ipynb의_사본.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lTXcXnLVkV-o"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqtsMSWL2XU4",
        "colab_type": "text"
      },
      "source": [
        "# 경고 메세지 무시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkUz9mddgtdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60WHzIBQB3ej",
        "colab_type": "code",
        "outputId": "d5a82b24-d026-4b3e-c650-251d6bd03433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoykbzuczqRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Add, BatchNormalization, concatenate\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3OTeZrQuKIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "np.random.seed(777)\n",
        "random.seed(777)\n",
        "#tf.random.set_seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cDhVV8IkIrf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94b79062-ab99-4528-9699-d9abdd4841b4"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWzotgAi2R_L",
        "colab_type": "text"
      },
      "source": [
        "# 재생산성을 위해 시드 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQBfOqbz19RO",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQJQW28aLgnR",
        "colab_type": "code",
        "outputId": "8a53b989-08ca-4d67-94da-73e1b0e0d29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "os.chdir('/gdrive/My Drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OmSpJrg2hD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  @ 정리해서 저장해놨음 \n",
        "# # 디렉토리 변경\n",
        "newPath='./데이콘 정리된데이터'\n",
        "train_diff = np.load(newPath+\"/full_train_diff.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLSoQrzV0SLU",
        "colab_type": "code",
        "outputId": "50fe0587-661f-4f30-e6c0-58b468e8ab4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_diff.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76345, 40, 40, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_0GOr_jvFJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_diff_images = train_diff[:, :, :, :9]\n",
        "train_diff_surface = train_diff[:, :, :, 9]\n",
        "train_diff_location_diff = train_diff[:, :, :, 10:12]\n",
        "train_diff_precipitation = train_diff[:, :, :, -1]\n",
        "del train_diff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Js17ySHvFNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51b9ab8d-45dc-4eec-df8b-5b1724b10064"
      },
      "source": [
        "# @train_dff image Std scaling하기\n",
        "mean = train_diff_images[:,:,:,:9].mean(axis=(0,1,2))\n",
        "std = train_diff_images[:,:,:,:9].std(axis=(0,1,2))\n",
        "train_diff_images[:,:,:,:9] = (train_diff_images[:,:,:,:9] - mean) / std\n",
        "train_diff_images.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76345, 40, 40, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M0LeQAnvFRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @ 지표 타입 변경 (300->3,200->2,...)\n",
        "train_diff_surface = np.where(train_diff_surface >= 300, 2, np.where(train_diff_surface >= 200, 1, np.where(train_diff_surface >= 100, 3, train_diff_surface)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8NObAa7viO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c667e471-fa43-4ac9-dd43-8dc738d21983"
      },
      "source": [
        "# @ 위경도차이 shape\n",
        "train_diff_location_diff[:,:,:,:2].shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76345, 40, 40, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD3U88dOv0JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @ 다시 합치기\n",
        "Scaled_beforeSplited = np.concatenate((train_diff_images, train_diff_surface.reshape(-1, 40, 40, 1), train_diff_location_diff, train_diff_precipitation.reshape(-1, 40, 40, 1)), axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnuUxrylv0aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_diff_images, train_diff_surface, train_diff_location_diff, train_diff_precipitation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xco3gxDOv0WK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91fe4bd7-4e63-474f-c5ea-370f1eb6599c"
      },
      "source": [
        "# @ shape 확인\n",
        "Scaled_beforeSplited.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76345, 40, 40, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m8mC90Nv0VU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1a3da0cb-a473-45ea-e662-41ec00d36d13"
      },
      "source": [
        "# @ train_test_split 나누기\n",
        "values = list(range(Scaled_beforeSplited.shape[0]))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_num, test_num = train_test_split(values, test_size=0.025)\n",
        "\n",
        "xTrain = Scaled_beforeSplited[:,:,:,:-1][train_num]\n",
        "yTrain = Scaled_beforeSplited[:,:,:,-1:][train_num]\n",
        "xValid = Scaled_beforeSplited[:,:,:,:-1][test_num]\n",
        "yValid = Scaled_beforeSplited[:,:,:,-1:][test_num]\n",
        "\n",
        "xTrain.shape, yTrain.shape, xValid.shape, yValid.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((74436, 40, 40, 12),\n",
              " (74436, 40, 40, 1),\n",
              " (1909, 40, 40, 12),\n",
              " (1909, 40, 40, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA6rpBgOv0Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save \"Scaled_beforeSplited\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jM9yzLVv0Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M-Uzyevv0Nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVTqlkNwLKZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 강수량이 -9999인것 삭제(이미 되어져 있어서 shape그대로)\n",
        "# train_diff = np.delete(train_diff, np.where(train_diff[:, :, :, -1] == -9999), axis=0)\n",
        "# train_diff.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axgYSzUJozH2",
        "colab_type": "code",
        "outputId": "455e6e4e-bde8-48ea-f7ac-a41d7f03c693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "values = list(range(train_diff.shape[0]))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_num, test_num = train_test_split(values, test_size=0.025)\n",
        "\n",
        "xTrain = train_diff[:,:,:,:-1][train_num]\n",
        "yTrain = train_diff[:,:,:,-1][train_num]\n",
        "xValid = train_diff[:,:,:,:-1][test_num]\n",
        "yValid = train_diff[:,:,:,-1][test_num]\n",
        "\n",
        "xTrain.shape, yTrain.shape, xValid.shape, yValid.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((74436, 40, 40, 12), (74436, 40, 40), (1909, 40, 40, 12), (1909, 40, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpFWlY9MvY5z",
        "colab_type": "text"
      },
      "source": [
        "## train_diff를 image, surface, location, precipitation으로 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JvdwZQNLv8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_diff_images = xTrain[:, :, :, :9]\n",
        "train_diff_surface = xTrain[:, :, :, 9]\n",
        "train_diff_location_diff = xTrain[:, :, :, 10:12]\n",
        "train_diff_precipitation = xTrain[:, :, :, -1]\n",
        "del xTrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcROj1AJ1-n-",
        "colab_type": "code",
        "outputId": "debbc83b-d6f5-47b4-c5ed-28b7d545e7e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "xValid_diff_images = xValid[:, :, :, :9]\n",
        "xValid_diff_surface = xValid[:, :, :, 9]\n",
        "xValid_diff_location_diff = xValid[:, :, :, 10:12]\n",
        "xValid_diff_precipitation = xValid[:, :, :, -1]\n",
        "del xValid\n",
        "xValid_diff_location_diff.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1909, 40, 40, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnwVJt5OO-lk",
        "colab_type": "code",
        "outputId": "d753c1e3-4824-4d6b-f668-0302b187b391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_diff_location_diff.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74436, 40, 40, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xboZV-iWvhlh",
        "colab_type": "text"
      },
      "source": [
        "## 각각 scaling하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgO7aKDJkr0q",
        "colab_type": "code",
        "outputId": "9e463965-ac45-4745-f1fb-f4d7b6f0fa13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# xtrain image Std scaling하기\n",
        "mean = train_diff_images[:,:,:,:9].mean(axis=(0,1,2))\n",
        "std = train_diff_images[:,:,:,:9].std(axis=(0,1,2))\n",
        "train_diff_images[:,:,:,:9] = (train_diff_images[:,:,:,:9] - mean) / std\n",
        "train_diff_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74436, 40, 40, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFRlb6tf3zM_",
        "colab_type": "code",
        "outputId": "8abc399a-55b0-4015-922f-6fecee2eb946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# xvalid image Std scaling하기\n",
        "mean = xValid_diff_images[:,:,:,:9].mean(axis=(0,1,2))\n",
        "std = xValid_diff_images[:,:,:,:9].std(axis=(0,1,2))\n",
        "xValid_diff_images[:,:,:,:9] = (xValid_diff_images[:,:,:,:9] - mean) / std\n",
        "xValid_diff_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1909, 40, 40, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFPIyGb4ksFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 지표 타입 변경 (300->3,200->2,...)\n",
        "train_diff_surface = np.where(train_diff_surface >= 300, 2, np.where(train_diff_surface >= 200, 1, np.where(train_diff_surface >= 100, 3, train_diff_surface)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d_oeW_N4LHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 지표 타입 변경 (300->3,200->2,...)\n",
        "xValid_diff_surface = np.where(xValid_diff_surface >= 300, 2, np.where(xValid_diff_surface >= 200, 1, np.where(xValid_diff_surface >= 100, 3, xValid_diff_surface)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDSaJByZksKz",
        "colab_type": "code",
        "outputId": "44dfce2b-d1db-47c2-fb84-2f07ee7a0f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_diff_location_diff[:,:,:,:2].shape\n",
        "xValid_diff_location_diff[:,:,:,:2].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1909, 40, 40, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6aHHbfEvkhS",
        "colab_type": "text"
      },
      "source": [
        "## 다시 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w1cTtAhksAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_scaled = np.concatenate((train_diff_images, train_diff_surface.reshape(-1, 40, 40, 1), train_diff_location_diff, train_diff_precipitation.reshape(-1, 40, 40, 1)), axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFNvSOFv4h6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xValid_scaled = np.concatenate((xValid_diff_images, xValid_diff_surface.reshape(-1, 40, 40, 1), xValid_diff_location_diff, xValid_diff_precipitation.reshape(-1, 40, 40, 1)), axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a6eiMEpkr_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_diff_images, train_diff_location_diff,train_diff_surface,train_diff_precipitation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPLRKymT4t_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del xValid_diff_images, xValid_diff_location_diff,xValid_diff_surface,xValid_diff_precipitation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QANSYDwa6j5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.hstack(train_scaled,"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U91keAoskr7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.save('./데이콘 정리된데이터'+\"/refinedTrain_diff.npy\",train_scaled) #<-refinedTrain_diff 로 저장\n",
        "#실수로 xValid랑 나누어저장함"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wF8hRQUkr6H",
        "colab_type": "code",
        "outputId": "b3f5aa13-3c3d-48df-fb28-37f9847f72fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_scaled.shape # train_diff의 precitation이 다시 들어갔으니 다시 나누어야함..."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74436, 40, 40, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrR02qQG43rK",
        "colab_type": "code",
        "outputId": "b5328e73-aaa8-4b46-9813-71adca291dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "xValid_scaled.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1909, 40, 40, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjnc8wOohNwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splited_scaled_train = np.load('./데이콘 정리된데이터'+\"/splited_scaled_train.npy\")\n",
        "splited_scaled_xValid = np.load('./데이콘 정리된데이터'+\"/splited_scaled_xValid.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI6BskdEKqSf",
        "colab_type": "text"
      },
      "source": [
        "### splited train,xValid로 따로 저장해서 나중에 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqGN4M9dKBS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save('./데이콘 정리된데이터'+\"/splited_scaled_train.npy\",train_scaled)\n",
        "# np.save('./데이콘 정리된데이터'+\"/splited_scaled_xValid.npy\",xValid_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTXcXnLVkV-o",
        "colab_type": "text"
      },
      "source": [
        "# test데이터로 diff만들어 처리하기(이미함)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYaAU56UPr4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xTest = np.load(newPath+'/test.npy')\n",
        "xTest.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1qRIkZQQRUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tempLen = xTest.shape[0]*xTest.shape[1]*xTest.shape[2]\n",
        "tempLen #<- reshape용 임시 길이변수\n",
        "tempTest = xTest.reshape(tempLen,xTest.shape[-1]) #<- (3865600,14) reshape하기\n",
        "tempStack = np.hstack((tempTest[:,:10],(tempTest[:,10]-tempTest[:,12]).reshape(-1,1))) #location 빼서 더하기(위도)\n",
        "tempStack.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO7O4gMvQmr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TestStacked = np.hstack((tempStack,(tempTest[:,11]-tempTest[:,13]).reshape(-1,1)))\n",
        "TestStacked.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO0EubsMQDHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_diff=TestStacked.reshape(xTest.shape[0],xTest.shape[1],xTest.shape[2],12)\n",
        "Test_diff.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU4B89kFQ_GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"Test_diff.npy\",Test_diff) #<-Test_diff 만들어서 저장하기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiGCd5jsQ_K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_diff_images = Test_diff[:, :, :, :9]\n",
        "test_diff_surface = Test_diff[:, :, :, 9]\n",
        "test_diff_location_diff = Test_diff[:, :, : , 10:12] #<-앞 소문자로 바꿈 \n",
        "test_diff_images.shape, test_diff_surface.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lg154Wbkw-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = test_diff_images[:,:,:,:9].mean(axis=(0,1,2))\n",
        "std = test_diff_images[:,:,:,:9].std(axis=(0,1,2))\n",
        "test_diff_images[:,:,:,:9] = (test_diff_images[:,:,:,:9] - mean) / std\n",
        "test_diff_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy2lX7Y2kxHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_diff_surface = np.where(test_diff_surface >= 300, 2, np.where(test_diff_surface >= 200, 1, np.where(test_diff_surface >= 100, 3, test_diff_surface)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HJD2ENDSk6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = test_diff_location_diff[:,:,:,:2].mean(axis=(0,1,2))\n",
        "std = test_diff_location_diff[:,:,:,:2].std(axis=(0,1,2))\n",
        "test_diff_location_diff[:,:,:,:2] = (test_diff_location_diff[:,:,:,:2] - mean) / std\n",
        "test_diff_location_diff.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mgpmn7VNAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhL2-a_PVFeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_diff_images = Test_diff[:, :, :, :9]\n",
        "# test_diff_surface = Test_diff[:, :, :, 9]\n",
        "# test_diff_location_diff = Test_diff[:, :, : , 10:12] #<-앞 소문자로 바꿈 \n",
        "# test_diff_images.shape, test_diff_surface.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WszvbzVUTYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = np.concatenate((test_diff_images, test_diff_surface.reshape(-1, 40, 40, 1), # test_diff_location_diff = Test_diff[:, :, : , 10:12] #<-앞 소문자로 바꿈 \n",
        "), axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvz4TWx-UTXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"test_refinedAll.npy\",test) #<-Test_diff 만들어서 저장하기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7sMSKX3PQpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = test[:, :, :, :9]\n",
        "test_surface = test[:, :, :, 9]\n",
        "test_location = test[:, :, : , 10:14]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvLUAPSJPQxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tempTest = xTest.reshape(tempLen,xTest.shape[-1]) #<- (3865600,14)\n",
        "tempStack = np.hstack((tempTest[:,:10],(tempTest[:,10]-tempTest[:,12]).reshape(-1,1)))\n",
        "tempStack.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF1L6wzGPKix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-earaCF2ens",
        "colab_type": "text"
      },
      "source": [
        "# 학습용 이미지와 라벨로 '다시' 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FByXsQu8jlGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f59e9f16-02cd-4e90-d396-6cc69339f70c"
      },
      "source": [
        "xTrain = splited_scaled_train[:, :, :, :-1]\n",
        "yTrain = splited_scaled_train[:, :, :, -1:]\n",
        "\n",
        "del splited_scaled_train\n",
        "xTrain.shape, yTrain.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((74436, 40, 40, 12), (74436, 40, 40, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBxLc_7wiNXP",
        "colab_type": "text"
      },
      "source": [
        "xTrain.shape, yTrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHDlu5wJ7Aoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b37f92ca-0bfb-4adf-f561-c9fe7311c9a3"
      },
      "source": [
        "xValid = splited_scaled_xValid[:,:,:,:-1]\n",
        "yValid = splited_scaled_xValid[:,:,:,-1:]\n",
        "\n",
        "del splited_scaled_xValid\n",
        "xValid.shape, yValid.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1909, 40, 40, 12), (1909, 40, 40, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkA2oehlz-sf",
        "colab_type": "text"
      },
      "source": [
        "\"train_diff파일을 train_test_split을 한 뒤 xTrain을 scaling해줌\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhvwK8-H088Z",
        "colab_type": "text"
      },
      "source": [
        "\"scaling한후 다시 합쳐서(train_scaled) image와 label로 나눔\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6U7vpww0-B6",
        "colab_type": "text"
      },
      "source": [
        "\"image와 label로 학습 후 xValid,yValid로 테스트\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEcF3wPk1Fyj",
        "colab_type": "text"
      },
      "source": [
        "\"테스트 후 scaling해둔 test_diff로 제출용 파일 만들기\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKZXv5p75NBz",
        "colab_type": "text"
      },
      "source": [
        "\"xValid도 scaling~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsD13Zj9tenp",
        "colab_type": "text"
      },
      "source": [
        "# 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0gcSdf6EL0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mae(y_true, y_pred) :\n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    \n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    \n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    \n",
        "    over_threshold = y_true >= 0.1\n",
        "    \n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    \n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    \n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    \n",
        "    remove_NAs = y_true >= 0\n",
        "    \n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    \n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    \n",
        "    return(f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
        "\n",
        "def fscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
        "    return score\n",
        "\n",
        "def maeOverFscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9IOlQQE1xgn",
        "colab_type": "text"
      },
      "source": [
        "# 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sDkbMCotUT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델\n",
        "def create_model():\n",
        "    inputs=Input(xTrain.shape[1:])\n",
        "    \n",
        "    bn=BatchNormalization()(inputs)\n",
        "    conv0=Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    bn=BatchNormalization()(conv0)\n",
        "    conv=Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
        "    concat=concatenate([conv0, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    conv=Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "    concat=concatenate([concat, conv], axis=3)\n",
        "        \n",
        "    for i in range(5):\n",
        "        bn=BatchNormalization()(concat)\n",
        "        conv=Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "        concat=concatenate([concat, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    outputs=Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    model=Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U42Xqgd9zn_R",
        "colab_type": "code",
        "outputId": "613fb90b-0b15-4b1d-dd7e-10bb4dae17cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Model = create_model()\n",
        "Model.summary()\n",
        "# 직접 쓴 ResNet과 논문에 나온 ResNet은 차이가 있음\n",
        "# layer1: (conv2d1+BN)+Conv2d1 =>\n",
        "# layer2: BN+conv2d2 =>\n",
        "# layer3: BN+conv2d3 =>\n",
        "# layer4: BN+conv2d4 =>\n",
        "# layer5: BN+conv2d5 =>\n",
        "# layer6: BN+conv2d6 =>\n",
        "# layer7: BN+conv2d7 =>\n",
        "# layer8: BN+conv2d8 => 강수량 1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 40, 40, 12)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 40, 40, 12)   48          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 40, 40, 256)  3328        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 40, 40, 256)  1024        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 40, 40, 128)  131200      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 40, 40, 384)  0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 40, 40, 384)  1536        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 40, 40, 64)   221248      batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 40, 40, 448)  0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 40, 40, 448)  1792        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 40, 40, 32)   129056      batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 40, 40, 480)  0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 40, 40, 480)  1920        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 40, 40, 32)   138272      batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 40, 40, 512)  0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 40, 40, 512)  2048        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 40, 40, 32)   147488      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 40, 40, 544)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 40, 40, 544)  2176        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 40, 40, 32)   156704      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 40, 40, 576)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 40, 40, 576)  2304        concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 40, 40, 32)   165920      batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 40, 40, 608)  0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 40, 40, 608)  2432        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 40, 40, 1)    609         batch_normalization_8[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 1,109,105\n",
            "Trainable params: 1,101,465\n",
            "Non-trainable params: 7,640\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1292PdsIXh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qyWJ4Je2_Ah",
        "colab_type": "text"
      },
      "source": [
        "# 콜백 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y72TywZ8w8n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callback 정의(EarlyStopping, ReduceLROnPlateau)\n",
        "callbacks_list = [\n",
        "                  tf.keras.callbacks.EarlyStopping(\n",
        "                      monitor='val_maeOverFscore_keras',\n",
        "                      patience=7,\n",
        "                      restore_best_weights=True\n",
        "                      ),\n",
        "                  tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                      monitor='val_maeOverFscore_keras',\n",
        "                      patience=7,\n",
        "                      factor=0.8\n",
        "                      )\n",
        "                  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwmKnIWR1RNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "   #tf.keras.callbacks.ModelCheckpoint(\n",
        "                  #    filepath='models/model' + str(model_number)+'.h5',\n",
        "                  #    monitor='val_maeOverFscore_keras',\n",
        "                  #    save_best_only=True\n",
        "                  #    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgfukO9250g",
        "colab_type": "text"
      },
      "source": [
        "# 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0v1OgSQ1OuB",
        "colab_type": "code",
        "outputId": "851a17c1-e6da-42e3-e96e-1ad24c0b3026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = Model.fit(xTrain, yTrain, epochs=50, batch_size=128,\n",
        "                    validation_data=(xValid, yValid), \n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 74436 samples, validate on 1909 samples\n",
            "Epoch 1/50\n",
            "74436/74436 [==============================] - 242s 3ms/sample - loss: 44.9600 - maeOverFscore_keras: 2.5883 - fscore_keras: 0.6416 - val_loss: 32.1073 - val_maeOverFscore_keras: 4.5134 - val_fscore_keras: 0.3503\n",
            "Epoch 2/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9373 - maeOverFscore_keras: 2.0251 - fscore_keras: 0.7023 - val_loss: 31.9950 - val_maeOverFscore_keras: 2.0101 - val_fscore_keras: 0.7339\n",
            "Epoch 3/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9344 - maeOverFscore_keras: 1.9100 - fscore_keras: 0.7200 - val_loss: 31.9904 - val_maeOverFscore_keras: 1.9299 - val_fscore_keras: 0.7487\n",
            "Epoch 4/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9330 - maeOverFscore_keras: 1.8733 - fscore_keras: 0.7245 - val_loss: 31.9879 - val_maeOverFscore_keras: 1.8810 - val_fscore_keras: 0.7418\n",
            "Epoch 5/50\n",
            "74436/74436 [==============================] - 232s 3ms/sample - loss: 44.9317 - maeOverFscore_keras: 1.8208 - fscore_keras: 0.7350 - val_loss: 31.9885 - val_maeOverFscore_keras: 1.8470 - val_fscore_keras: 0.7567\n",
            "Epoch 6/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9307 - maeOverFscore_keras: 1.7856 - fscore_keras: 0.7409 - val_loss: 31.9848 - val_maeOverFscore_keras: 1.7891 - val_fscore_keras: 0.7621\n",
            "Epoch 7/50\n",
            "74436/74436 [==============================] - 232s 3ms/sample - loss: 44.9298 - maeOverFscore_keras: 1.7627 - fscore_keras: 0.7445 - val_loss: 31.9854 - val_maeOverFscore_keras: 1.7670 - val_fscore_keras: 0.7673\n",
            "Epoch 8/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9285 - maeOverFscore_keras: 1.7182 - fscore_keras: 0.7519 - val_loss: 31.9835 - val_maeOverFscore_keras: 1.8068 - val_fscore_keras: 0.7455\n",
            "Epoch 9/50\n",
            "74436/74436 [==============================] - 230s 3ms/sample - loss: 44.9277 - maeOverFscore_keras: 1.6960 - fscore_keras: 0.7552 - val_loss: 31.9828 - val_maeOverFscore_keras: 1.6961 - val_fscore_keras: 0.7684\n",
            "Epoch 10/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9269 - maeOverFscore_keras: 1.6734 - fscore_keras: 0.7592 - val_loss: 31.9838 - val_maeOverFscore_keras: 1.8619 - val_fscore_keras: 0.7228\n",
            "Epoch 11/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9260 - maeOverFscore_keras: 1.6427 - fscore_keras: 0.7651 - val_loss: 31.9822 - val_maeOverFscore_keras: 1.7201 - val_fscore_keras: 0.7659\n",
            "Epoch 12/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9255 - maeOverFscore_keras: 1.6332 - fscore_keras: 0.7658 - val_loss: 31.9806 - val_maeOverFscore_keras: 1.6993 - val_fscore_keras: 0.7761\n",
            "Epoch 13/50\n",
            "74436/74436 [==============================] - 230s 3ms/sample - loss: 44.9248 - maeOverFscore_keras: 1.6123 - fscore_keras: 0.7702 - val_loss: 31.9845 - val_maeOverFscore_keras: 1.8136 - val_fscore_keras: 0.7537\n",
            "Epoch 14/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9240 - maeOverFscore_keras: 1.5837 - fscore_keras: 0.7739 - val_loss: 31.9797 - val_maeOverFscore_keras: 1.6625 - val_fscore_keras: 0.7808\n",
            "Epoch 15/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9236 - maeOverFscore_keras: 1.5787 - fscore_keras: 0.7746 - val_loss: 31.9803 - val_maeOverFscore_keras: 1.6734 - val_fscore_keras: 0.7777\n",
            "Epoch 16/50\n",
            "74436/74436 [==============================] - 232s 3ms/sample - loss: 44.9227 - maeOverFscore_keras: 1.5492 - fscore_keras: 0.7790 - val_loss: 31.9824 - val_maeOverFscore_keras: 1.7511 - val_fscore_keras: 0.7702\n",
            "Epoch 17/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9221 - maeOverFscore_keras: 1.5324 - fscore_keras: 0.7829 - val_loss: 31.9830 - val_maeOverFscore_keras: 1.7348 - val_fscore_keras: 0.7728\n",
            "Epoch 18/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9216 - maeOverFscore_keras: 1.5187 - fscore_keras: 0.7843 - val_loss: 31.9801 - val_maeOverFscore_keras: 1.6511 - val_fscore_keras: 0.7900\n",
            "Epoch 19/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9212 - maeOverFscore_keras: 1.5154 - fscore_keras: 0.7855 - val_loss: 31.9809 - val_maeOverFscore_keras: 1.6540 - val_fscore_keras: 0.7718\n",
            "Epoch 20/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9208 - maeOverFscore_keras: 1.4974 - fscore_keras: 0.7871 - val_loss: 31.9796 - val_maeOverFscore_keras: 1.6524 - val_fscore_keras: 0.7832\n",
            "Epoch 21/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9203 - maeOverFscore_keras: 1.4893 - fscore_keras: 0.7892 - val_loss: 31.9804 - val_maeOverFscore_keras: 1.7067 - val_fscore_keras: 0.7806\n",
            "Epoch 22/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9199 - maeOverFscore_keras: 1.4755 - fscore_keras: 0.7910 - val_loss: 31.9788 - val_maeOverFscore_keras: 1.6290 - val_fscore_keras: 0.7933\n",
            "Epoch 23/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9196 - maeOverFscore_keras: 1.4666 - fscore_keras: 0.7916 - val_loss: 31.9820 - val_maeOverFscore_keras: 1.6651 - val_fscore_keras: 0.7918\n",
            "Epoch 24/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9191 - maeOverFscore_keras: 1.4590 - fscore_keras: 0.7939 - val_loss: 31.9802 - val_maeOverFscore_keras: 1.5952 - val_fscore_keras: 0.7980\n",
            "Epoch 25/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9189 - maeOverFscore_keras: 1.4511 - fscore_keras: 0.7936 - val_loss: 31.9807 - val_maeOverFscore_keras: 1.6746 - val_fscore_keras: 0.7802\n",
            "Epoch 26/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9184 - maeOverFscore_keras: 1.4402 - fscore_keras: 0.7965 - val_loss: 31.9777 - val_maeOverFscore_keras: 1.5926 - val_fscore_keras: 0.7955\n",
            "Epoch 27/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9182 - maeOverFscore_keras: 1.4330 - fscore_keras: 0.7975 - val_loss: 31.9775 - val_maeOverFscore_keras: 1.6202 - val_fscore_keras: 0.7856\n",
            "Epoch 28/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9179 - maeOverFscore_keras: 1.4234 - fscore_keras: 0.7978 - val_loss: 31.9785 - val_maeOverFscore_keras: 1.6129 - val_fscore_keras: 0.7989\n",
            "Epoch 29/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9177 - maeOverFscore_keras: 1.4209 - fscore_keras: 0.7988 - val_loss: 31.9812 - val_maeOverFscore_keras: 1.7185 - val_fscore_keras: 0.7757\n",
            "Epoch 30/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9174 - maeOverFscore_keras: 1.4146 - fscore_keras: 0.7997 - val_loss: 31.9800 - val_maeOverFscore_keras: 1.6750 - val_fscore_keras: 0.7829\n",
            "Epoch 31/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9171 - maeOverFscore_keras: 1.4069 - fscore_keras: 0.8013 - val_loss: 31.9813 - val_maeOverFscore_keras: 1.6829 - val_fscore_keras: 0.7928\n",
            "Epoch 32/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9169 - maeOverFscore_keras: 1.4011 - fscore_keras: 0.8011 - val_loss: 31.9782 - val_maeOverFscore_keras: 1.5848 - val_fscore_keras: 0.7938\n",
            "Epoch 33/50\n",
            "74436/74436 [==============================] - 232s 3ms/sample - loss: 44.9165 - maeOverFscore_keras: 1.3949 - fscore_keras: 0.8026 - val_loss: 31.9807 - val_maeOverFscore_keras: 1.6232 - val_fscore_keras: 0.7900\n",
            "Epoch 34/50\n",
            "74436/74436 [==============================] - 232s 3ms/sample - loss: 44.9165 - maeOverFscore_keras: 1.3927 - fscore_keras: 0.8025 - val_loss: 31.9793 - val_maeOverFscore_keras: 1.6336 - val_fscore_keras: 0.7919\n",
            "Epoch 35/50\n",
            "74436/74436 [==============================] - 232s 3ms/sample - loss: 44.9161 - maeOverFscore_keras: 1.3851 - fscore_keras: 0.8037 - val_loss: 31.9780 - val_maeOverFscore_keras: 1.5655 - val_fscore_keras: 0.8072\n",
            "Epoch 36/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9160 - maeOverFscore_keras: 1.3831 - fscore_keras: 0.8039 - val_loss: 31.9802 - val_maeOverFscore_keras: 1.6413 - val_fscore_keras: 0.7727\n",
            "Epoch 37/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9158 - maeOverFscore_keras: 1.3766 - fscore_keras: 0.8045 - val_loss: 31.9771 - val_maeOverFscore_keras: 1.5941 - val_fscore_keras: 0.8032\n",
            "Epoch 38/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9156 - maeOverFscore_keras: 1.3729 - fscore_keras: 0.8044 - val_loss: 31.9796 - val_maeOverFscore_keras: 1.6209 - val_fscore_keras: 0.7901\n",
            "Epoch 39/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9153 - maeOverFscore_keras: 1.3664 - fscore_keras: 0.8056 - val_loss: 31.9765 - val_maeOverFscore_keras: 1.5392 - val_fscore_keras: 0.8109\n",
            "Epoch 40/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9151 - maeOverFscore_keras: 1.3638 - fscore_keras: 0.8055 - val_loss: 31.9758 - val_maeOverFscore_keras: 1.5428 - val_fscore_keras: 0.8005\n",
            "Epoch 41/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9150 - maeOverFscore_keras: 1.3605 - fscore_keras: 0.8053 - val_loss: 31.9771 - val_maeOverFscore_keras: 1.5817 - val_fscore_keras: 0.8003\n",
            "Epoch 42/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9148 - maeOverFscore_keras: 1.3553 - fscore_keras: 0.8065 - val_loss: 31.9781 - val_maeOverFscore_keras: 1.5770 - val_fscore_keras: 0.7958\n",
            "Epoch 43/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9145 - maeOverFscore_keras: 1.3485 - fscore_keras: 0.8067 - val_loss: 31.9801 - val_maeOverFscore_keras: 1.6538 - val_fscore_keras: 0.8012\n",
            "Epoch 44/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9144 - maeOverFscore_keras: 1.3472 - fscore_keras: 0.8066 - val_loss: 31.9767 - val_maeOverFscore_keras: 1.5709 - val_fscore_keras: 0.8039\n",
            "Epoch 45/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9142 - maeOverFscore_keras: 1.3416 - fscore_keras: 0.8076 - val_loss: 31.9765 - val_maeOverFscore_keras: 1.5663 - val_fscore_keras: 0.8035\n",
            "Epoch 46/50\n",
            "74436/74436 [==============================] - 231s 3ms/sample - loss: 44.9140 - maeOverFscore_keras: 1.3405 - fscore_keras: 0.8077 - val_loss: 31.9825 - val_maeOverFscore_keras: 1.6654 - val_fscore_keras: 0.7712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjOomGUxRv3T",
        "colab_type": "text"
      },
      "source": [
        "# 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xr0cTPbRyVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model.save('''경로 및 파일 명 설정''')\n",
        "model_path = './모델저장폴더/'\n",
        "file_name = '05-28 Resnet Scaled before splited.h5'\n",
        "Model.save(model_path+file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_AvPHjuPtNL",
        "colab_type": "text"
      },
      "source": [
        "# 평가 값 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrCQELKPu3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B65pMS8zPwWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "159c4531-64ca-4ecb-ce84-f3a291b4e399"
      },
      "source": [
        "plt.plot(history.history['val_maeOverFscore_keras'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f58365fb400>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gFNggR0R8bP",
        "colab_type": "text"
      },
      "source": [
        "# 테스트 데이터로 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfwKtYuW8YU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 디렉토리 변경\n",
        "# newPath='./데이콘 정리된데이터'\n",
        "# train_diff = np.load(newPath+\"/full_train_diff.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBZANRk_SOoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dd70175-1438-4dcf-939c-99c3b59878e5"
      },
      "source": [
        "Test_diff = np.load(newPath+'/Test_diff.npy')\n",
        "Test_diff.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2416, 40, 40, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWK5ryzHcoAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_diff_images = Test_diff[:, :, :, :9]\n",
        "Test_diff_surface = Test_diff[:, :, :, 9]\n",
        "Test_diff_location_diff = Test_diff[:, :, :, 10:12]\n",
        "del Test_diff\n",
        "#Test_diff에는 precipitation이없음@@@!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbMK_-YMdUi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test_diff의 image Std scaling하기\n",
        "mean = Test_diff_images[:,:,:,:9].mean(axis=(0,1,2))\n",
        "std = Test_diff_images[:,:,:,:9].std(axis=(0,1,2))\n",
        "Test_diff_images[:,:,:,:9] = (Test_diff_images[:,:,:,:9] - mean) / std\n",
        "Test_diff_images.shape\n",
        "# 지표 타입 변경 (300->3,200->2,...)\n",
        "Test_diff_surface = np.where(Test_diff_surface >= 300, 2, np.where(Test_diff_surface >= 200, 1, np.where(Test_diff_surface >= 100, 3, Test_diff_surface)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdoZYGzjdUnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65J1FXISdVZL",
        "colab_type": "text"
      },
      "source": [
        "# 나누어진 test 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL7Xtkp6coE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dc525b9-daf8-4cdc-c93f-d26214f03e18"
      },
      "source": [
        "# train_diff_location_diff[:,:,:,:2].shape\n",
        "# xValid_diff_location_diff[:,:,:,:2].shape\n",
        "Test_diff_location_diff.shape\n",
        "Test_scaled = np.concatenate((Test_diff_images, Test_diff_surface.reshape(-1, 40, 40, 1), Test_diff_location_diff), axis=3)\n",
        "Test_scaled.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2416, 40, 40, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qH5s6IQdDko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N910cGZ8dEA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaled된 test데이터 저장하기\n",
        "np.save('./데이콘 정리된데이터'+\"/Test_scaled.npy\",Test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wFPAOgTdDpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLMxD8lGSQ8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = Model.predict(Test_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo5nhNRxSSu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del Test_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vC7kuhXSUOc",
        "colab_type": "text"
      },
      "source": [
        "# 제출 파일 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZtE9c7tSUjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "submission = pd.read_csv('./데이콘 정리된데이터'+'/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu7Y3UOySbiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "254de86f-f243-48ee-9cf0-24dcdecc20d2"
      },
      "source": [
        "submission.iloc[:,1:] = pred.reshape(-1,1600)\n",
        "submission"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>px_1</th>\n",
              "      <th>px_2</th>\n",
              "      <th>px_3</th>\n",
              "      <th>px_4</th>\n",
              "      <th>px_5</th>\n",
              "      <th>px_6</th>\n",
              "      <th>px_7</th>\n",
              "      <th>px_8</th>\n",
              "      <th>px_9</th>\n",
              "      <th>px_10</th>\n",
              "      <th>px_11</th>\n",
              "      <th>px_12</th>\n",
              "      <th>px_13</th>\n",
              "      <th>px_14</th>\n",
              "      <th>px_15</th>\n",
              "      <th>px_16</th>\n",
              "      <th>px_17</th>\n",
              "      <th>px_18</th>\n",
              "      <th>px_19</th>\n",
              "      <th>px_20</th>\n",
              "      <th>px_21</th>\n",
              "      <th>px_22</th>\n",
              "      <th>px_23</th>\n",
              "      <th>px_24</th>\n",
              "      <th>px_25</th>\n",
              "      <th>px_26</th>\n",
              "      <th>px_27</th>\n",
              "      <th>px_28</th>\n",
              "      <th>px_29</th>\n",
              "      <th>px_30</th>\n",
              "      <th>px_31</th>\n",
              "      <th>px_32</th>\n",
              "      <th>px_33</th>\n",
              "      <th>px_34</th>\n",
              "      <th>px_35</th>\n",
              "      <th>px_36</th>\n",
              "      <th>px_37</th>\n",
              "      <th>px_38</th>\n",
              "      <th>px_39</th>\n",
              "      <th>...</th>\n",
              "      <th>px_1561</th>\n",
              "      <th>px_1562</th>\n",
              "      <th>px_1563</th>\n",
              "      <th>px_1564</th>\n",
              "      <th>px_1565</th>\n",
              "      <th>px_1566</th>\n",
              "      <th>px_1567</th>\n",
              "      <th>px_1568</th>\n",
              "      <th>px_1569</th>\n",
              "      <th>px_1570</th>\n",
              "      <th>px_1571</th>\n",
              "      <th>px_1572</th>\n",
              "      <th>px_1573</th>\n",
              "      <th>px_1574</th>\n",
              "      <th>px_1575</th>\n",
              "      <th>px_1576</th>\n",
              "      <th>px_1577</th>\n",
              "      <th>px_1578</th>\n",
              "      <th>px_1579</th>\n",
              "      <th>px_1580</th>\n",
              "      <th>px_1581</th>\n",
              "      <th>px_1582</th>\n",
              "      <th>px_1583</th>\n",
              "      <th>px_1584</th>\n",
              "      <th>px_1585</th>\n",
              "      <th>px_1586</th>\n",
              "      <th>px_1587</th>\n",
              "      <th>px_1588</th>\n",
              "      <th>px_1589</th>\n",
              "      <th>px_1590</th>\n",
              "      <th>px_1591</th>\n",
              "      <th>px_1592</th>\n",
              "      <th>px_1593</th>\n",
              "      <th>px_1594</th>\n",
              "      <th>px_1595</th>\n",
              "      <th>px_1596</th>\n",
              "      <th>px_1597</th>\n",
              "      <th>px_1598</th>\n",
              "      <th>px_1599</th>\n",
              "      <th>px_1600</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>029858_01</td>\n",
              "      <td>3.942415</td>\n",
              "      <td>1.645509</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.595663</td>\n",
              "      <td>12.045096</td>\n",
              "      <td>11.238461</td>\n",
              "      <td>1.854362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.571892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.003605</td>\n",
              "      <td>15.340535</td>\n",
              "      <td>4.050344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>029858_02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>029858_03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>029858_05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.768276</td>\n",
              "      <td>8.474299</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>6.497280</td>\n",
              "      <td>55.490929</td>\n",
              "      <td>90.798668</td>\n",
              "      <td>31.016533</td>\n",
              "      <td>2.512514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>029858_07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.105764</td>\n",
              "      <td>0.057458</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.465321</td>\n",
              "      <td>6.593607</td>\n",
              "      <td>3.456276</td>\n",
              "      <td>6.774041</td>\n",
              "      <td>11.202007</td>\n",
              "      <td>11.814945</td>\n",
              "      <td>11.537794</td>\n",
              "      <td>6.33144</td>\n",
              "      <td>4.343465</td>\n",
              "      <td>4.962487</td>\n",
              "      <td>14.886460</td>\n",
              "      <td>20.530565</td>\n",
              "      <td>24.112438</td>\n",
              "      <td>26.753447</td>\n",
              "      <td>22.088959</td>\n",
              "      <td>13.465039</td>\n",
              "      <td>16.591497</td>\n",
              "      <td>20.641062</td>\n",
              "      <td>21.7089</td>\n",
              "      <td>29.456413</td>\n",
              "      <td>30.887444</td>\n",
              "      <td>30.89147</td>\n",
              "      <td>31.481464</td>\n",
              "      <td>32.136936</td>\n",
              "      <td>29.752735</td>\n",
              "      <td>18.630568</td>\n",
              "      <td>8.925898</td>\n",
              "      <td>4.696815</td>\n",
              "      <td>0.862106</td>\n",
              "      <td>1.387504</td>\n",
              "      <td>2.781418</td>\n",
              "      <td>5.506512</td>\n",
              "      <td>10.081458</td>\n",
              "      <td>5.127625</td>\n",
              "      <td>3.845044</td>\n",
              "      <td>3.264772</td>\n",
              "      <td>8.408371</td>\n",
              "      <td>24.591402</td>\n",
              "      <td>21.135443</td>\n",
              "      <td>19.77174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2411</th>\n",
              "      <td>031287_08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2412</th>\n",
              "      <td>031288_01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.627764</td>\n",
              "      <td>2.026138</td>\n",
              "      <td>0.986062</td>\n",
              "      <td>0.014814</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.098043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.162946</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>6.664448</td>\n",
              "      <td>11.663042</td>\n",
              "      <td>13.058616</td>\n",
              "      <td>13.845306</td>\n",
              "      <td>6.478085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2413</th>\n",
              "      <td>031288_02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.083721</td>\n",
              "      <td>7.164368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.316255</td>\n",
              "      <td>21.069624</td>\n",
              "      <td>30.671768</td>\n",
              "      <td>36.047611</td>\n",
              "      <td>50.515995</td>\n",
              "      <td>53.543076</td>\n",
              "      <td>52.020184</td>\n",
              "      <td>73.424339</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>031288_08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>031288_11</td>\n",
              "      <td>17.193115</td>\n",
              "      <td>11.447588</td>\n",
              "      <td>5.697817</td>\n",
              "      <td>3.57439</td>\n",
              "      <td>1.480488</td>\n",
              "      <td>0.912454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.316756</td>\n",
              "      <td>1.117025</td>\n",
              "      <td>2.103495</td>\n",
              "      <td>2.15512</td>\n",
              "      <td>1.181538</td>\n",
              "      <td>1.841605</td>\n",
              "      <td>1.421549</td>\n",
              "      <td>0.757479</td>\n",
              "      <td>1.262872</td>\n",
              "      <td>1.479366</td>\n",
              "      <td>0.711018</td>\n",
              "      <td>0.859830</td>\n",
              "      <td>1.398510</td>\n",
              "      <td>1.265412</td>\n",
              "      <td>1.130621</td>\n",
              "      <td>2.583252</td>\n",
              "      <td>5.053743</td>\n",
              "      <td>7.344794</td>\n",
              "      <td>3.631328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2416 rows × 1601 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id       px_1       px_2  ...    px_1598    px_1599   px_1600\n",
              "0     029858_01   3.942415   1.645509  ...   0.000000   0.000000   0.00000\n",
              "1     029858_02   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "2     029858_03   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "3     029858_05   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "4     029858_07   0.000000   0.000000  ...  24.591402  21.135443  19.77174\n",
              "...         ...        ...        ...  ...        ...        ...       ...\n",
              "2411  031287_08   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "2412  031288_01   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "2413  031288_02   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "2414  031288_08   0.000000   0.000000  ...   0.000000   0.000000   0.00000\n",
              "2415  031288_11  17.193115  11.447588  ...   0.000000   0.000000   0.00000\n",
              "\n",
              "[2416 rows x 1601 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XypDpdQoSdb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dmj8xsvSfJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('./모델저장폴더/'+'05-28 Scaled submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cBbzHA_fsVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}