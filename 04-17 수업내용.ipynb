{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#케라스 모델 생성 절차\n",
    "1) 데이터셋 생성:\n",
    "    - 훈련, 검증, 테스트\n",
    "2) 모델 구성...:\n",
    "    - 시퀀스 모델 생성한 다음에 레이어를 추가\n",
    "    - 복잡한 모델은 케라스 함수 api 사용하면됨\n",
    "3) 모델 학습과정 설정:\n",
    "    - Cost 함수, 최적화 방법 정의\n",
    "    - Compile함수가 사용됨\n",
    "4) 모델 학습:\n",
    "    - 트레이닝 데이터로 모델 학습\n",
    "    - fit 함수가 사용됨\n",
    "5) 훈련셋,검증셋의 cost 측정:\n",
    "6) 모델 평가:\n",
    "    - test 데이터 셋으로 평가\n",
    "    - evaluate함수가 사용됨\n",
    "7) 모델 사용:\n",
    "    - 입력 -> 모델 -> 출력(예측...)\n",
    "    - predict 함수가 사용됨\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 데이터셋 생성하기\n",
    "(xTrain,yTrain),(xTest,yTest) = mnist.load_data() # 2개씩 들어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = np_utils.to_categorical(yTrain)   #<- 원핫인코딩하는 함수: np_utils\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 모델 구성\n",
    "model=Sequential()\n",
    "model.add(Dense(units=64,input_dim=28*28,activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax')) # layer를 추가할 때 함수Dense를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.6710 - accuracy: 0.8289\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3431 - accuracy: 0.9037\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2965 - accuracy: 0.9164\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2678 - accuracy: 0.9241\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2462 - accuracy: 0.9308\n"
     ]
    }
   ],
   "source": [
    "#4. 모델 학습\n",
    "hist = model.fit(xTrain, yTrain, epochs=5, batch_size=32)#epoch: 데이터를 몇 번 학습할 거냐\n",
    "#batch_size: 몇 개의 샘플로 가중치를 갱신할 거냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: [0.6710068199674288, 0.34313783300320305, 0.29646547234654425, 0.26780129848321277, 0.24623901411096255]\n",
      "accuracy: [0.82888335, 0.9036833, 0.9163833, 0.9241167, 0.93075]\n"
     ]
    }
   ],
   "source": [
    "print(\"loss:\",hist.history['loss'])\n",
    "print(\"accuracy:\",hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 82us/step\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(xTest,yTest,batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.1925501e-05 1.6435973e-08 1.8481190e-04 1.1433597e-03 6.9115686e-07\n",
      "  1.9044955e-05 5.3961910e-09 9.9833089e-01 2.1637268e-05 2.5770490e-04]]\n"
     ]
    }
   ],
   "source": [
    "#모델 예측\n",
    "xhat = xTest[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n-훈련셋 : 모의고사\\n-검증셋 : \\n=> 테스트셋 : (작년)수능     학생:5명, 모델:5개\\n\\n*(학생마다)공부하는 법이 다 다름: 모델이 다 다름\\n\\n학습? 문제, 답안지 제공\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "-훈련셋 : 모의고사\n",
    "-검증셋 : \n",
    "=> 테스트셋 : (작년)수능     학생:5명, 모델:5개\n",
    "\n",
    "*(학생마다)공부하는 법이 다 다름: 모델이 다 다름\n",
    "\n",
    "학습? 문제, 답안지 제공\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-훈련데이터셋(70) / 시험셋(30) (<-작년수능)\n",
    "-훈련셋: <훈련셋(70)> / <검증셋(30)>\n",
    "실전: 올해 수능\n",
    "=> 훈련셋에 최적의 데이터 셋의 비중을 하이퍼파라미터!\n",
    "하이퍼파라미터 튜닝을 해야함\n",
    "조기종료를 잘 해야함(너무 많이 학습하면 과적합)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "모의고사: #1 ~ 4 학습 #5로 평가 = 점수 A\n",
    "        #1,2,3,5 학습 #4로 평가 = 점수 B\n",
    "        ...\n",
    "        --------------------------------\n",
    "                              => (평균,분산) *분산을보는이유:1,2,3,4회에선 90%이상인데\n",
    "                                                       5회에서 40%가 나오면 문제가 있음\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain,yTrain),(xTest,yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal = xTrain[50000:]\n",
    "yVal = yTrain[50000:]\n",
    "xTrain = xTrain[:50000]\n",
    "yTrain = yTrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain.reshape(50000,784).astype('float32')/255.0\n",
    "xVal=xVal.reshape(10000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련, 검증 데이터 선택\n",
    "tri=np.random.choice(50000,700)\n",
    "vri=np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain[tri] #700\n",
    "yTrain=yTrain[tri]\n",
    "xVal=xVal[vri] #300\n",
    "yVal=yVal[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = np_utils.to_categorical(yTrain)\n",
    "yVal = np_utils.to_categorical(yVal)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.add(Dense(input_dim=28*28, units=2,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 160us/step - loss: 2.2576 - accuracy: 0.1643 - val_loss: 2.2272 - val_accuracy: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 2.2072 - accuracy: 0.1657 - val_loss: 2.1908 - val_accuracy: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 2.1730 - accuracy: 0.1729 - val_loss: 2.1631 - val_accuracy: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 2.1441 - accuracy: 0.1786 - val_loss: 2.1372 - val_accuracy: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 2.1177 - accuracy: 0.1900 - val_loss: 2.1141 - val_accuracy: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 2.0940 - accuracy: 0.2029 - val_loss: 2.0931 - val_accuracy: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 2.0721 - accuracy: 0.2071 - val_loss: 2.0727 - val_accuracy: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 2.0520 - accuracy: 0.2129 - val_loss: 2.0564 - val_accuracy: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 2.0342 - accuracy: 0.2157 - val_loss: 2.0410 - val_accuracy: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 2.0190 - accuracy: 0.2143 - val_loss: 2.0269 - val_accuracy: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 2.0041 - accuracy: 0.2186 - val_loss: 2.0125 - val_accuracy: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.9911 - accuracy: 0.2200 - val_loss: 2.0037 - val_accuracy: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.9789 - accuracy: 0.2286 - val_loss: 1.9955 - val_accuracy: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.9685 - accuracy: 0.2329 - val_loss: 1.9833 - val_accuracy: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.9582 - accuracy: 0.2214 - val_loss: 1.9753 - val_accuracy: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.9484 - accuracy: 0.2357 - val_loss: 1.9686 - val_accuracy: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.9393 - accuracy: 0.2343 - val_loss: 1.9612 - val_accuracy: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.9309 - accuracy: 0.2314 - val_loss: 1.9537 - val_accuracy: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.9232 - accuracy: 0.2286 - val_loss: 1.9452 - val_accuracy: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.9156 - accuracy: 0.2386 - val_loss: 1.9392 - val_accuracy: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.9085 - accuracy: 0.2343 - val_loss: 1.9363 - val_accuracy: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.9011 - accuracy: 0.2386 - val_loss: 1.9289 - val_accuracy: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.8954 - accuracy: 0.2357 - val_loss: 1.9234 - val_accuracy: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.8895 - accuracy: 0.2314 - val_loss: 1.9201 - val_accuracy: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.8830 - accuracy: 0.2343 - val_loss: 1.9178 - val_accuracy: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.8769 - accuracy: 0.2300 - val_loss: 1.9105 - val_accuracy: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8715 - accuracy: 0.2357 - val_loss: 1.9098 - val_accuracy: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.8662 - accuracy: 0.2400 - val_loss: 1.9094 - val_accuracy: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8615 - accuracy: 0.2400 - val_loss: 1.9041 - val_accuracy: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.8565 - accuracy: 0.2243 - val_loss: 1.8976 - val_accuracy: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.8513 - accuracy: 0.2471 - val_loss: 1.8971 - val_accuracy: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.8463 - accuracy: 0.2371 - val_loss: 1.8925 - val_accuracy: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8423 - accuracy: 0.2229 - val_loss: 1.8874 - val_accuracy: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.8382 - accuracy: 0.2371 - val_loss: 1.8808 - val_accuracy: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.8335 - accuracy: 0.2471 - val_loss: 1.8836 - val_accuracy: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.8299 - accuracy: 0.2343 - val_loss: 1.8756 - val_accuracy: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.8257 - accuracy: 0.2486 - val_loss: 1.8745 - val_accuracy: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.8220 - accuracy: 0.2371 - val_loss: 1.8700 - val_accuracy: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8184 - accuracy: 0.2457 - val_loss: 1.8706 - val_accuracy: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8144 - accuracy: 0.2314 - val_loss: 1.8677 - val_accuracy: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.8105 - accuracy: 0.2400 - val_loss: 1.8668 - val_accuracy: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8075 - accuracy: 0.2471 - val_loss: 1.8635 - val_accuracy: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.8046 - accuracy: 0.2429 - val_loss: 1.8611 - val_accuracy: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.8001 - accuracy: 0.2371 - val_loss: 1.8566 - val_accuracy: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.7970 - accuracy: 0.2429 - val_loss: 1.8564 - val_accuracy: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.7939 - accuracy: 0.2271 - val_loss: 1.8528 - val_accuracy: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.7913 - accuracy: 0.2600 - val_loss: 1.8551 - val_accuracy: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.7886 - accuracy: 0.2471 - val_loss: 1.8543 - val_accuracy: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.7858 - accuracy: 0.2486 - val_loss: 1.8504 - val_accuracy: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7819 - accuracy: 0.2471 - val_loss: 1.8443 - val_accuracy: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7794 - accuracy: 0.2643 - val_loss: 1.8468 - val_accuracy: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7762 - accuracy: 0.2486 - val_loss: 1.8411 - val_accuracy: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.7744 - accuracy: 0.2514 - val_loss: 1.8486 - val_accuracy: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7716 - accuracy: 0.2700 - val_loss: 1.8472 - val_accuracy: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.7687 - accuracy: 0.2500 - val_loss: 1.8364 - val_accuracy: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7672 - accuracy: 0.2543 - val_loss: 1.8430 - val_accuracy: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.7641 - accuracy: 0.2714 - val_loss: 1.8390 - val_accuracy: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.7616 - accuracy: 0.2557 - val_loss: 1.8347 - val_accuracy: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.7590 - accuracy: 0.2671 - val_loss: 1.8329 - val_accuracy: 0.2233\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7552 - accuracy: 0.2614 - val_loss: 1.8256 - val_accuracy: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.7566 - accuracy: 0.2814 - val_loss: 1.8336 - val_accuracy: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7531 - accuracy: 0.2729 - val_loss: 1.8312 - val_accuracy: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7505 - accuracy: 0.2857 - val_loss: 1.8299 - val_accuracy: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.7484 - accuracy: 0.2800 - val_loss: 1.8268 - val_accuracy: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.7457 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.7439 - accuracy: 0.2786 - val_loss: 1.8296 - val_accuracy: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.7419 - accuracy: 0.2700 - val_loss: 1.8299 - val_accuracy: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.7405 - accuracy: 0.2729 - val_loss: 1.8238 - val_accuracy: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.7376 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.7356 - accuracy: 0.2857 - val_loss: 1.8269 - val_accuracy: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.7345 - accuracy: 0.2800 - val_loss: 1.8214 - val_accuracy: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.7328 - accuracy: 0.2857 - val_loss: 1.8226 - val_accuracy: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7298 - accuracy: 0.2800 - val_loss: 1.8252 - val_accuracy: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.7283 - accuracy: 0.2857 - val_loss: 1.8257 - val_accuracy: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7268 - accuracy: 0.2786 - val_loss: 1.8190 - val_accuracy: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7255 - accuracy: 0.2857 - val_loss: 1.8196 - val_accuracy: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7228 - accuracy: 0.3057 - val_loss: 1.8232 - val_accuracy: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7212 - accuracy: 0.2857 - val_loss: 1.8187 - val_accuracy: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7199 - accuracy: 0.2829 - val_loss: 1.8203 - val_accuracy: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.7188 - accuracy: 0.2929 - val_loss: 1.8197 - val_accuracy: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.7165 - accuracy: 0.2843 - val_loss: 1.8256 - val_accuracy: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7142 - accuracy: 0.2829 - val_loss: 1.8144 - val_accuracy: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7132 - accuracy: 0.2857 - val_loss: 1.8190 - val_accuracy: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.7127 - accuracy: 0.2986 - val_loss: 1.8220 - val_accuracy: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7097 - accuracy: 0.2971 - val_loss: 1.8159 - val_accuracy: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7082 - accuracy: 0.2800 - val_loss: 1.8136 - val_accuracy: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7051 - accuracy: 0.3100 - val_loss: 1.8191 - val_accuracy: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7062 - accuracy: 0.3043 - val_loss: 1.8125 - val_accuracy: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.7043 - accuracy: 0.3043 - val_loss: 1.8167 - val_accuracy: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.7027 - accuracy: 0.2843 - val_loss: 1.8151 - val_accuracy: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.7017 - accuracy: 0.3086 - val_loss: 1.8185 - val_accuracy: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6987 - accuracy: 0.3129 - val_loss: 1.8215 - val_accuracy: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6980 - accuracy: 0.3071 - val_loss: 1.8173 - val_accuracy: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6970 - accuracy: 0.3157 - val_loss: 1.8176 - val_accuracy: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6943 - accuracy: 0.2986 - val_loss: 1.8194 - val_accuracy: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6948 - accuracy: 0.3014 - val_loss: 1.8095 - val_accuracy: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6930 - accuracy: 0.3057 - val_loss: 1.8228 - val_accuracy: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6921 - accuracy: 0.3043 - val_loss: 1.8117 - val_accuracy: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6901 - accuracy: 0.3129 - val_loss: 1.8252 - val_accuracy: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6890 - accuracy: 0.3129 - val_loss: 1.8210 - val_accuracy: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6878 - accuracy: 0.3143 - val_loss: 1.8190 - val_accuracy: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6877 - accuracy: 0.3014 - val_loss: 1.8219 - val_accuracy: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6843 - accuracy: 0.3000 - val_loss: 1.8102 - val_accuracy: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6842 - accuracy: 0.3200 - val_loss: 1.8122 - val_accuracy: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6821 - accuracy: 0.3071 - val_loss: 1.8063 - val_accuracy: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6814 - accuracy: 0.3114 - val_loss: 1.8173 - val_accuracy: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6805 - accuracy: 0.3071 - val_loss: 1.8228 - val_accuracy: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6784 - accuracy: 0.3071 - val_loss: 1.8167 - val_accuracy: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6782 - accuracy: 0.3143 - val_loss: 1.8178 - val_accuracy: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6775 - accuracy: 0.3171 - val_loss: 1.8147 - val_accuracy: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6775 - accuracy: 0.3043 - val_loss: 1.8173 - val_accuracy: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6745 - accuracy: 0.3129 - val_loss: 1.8193 - val_accuracy: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6737 - accuracy: 0.3100 - val_loss: 1.8196 - val_accuracy: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6724 - accuracy: 0.3014 - val_loss: 1.8221 - val_accuracy: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6711 - accuracy: 0.3071 - val_loss: 1.8128 - val_accuracy: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.6703 - accuracy: 0.3157 - val_loss: 1.8255 - val_accuracy: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6694 - accuracy: 0.3100 - val_loss: 1.8228 - val_accuracy: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.6682 - accuracy: 0.3114 - val_loss: 1.8262 - val_accuracy: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.6670 - accuracy: 0.3257 - val_loss: 1.8216 - val_accuracy: 0.2200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6661 - accuracy: 0.3129 - val_loss: 1.8219 - val_accuracy: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6646 - accuracy: 0.3071 - val_loss: 1.8132 - val_accuracy: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6637 - accuracy: 0.3229 - val_loss: 1.8194 - val_accuracy: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6629 - accuracy: 0.3100 - val_loss: 1.8139 - val_accuracy: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6619 - accuracy: 0.3143 - val_loss: 1.8187 - val_accuracy: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6606 - accuracy: 0.3257 - val_loss: 1.8212 - val_accuracy: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6592 - accuracy: 0.3143 - val_loss: 1.8245 - val_accuracy: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6583 - accuracy: 0.3129 - val_loss: 1.8147 - val_accuracy: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6565 - accuracy: 0.3300 - val_loss: 1.8280 - val_accuracy: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6570 - accuracy: 0.3143 - val_loss: 1.8193 - val_accuracy: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6548 - accuracy: 0.3214 - val_loss: 1.8124 - val_accuracy: 0.2533\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6547 - accuracy: 0.3229 - val_loss: 1.8202 - val_accuracy: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6545 - accuracy: 0.3200 - val_loss: 1.8133 - val_accuracy: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6524 - accuracy: 0.3143 - val_loss: 1.8317 - val_accuracy: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6514 - accuracy: 0.3214 - val_loss: 1.8226 - val_accuracy: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.6512 - accuracy: 0.3314 - val_loss: 1.8233 - val_accuracy: 0.2267\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6493 - accuracy: 0.3186 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.6483 - accuracy: 0.3214 - val_loss: 1.8191 - val_accuracy: 0.2200\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6488 - accuracy: 0.3257 - val_loss: 1.8199 - val_accuracy: 0.2167\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.6466 - accuracy: 0.3257 - val_loss: 1.8512 - val_accuracy: 0.2433\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6465 - accuracy: 0.3214 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6446 - accuracy: 0.3229 - val_loss: 1.8284 - val_accuracy: 0.2267\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6437 - accuracy: 0.3243 - val_loss: 1.8154 - val_accuracy: 0.2633\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6437 - accuracy: 0.3329 - val_loss: 1.8292 - val_accuracy: 0.2433\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6431 - accuracy: 0.3329 - val_loss: 1.8273 - val_accuracy: 0.2300\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6419 - accuracy: 0.3271 - val_loss: 1.8197 - val_accuracy: 0.2200\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6392 - accuracy: 0.3343 - val_loss: 1.8324 - val_accuracy: 0.2233\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6412 - accuracy: 0.3100 - val_loss: 1.8328 - val_accuracy: 0.2333\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6390 - accuracy: 0.3243 - val_loss: 1.8306 - val_accuracy: 0.2500\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6375 - accuracy: 0.3271 - val_loss: 1.8189 - val_accuracy: 0.2133\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.6367 - accuracy: 0.3229 - val_loss: 1.8276 - val_accuracy: 0.2233\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6364 - accuracy: 0.3257 - val_loss: 1.8245 - val_accuracy: 0.2267\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6350 - accuracy: 0.3214 - val_loss: 1.8290 - val_accuracy: 0.2233\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6340 - accuracy: 0.3400 - val_loss: 1.8270 - val_accuracy: 0.2300\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6319 - accuracy: 0.3457 - val_loss: 1.8343 - val_accuracy: 0.2233\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6316 - accuracy: 0.3243 - val_loss: 1.8183 - val_accuracy: 0.2367\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6326 - accuracy: 0.3329 - val_loss: 1.8309 - val_accuracy: 0.2200\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6308 - accuracy: 0.3300 - val_loss: 1.8241 - val_accuracy: 0.2200\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6308 - accuracy: 0.3343 - val_loss: 1.8329 - val_accuracy: 0.2300\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.6285 - accuracy: 0.3257 - val_loss: 1.8336 - val_accuracy: 0.2433\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6278 - accuracy: 0.3300 - val_loss: 1.8304 - val_accuracy: 0.2233\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6271 - accuracy: 0.3257 - val_loss: 1.8406 - val_accuracy: 0.2300\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6265 - accuracy: 0.3271 - val_loss: 1.8350 - val_accuracy: 0.2267\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6254 - accuracy: 0.3371 - val_loss: 1.8365 - val_accuracy: 0.2300\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6239 - accuracy: 0.3314 - val_loss: 1.8264 - val_accuracy: 0.2100\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6236 - accuracy: 0.3200 - val_loss: 1.8396 - val_accuracy: 0.2367\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6230 - accuracy: 0.3286 - val_loss: 1.8344 - val_accuracy: 0.2233\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6221 - accuracy: 0.3314 - val_loss: 1.8389 - val_accuracy: 0.2633\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6208 - accuracy: 0.3386 - val_loss: 1.8444 - val_accuracy: 0.2200\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6198 - accuracy: 0.3386 - val_loss: 1.8525 - val_accuracy: 0.2233\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6191 - accuracy: 0.3371 - val_loss: 1.8369 - val_accuracy: 0.2233\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6170 - accuracy: 0.3271 - val_loss: 1.8517 - val_accuracy: 0.2600\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6164 - accuracy: 0.3386 - val_loss: 1.8397 - val_accuracy: 0.2133\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.6182 - accuracy: 0.3386 - val_loss: 1.8392 - val_accuracy: 0.2367\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6167 - accuracy: 0.3300 - val_loss: 1.8420 - val_accuracy: 0.2200\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6166 - accuracy: 0.3357 - val_loss: 1.8406 - val_accuracy: 0.2200\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.6143 - accuracy: 0.3229 - val_loss: 1.8437 - val_accuracy: 0.2600\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6134 - accuracy: 0.3371 - val_loss: 1.8384 - val_accuracy: 0.2167\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6139 - accuracy: 0.3371 - val_loss: 1.8446 - val_accuracy: 0.2267\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6134 - accuracy: 0.3400 - val_loss: 1.8376 - val_accuracy: 0.2233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6110 - accuracy: 0.3371 - val_loss: 1.8415 - val_accuracy: 0.2667\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6115 - accuracy: 0.3457 - val_loss: 1.8339 - val_accuracy: 0.2567\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6106 - accuracy: 0.3471 - val_loss: 1.8365 - val_accuracy: 0.2167\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6115 - accuracy: 0.3300 - val_loss: 1.8411 - val_accuracy: 0.2333\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6093 - accuracy: 0.3443 - val_loss: 1.8453 - val_accuracy: 0.2267\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6076 - accuracy: 0.3386 - val_loss: 1.8641 - val_accuracy: 0.2200\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.6086 - accuracy: 0.3443 - val_loss: 1.8449 - val_accuracy: 0.2233\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6065 - accuracy: 0.3543 - val_loss: 1.8442 - val_accuracy: 0.2167\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.6075 - accuracy: 0.3386 - val_loss: 1.8412 - val_accuracy: 0.2133\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6045 - accuracy: 0.3529 - val_loss: 1.8517 - val_accuracy: 0.2233\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6065 - accuracy: 0.3314 - val_loss: 1.8401 - val_accuracy: 0.2300\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6042 - accuracy: 0.3529 - val_loss: 1.8564 - val_accuracy: 0.2233\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6044 - accuracy: 0.3500 - val_loss: 1.8503 - val_accuracy: 0.2200\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.6029 - accuracy: 0.3357 - val_loss: 1.8539 - val_accuracy: 0.2267\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.6025 - accuracy: 0.3414 - val_loss: 1.8470 - val_accuracy: 0.2267\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.6019 - accuracy: 0.3457 - val_loss: 1.8453 - val_accuracy: 0.2467\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.6016 - accuracy: 0.3514 - val_loss: 1.8472 - val_accuracy: 0.2167\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6002 - accuracy: 0.3443 - val_loss: 1.8488 - val_accuracy: 0.2300\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.6005 - accuracy: 0.3386 - val_loss: 1.8591 - val_accuracy: 0.2200\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.6003 - accuracy: 0.3429 - val_loss: 1.8558 - val_accuracy: 0.2200\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.5975 - accuracy: 0.3457 - val_loss: 1.8604 - val_accuracy: 0.2633\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.5986 - accuracy: 0.3457 - val_loss: 1.8469 - val_accuracy: 0.2167\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5979 - accuracy: 0.3414 - val_loss: 1.8478 - val_accuracy: 0.2100\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5965 - accuracy: 0.3343 - val_loss: 1.8562 - val_accuracy: 0.2267\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5953 - accuracy: 0.3557 - val_loss: 1.8461 - val_accuracy: 0.2067\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5953 - accuracy: 0.3429 - val_loss: 1.8508 - val_accuracy: 0.2200\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5946 - accuracy: 0.3500 - val_loss: 1.8463 - val_accuracy: 0.2133\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.5947 - accuracy: 0.3543 - val_loss: 1.8537 - val_accuracy: 0.2233\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.5920 - accuracy: 0.3414 - val_loss: 1.8557 - val_accuracy: 0.2233\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.5919 - accuracy: 0.3514 - val_loss: 1.8521 - val_accuracy: 0.2300\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.5915 - accuracy: 0.3443 - val_loss: 1.8523 - val_accuracy: 0.2267\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5903 - accuracy: 0.3371 - val_loss: 1.8456 - val_accuracy: 0.2567\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5913 - accuracy: 0.3471 - val_loss: 1.8593 - val_accuracy: 0.2200\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5894 - accuracy: 0.3500 - val_loss: 1.8519 - val_accuracy: 0.2233\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5905 - accuracy: 0.3457 - val_loss: 1.8541 - val_accuracy: 0.2267\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5886 - accuracy: 0.3514 - val_loss: 1.8602 - val_accuracy: 0.2667\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5895 - accuracy: 0.3486 - val_loss: 1.8624 - val_accuracy: 0.2267\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5881 - accuracy: 0.3471 - val_loss: 1.8638 - val_accuracy: 0.2300\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5876 - accuracy: 0.3486 - val_loss: 1.8600 - val_accuracy: 0.2300\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5865 - accuracy: 0.3500 - val_loss: 1.8659 - val_accuracy: 0.2267\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5855 - accuracy: 0.3514 - val_loss: 1.8581 - val_accuracy: 0.2267\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5855 - accuracy: 0.3471 - val_loss: 1.8621 - val_accuracy: 0.2267\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5845 - accuracy: 0.3514 - val_loss: 1.8751 - val_accuracy: 0.2500\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5844 - accuracy: 0.3443 - val_loss: 1.8615 - val_accuracy: 0.2600\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5845 - accuracy: 0.3529 - val_loss: 1.8766 - val_accuracy: 0.2467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5833 - accuracy: 0.3457 - val_loss: 1.8572 - val_accuracy: 0.2167\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.5835 - accuracy: 0.3486 - val_loss: 1.8686 - val_accuracy: 0.2233\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5825 - accuracy: 0.3486 - val_loss: 1.8611 - val_accuracy: 0.2133\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.5825 - accuracy: 0.3443 - val_loss: 1.8693 - val_accuracy: 0.2267\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5801 - accuracy: 0.3471 - val_loss: 1.8688 - val_accuracy: 0.2233\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5818 - accuracy: 0.3471 - val_loss: 1.8635 - val_accuracy: 0.2133\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5797 - accuracy: 0.3529 - val_loss: 1.8605 - val_accuracy: 0.2200\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5809 - accuracy: 0.3514 - val_loss: 1.8730 - val_accuracy: 0.2133\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5796 - accuracy: 0.3486 - val_loss: 1.8781 - val_accuracy: 0.2200\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5791 - accuracy: 0.3457 - val_loss: 1.8666 - val_accuracy: 0.2133\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5777 - accuracy: 0.3571 - val_loss: 1.8693 - val_accuracy: 0.2100\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5778 - accuracy: 0.3443 - val_loss: 1.8664 - val_accuracy: 0.2133\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5770 - accuracy: 0.3429 - val_loss: 1.8718 - val_accuracy: 0.2300\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5774 - accuracy: 0.3471 - val_loss: 1.8613 - val_accuracy: 0.2200\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5770 - accuracy: 0.3571 - val_loss: 1.8682 - val_accuracy: 0.2267\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8719 - val_accuracy: 0.2500\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8738 - val_accuracy: 0.2433\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5743 - accuracy: 0.3514 - val_loss: 1.8733 - val_accuracy: 0.2100\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5743 - accuracy: 0.3629 - val_loss: 1.8806 - val_accuracy: 0.2200\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5713 - accuracy: 0.3557 - val_loss: 1.8724 - val_accuracy: 0.2200\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5715 - accuracy: 0.3586 - val_loss: 1.8838 - val_accuracy: 0.2233\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5712 - accuracy: 0.3543 - val_loss: 1.8710 - val_accuracy: 0.2533\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5722 - accuracy: 0.3557 - val_loss: 1.8631 - val_accuracy: 0.2167\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5716 - accuracy: 0.3557 - val_loss: 1.8700 - val_accuracy: 0.2233\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5712 - accuracy: 0.3471 - val_loss: 1.8840 - val_accuracy: 0.2233\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5680 - accuracy: 0.3657 - val_loss: 1.8981 - val_accuracy: 0.2167\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5704 - accuracy: 0.3486 - val_loss: 1.8793 - val_accuracy: 0.2400\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5682 - accuracy: 0.3643 - val_loss: 1.8744 - val_accuracy: 0.2200\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5689 - accuracy: 0.3586 - val_loss: 1.8820 - val_accuracy: 0.2133\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5677 - accuracy: 0.3571 - val_loss: 1.8835 - val_accuracy: 0.2267\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5681 - accuracy: 0.3457 - val_loss: 1.8713 - val_accuracy: 0.2267\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5657 - accuracy: 0.3571 - val_loss: 1.8761 - val_accuracy: 0.2533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5667 - accuracy: 0.3514 - val_loss: 1.8912 - val_accuracy: 0.2467\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5649 - accuracy: 0.3614 - val_loss: 1.8946 - val_accuracy: 0.2567\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5648 - accuracy: 0.3643 - val_loss: 1.8911 - val_accuracy: 0.2167\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5657 - accuracy: 0.3600 - val_loss: 1.8989 - val_accuracy: 0.2200\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5637 - accuracy: 0.3571 - val_loss: 1.8751 - val_accuracy: 0.2167\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.5638 - accuracy: 0.3614 - val_loss: 1.8836 - val_accuracy: 0.2100\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5631 - accuracy: 0.3629 - val_loss: 1.8858 - val_accuracy: 0.2100\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5640 - accuracy: 0.3571 - val_loss: 1.8812 - val_accuracy: 0.2133\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5638 - accuracy: 0.3686 - val_loss: 1.8902 - val_accuracy: 0.2200\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5614 - accuracy: 0.3614 - val_loss: 1.8968 - val_accuracy: 0.2500\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5612 - accuracy: 0.3629 - val_loss: 1.8918 - val_accuracy: 0.2300\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5613 - accuracy: 0.3614 - val_loss: 1.8757 - val_accuracy: 0.2100\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5601 - accuracy: 0.3643 - val_loss: 1.8854 - val_accuracy: 0.2133\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5594 - accuracy: 0.3671 - val_loss: 1.8674 - val_accuracy: 0.2333\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5610 - accuracy: 0.3657 - val_loss: 1.8914 - val_accuracy: 0.2333\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5595 - accuracy: 0.3600 - val_loss: 1.9030 - val_accuracy: 0.2267\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5591 - accuracy: 0.3571 - val_loss: 1.8964 - val_accuracy: 0.2200\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5589 - accuracy: 0.3457 - val_loss: 1.8841 - val_accuracy: 0.2233\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5589 - accuracy: 0.3629 - val_loss: 1.8914 - val_accuracy: 0.2200\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.5579 - accuracy: 0.3529 - val_loss: 1.8967 - val_accuracy: 0.2533\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5581 - accuracy: 0.3714 - val_loss: 1.8909 - val_accuracy: 0.2167\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5578 - accuracy: 0.3600 - val_loss: 1.9032 - val_accuracy: 0.2300\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5559 - accuracy: 0.3571 - val_loss: 1.8859 - val_accuracy: 0.2167\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5559 - accuracy: 0.3700 - val_loss: 1.8876 - val_accuracy: 0.2167\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5541 - accuracy: 0.3586 - val_loss: 1.8906 - val_accuracy: 0.2333\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5553 - accuracy: 0.3671 - val_loss: 1.8840 - val_accuracy: 0.2133\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5543 - accuracy: 0.3557 - val_loss: 1.8927 - val_accuracy: 0.2167\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5542 - accuracy: 0.3614 - val_loss: 1.8936 - val_accuracy: 0.2567\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5535 - accuracy: 0.3557 - val_loss: 1.8887 - val_accuracy: 0.2200\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5536 - accuracy: 0.3586 - val_loss: 1.8989 - val_accuracy: 0.2233\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5527 - accuracy: 0.3686 - val_loss: 1.9019 - val_accuracy: 0.2133\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5525 - accuracy: 0.3600 - val_loss: 1.8930 - val_accuracy: 0.2133\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5519 - accuracy: 0.3600 - val_loss: 1.9014 - val_accuracy: 0.2167\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5514 - accuracy: 0.3657 - val_loss: 1.9032 - val_accuracy: 0.2200\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5513 - accuracy: 0.3586 - val_loss: 1.9037 - val_accuracy: 0.2167\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5509 - accuracy: 0.3543 - val_loss: 1.8995 - val_accuracy: 0.2433\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5507 - accuracy: 0.3543 - val_loss: 1.9011 - val_accuracy: 0.2300\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5497 - accuracy: 0.3543 - val_loss: 1.9002 - val_accuracy: 0.2567\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5499 - accuracy: 0.3657 - val_loss: 1.9120 - val_accuracy: 0.2200\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5495 - accuracy: 0.3571 - val_loss: 1.9104 - val_accuracy: 0.2133\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5479 - accuracy: 0.3571 - val_loss: 1.9128 - val_accuracy: 0.2167\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5477 - accuracy: 0.3486 - val_loss: 1.8958 - val_accuracy: 0.2267\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.9820 - accuracy: 0.20 - 0s 61us/step - loss: 1.5485 - accuracy: 0.3686 - val_loss: 1.9145 - val_accuracy: 0.2267\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5472 - accuracy: 0.3629 - val_loss: 1.9031 - val_accuracy: 0.2300\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5469 - accuracy: 0.3629 - val_loss: 1.8934 - val_accuracy: 0.2200\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5479 - accuracy: 0.3657 - val_loss: 1.9081 - val_accuracy: 0.2167\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5464 - accuracy: 0.3529 - val_loss: 1.9016 - val_accuracy: 0.2333\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5452 - accuracy: 0.3671 - val_loss: 1.9066 - val_accuracy: 0.2200\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5432 - accuracy: 0.3643 - val_loss: 1.9140 - val_accuracy: 0.2267\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5458 - accuracy: 0.3600 - val_loss: 1.9100 - val_accuracy: 0.2233\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5436 - accuracy: 0.3671 - val_loss: 1.9064 - val_accuracy: 0.2267\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5453 - accuracy: 0.3600 - val_loss: 1.9129 - val_accuracy: 0.2333\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5435 - accuracy: 0.3643 - val_loss: 1.9120 - val_accuracy: 0.2367\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5448 - accuracy: 0.3671 - val_loss: 1.9110 - val_accuracy: 0.2167\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5426 - accuracy: 0.3586 - val_loss: 1.9058 - val_accuracy: 0.2300\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5423 - accuracy: 0.3729 - val_loss: 1.9273 - val_accuracy: 0.2367\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5387 - accuracy: 0.3657 - val_loss: 1.9056 - val_accuracy: 0.2633\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5433 - accuracy: 0.3686 - val_loss: 1.9131 - val_accuracy: 0.2300\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5406 - accuracy: 0.3657 - val_loss: 1.9118 - val_accuracy: 0.2233\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5404 - accuracy: 0.3614 - val_loss: 1.9141 - val_accuracy: 0.2233\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5412 - accuracy: 0.3614 - val_loss: 1.9213 - val_accuracy: 0.2333\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5408 - accuracy: 0.3614 - val_loss: 1.9096 - val_accuracy: 0.2300\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.6970 - accuracy: 0.30 - 0s 61us/step - loss: 1.5390 - accuracy: 0.3614 - val_loss: 1.9092 - val_accuracy: 0.2300\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5392 - accuracy: 0.3629 - val_loss: 1.9278 - val_accuracy: 0.2233\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5392 - accuracy: 0.3686 - val_loss: 1.9258 - val_accuracy: 0.2300\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5375 - accuracy: 0.3671 - val_loss: 1.9181 - val_accuracy: 0.2533\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5383 - accuracy: 0.3714 - val_loss: 1.9197 - val_accuracy: 0.2300\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5373 - accuracy: 0.3657 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5387 - accuracy: 0.3600 - val_loss: 1.9178 - val_accuracy: 0.2133\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5365 - accuracy: 0.3614 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5359 - accuracy: 0.3743 - val_loss: 1.9378 - val_accuracy: 0.2333\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5366 - accuracy: 0.3657 - val_loss: 1.9307 - val_accuracy: 0.2233\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5354 - accuracy: 0.3714 - val_loss: 1.9147 - val_accuracy: 0.2300\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5351 - accuracy: 0.3600 - val_loss: 1.9222 - val_accuracy: 0.2333\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5338 - accuracy: 0.3714 - val_loss: 1.9155 - val_accuracy: 0.2200\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5346 - accuracy: 0.3571 - val_loss: 1.9340 - val_accuracy: 0.2500\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5358 - accuracy: 0.3671 - val_loss: 1.9234 - val_accuracy: 0.2233\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5349 - accuracy: 0.3629 - val_loss: 1.9289 - val_accuracy: 0.2233\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5327 - accuracy: 0.3757 - val_loss: 1.9246 - val_accuracy: 0.2567\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5335 - accuracy: 0.3786 - val_loss: 1.9184 - val_accuracy: 0.2300\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5330 - accuracy: 0.3757 - val_loss: 1.9324 - val_accuracy: 0.2300\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5320 - accuracy: 0.3743 - val_loss: 1.9238 - val_accuracy: 0.2133\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5314 - accuracy: 0.3700 - val_loss: 1.9157 - val_accuracy: 0.2167\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5328 - accuracy: 0.3729 - val_loss: 1.9403 - val_accuracy: 0.2267\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5317 - accuracy: 0.3757 - val_loss: 1.9258 - val_accuracy: 0.2267\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5313 - accuracy: 0.3600 - val_loss: 1.9441 - val_accuracy: 0.2167\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5310 - accuracy: 0.3686 - val_loss: 1.9333 - val_accuracy: 0.2267\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5308 - accuracy: 0.3671 - val_loss: 1.9431 - val_accuracy: 0.2300\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5291 - accuracy: 0.3686 - val_loss: 1.9443 - val_accuracy: 0.2567\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5301 - accuracy: 0.3700 - val_loss: 1.9314 - val_accuracy: 0.2267\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5277 - accuracy: 0.3800 - val_loss: 1.9199 - val_accuracy: 0.2200\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5284 - accuracy: 0.3643 - val_loss: 1.9294 - val_accuracy: 0.2167\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5281 - accuracy: 0.3700 - val_loss: 1.9273 - val_accuracy: 0.2133\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5282 - accuracy: 0.3657 - val_loss: 1.9311 - val_accuracy: 0.2300\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5264 - accuracy: 0.3757 - val_loss: 1.9309 - val_accuracy: 0.2333\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5283 - accuracy: 0.3729 - val_loss: 1.9282 - val_accuracy: 0.2300\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5256 - accuracy: 0.3657 - val_loss: 1.9422 - val_accuracy: 0.2300\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5279 - accuracy: 0.3700 - val_loss: 1.9350 - val_accuracy: 0.2167\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5261 - accuracy: 0.3600 - val_loss: 1.9553 - val_accuracy: 0.2267\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5260 - accuracy: 0.3700 - val_loss: 1.9442 - val_accuracy: 0.2433\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5259 - accuracy: 0.3743 - val_loss: 1.9355 - val_accuracy: 0.2267\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9494 - val_accuracy: 0.2233\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9450 - val_accuracy: 0.2133\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5232 - accuracy: 0.3743 - val_loss: 1.9454 - val_accuracy: 0.2233\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5232 - accuracy: 0.3686 - val_loss: 1.9485 - val_accuracy: 0.2300\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5240 - accuracy: 0.3643 - val_loss: 1.9508 - val_accuracy: 0.2267\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5215 - accuracy: 0.3757 - val_loss: 1.9527 - val_accuracy: 0.2333\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5230 - accuracy: 0.3643 - val_loss: 1.9381 - val_accuracy: 0.2300\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5224 - accuracy: 0.3771 - val_loss: 1.9524 - val_accuracy: 0.2267\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5222 - accuracy: 0.3686 - val_loss: 1.9406 - val_accuracy: 0.2133\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5221 - accuracy: 0.3757 - val_loss: 1.9567 - val_accuracy: 0.2300\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5206 - accuracy: 0.3786 - val_loss: 1.9551 - val_accuracy: 0.2367\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5207 - accuracy: 0.3629 - val_loss: 1.9321 - val_accuracy: 0.2367\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5200 - accuracy: 0.3757 - val_loss: 1.9534 - val_accuracy: 0.2400\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5209 - accuracy: 0.3671 - val_loss: 1.9508 - val_accuracy: 0.2233\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5195 - accuracy: 0.3729 - val_loss: 1.9590 - val_accuracy: 0.2333\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5205 - accuracy: 0.3757 - val_loss: 1.9453 - val_accuracy: 0.2133\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5197 - accuracy: 0.3686 - val_loss: 1.9514 - val_accuracy: 0.2267\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5181 - accuracy: 0.3843 - val_loss: 1.9386 - val_accuracy: 0.2267\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5182 - accuracy: 0.3800 - val_loss: 1.9487 - val_accuracy: 0.2167\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5170 - accuracy: 0.3743 - val_loss: 1.9760 - val_accuracy: 0.2267\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.5182 - accuracy: 0.3743 - val_loss: 1.9761 - val_accuracy: 0.2367\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5188 - accuracy: 0.3700 - val_loss: 1.9516 - val_accuracy: 0.2367\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.5166 - accuracy: 0.3671 - val_loss: 1.9602 - val_accuracy: 0.2567\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5180 - accuracy: 0.3786 - val_loss: 1.9711 - val_accuracy: 0.2167\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5161 - accuracy: 0.3743 - val_loss: 1.9585 - val_accuracy: 0.2267\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5155 - accuracy: 0.3700 - val_loss: 1.9714 - val_accuracy: 0.2433\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5164 - accuracy: 0.3771 - val_loss: 1.9509 - val_accuracy: 0.2233\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.5163 - accuracy: 0.3743 - val_loss: 1.9579 - val_accuracy: 0.2267\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5156 - accuracy: 0.3714 - val_loss: 1.9502 - val_accuracy: 0.2333\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5153 - accuracy: 0.3743 - val_loss: 1.9578 - val_accuracy: 0.2300\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5143 - accuracy: 0.3714 - val_loss: 1.9668 - val_accuracy: 0.2467\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5158 - accuracy: 0.3800 - val_loss: 1.9490 - val_accuracy: 0.2267\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5125 - accuracy: 0.3671 - val_loss: 1.9572 - val_accuracy: 0.2400\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5132 - accuracy: 0.3757 - val_loss: 1.9539 - val_accuracy: 0.2367\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5137 - accuracy: 0.3714 - val_loss: 1.9599 - val_accuracy: 0.2233\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5137 - accuracy: 0.3757 - val_loss: 1.9730 - val_accuracy: 0.2233\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5136 - accuracy: 0.3757 - val_loss: 1.9565 - val_accuracy: 0.2267\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5132 - accuracy: 0.3771 - val_loss: 1.9565 - val_accuracy: 0.2167\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5124 - accuracy: 0.3771 - val_loss: 1.9619 - val_accuracy: 0.2167\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5111 - accuracy: 0.3857 - val_loss: 1.9755 - val_accuracy: 0.2367\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5124 - accuracy: 0.3643 - val_loss: 1.9588 - val_accuracy: 0.2200\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5107 - accuracy: 0.3743 - val_loss: 1.9904 - val_accuracy: 0.2333\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5113 - accuracy: 0.3643 - val_loss: 1.9599 - val_accuracy: 0.2167\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5109 - accuracy: 0.3657 - val_loss: 1.9595 - val_accuracy: 0.2267\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5086 - accuracy: 0.3771 - val_loss: 1.9650 - val_accuracy: 0.2233\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.5068 - accuracy: 0.3843 - val_loss: 1.9968 - val_accuracy: 0.2200\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5085 - accuracy: 0.3743 - val_loss: 1.9680 - val_accuracy: 0.2333\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5074 - accuracy: 0.3800 - val_loss: 1.9833 - val_accuracy: 0.2300\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5085 - accuracy: 0.3771 - val_loss: 1.9756 - val_accuracy: 0.2200\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5080 - accuracy: 0.3714 - val_loss: 1.9815 - val_accuracy: 0.2267\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5077 - accuracy: 0.3757 - val_loss: 1.9711 - val_accuracy: 0.2267\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5040 - accuracy: 0.3700 - val_loss: 1.9807 - val_accuracy: 0.2367\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5058 - accuracy: 0.3771 - val_loss: 1.9611 - val_accuracy: 0.2267\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5056 - accuracy: 0.3714 - val_loss: 1.9846 - val_accuracy: 0.2300\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5048 - accuracy: 0.3843 - val_loss: 1.9728 - val_accuracy: 0.2233\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5033 - accuracy: 0.3771 - val_loss: 1.9781 - val_accuracy: 0.2333\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5043 - accuracy: 0.3786 - val_loss: 1.9881 - val_accuracy: 0.2333\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.5015 - accuracy: 0.3786 - val_loss: 1.9798 - val_accuracy: 0.2333\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5031 - accuracy: 0.3843 - val_loss: 1.9929 - val_accuracy: 0.2267\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.5032 - accuracy: 0.3786 - val_loss: 1.9828 - val_accuracy: 0.2200\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5016 - accuracy: 0.3871 - val_loss: 1.9756 - val_accuracy: 0.2333\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5019 - accuracy: 0.3786 - val_loss: 1.9663 - val_accuracy: 0.2200\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5015 - accuracy: 0.3800 - val_loss: 1.9912 - val_accuracy: 0.2300\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.5011 - accuracy: 0.3829 - val_loss: 1.9693 - val_accuracy: 0.2433\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.5004 - accuracy: 0.3743 - val_loss: 1.9759 - val_accuracy: 0.2433\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5003 - accuracy: 0.3814 - val_loss: 1.9815 - val_accuracy: 0.2333\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.5001 - accuracy: 0.3757 - val_loss: 1.9681 - val_accuracy: 0.2200\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4991 - accuracy: 0.3886 - val_loss: 1.9619 - val_accuracy: 0.2400\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4984 - accuracy: 0.3914 - val_loss: 1.9803 - val_accuracy: 0.2167\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4983 - accuracy: 0.3814 - val_loss: 1.9858 - val_accuracy: 0.2533\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4984 - accuracy: 0.3843 - val_loss: 2.0113 - val_accuracy: 0.2300\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4982 - accuracy: 0.3771 - val_loss: 1.9701 - val_accuracy: 0.2300\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4977 - accuracy: 0.3814 - val_loss: 1.9836 - val_accuracy: 0.2467\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4990 - accuracy: 0.3786 - val_loss: 1.9920 - val_accuracy: 0.2333\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4974 - accuracy: 0.3843 - val_loss: 1.9780 - val_accuracy: 0.2233\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4967 - accuracy: 0.3814 - val_loss: 1.9880 - val_accuracy: 0.2367\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4976 - accuracy: 0.3743 - val_loss: 1.9917 - val_accuracy: 0.2233\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4957 - accuracy: 0.3900 - val_loss: 1.9837 - val_accuracy: 0.2267\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4975 - accuracy: 0.3843 - val_loss: 1.9691 - val_accuracy: 0.2233\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4957 - accuracy: 0.3943 - val_loss: 1.9995 - val_accuracy: 0.2200\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4948 - accuracy: 0.3857 - val_loss: 1.9635 - val_accuracy: 0.2300\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4946 - accuracy: 0.3771 - val_loss: 1.9794 - val_accuracy: 0.2233\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4960 - accuracy: 0.3800 - val_loss: 1.9815 - val_accuracy: 0.2300\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4951 - accuracy: 0.3886 - val_loss: 1.9841 - val_accuracy: 0.2300\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4944 - accuracy: 0.3829 - val_loss: 1.9982 - val_accuracy: 0.2233\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4937 - accuracy: 0.3857 - val_loss: 1.9936 - val_accuracy: 0.2400\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4946 - accuracy: 0.3829 - val_loss: 1.9965 - val_accuracy: 0.2233\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4942 - accuracy: 0.3829 - val_loss: 2.0001 - val_accuracy: 0.2300\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4931 - accuracy: 0.3886 - val_loss: 2.0088 - val_accuracy: 0.2267\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4926 - accuracy: 0.3800 - val_loss: 2.0223 - val_accuracy: 0.2300\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4927 - accuracy: 0.3843 - val_loss: 1.9971 - val_accuracy: 0.2267\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4918 - accuracy: 0.3886 - val_loss: 2.0059 - val_accuracy: 0.2333\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4929 - accuracy: 0.3843 - val_loss: 1.9975 - val_accuracy: 0.2233\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4919 - accuracy: 0.3843 - val_loss: 2.0043 - val_accuracy: 0.2233\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4908 - accuracy: 0.3857 - val_loss: 1.9997 - val_accuracy: 0.2300\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4910 - accuracy: 0.3871 - val_loss: 1.9943 - val_accuracy: 0.2333\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4908 - accuracy: 0.3871 - val_loss: 2.0016 - val_accuracy: 0.2333\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4907 - accuracy: 0.3843 - val_loss: 1.9913 - val_accuracy: 0.2233\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4898 - accuracy: 0.3786 - val_loss: 1.9959 - val_accuracy: 0.2467\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4899 - accuracy: 0.3871 - val_loss: 2.0019 - val_accuracy: 0.2333\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4902 - accuracy: 0.3857 - val_loss: 1.9970 - val_accuracy: 0.2267\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4881 - accuracy: 0.3943 - val_loss: 1.9948 - val_accuracy: 0.2433\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4900 - accuracy: 0.3886 - val_loss: 2.0062 - val_accuracy: 0.2300\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4883 - accuracy: 0.3957 - val_loss: 2.0089 - val_accuracy: 0.2300\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4883 - accuracy: 0.3900 - val_loss: 1.9980 - val_accuracy: 0.2267\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4872 - accuracy: 0.3857 - val_loss: 2.0059 - val_accuracy: 0.2467\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 1.9923 - val_accuracy: 0.2333\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4877 - accuracy: 0.3900 - val_loss: 2.0023 - val_accuracy: 0.2233\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4871 - accuracy: 0.3757 - val_loss: 2.0065 - val_accuracy: 0.2267\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4873 - accuracy: 0.3871 - val_loss: 2.0133 - val_accuracy: 0.2300\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4865 - accuracy: 0.3829 - val_loss: 1.9941 - val_accuracy: 0.2267\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4859 - accuracy: 0.3871 - val_loss: 2.0429 - val_accuracy: 0.2333\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 2.0173 - val_accuracy: 0.2233\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4859 - accuracy: 0.3957 - val_loss: 2.0124 - val_accuracy: 0.2267\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4845 - accuracy: 0.3971 - val_loss: 2.0157 - val_accuracy: 0.2367\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4850 - accuracy: 0.3914 - val_loss: 2.0205 - val_accuracy: 0.2367\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4838 - accuracy: 0.3900 - val_loss: 2.0030 - val_accuracy: 0.2267\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4842 - accuracy: 0.3900 - val_loss: 2.0116 - val_accuracy: 0.2233\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4835 - accuracy: 0.3900 - val_loss: 2.0127 - val_accuracy: 0.2267\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4839 - accuracy: 0.3900 - val_loss: 2.0173 - val_accuracy: 0.2267\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4838 - accuracy: 0.3929 - val_loss: 2.0124 - val_accuracy: 0.2333\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4833 - accuracy: 0.3900 - val_loss: 2.0080 - val_accuracy: 0.2300\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4824 - accuracy: 0.3957 - val_loss: 2.0183 - val_accuracy: 0.2367\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4821 - accuracy: 0.3871 - val_loss: 2.0288 - val_accuracy: 0.2400\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.4810 - accuracy: 0.3986 - val_loss: 2.0248 - val_accuracy: 0.2300\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4821 - accuracy: 0.4000 - val_loss: 2.0233 - val_accuracy: 0.2367\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4815 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2400\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4811 - accuracy: 0.4029 - val_loss: 2.0243 - val_accuracy: 0.2300\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4808 - accuracy: 0.3857 - val_loss: 2.0156 - val_accuracy: 0.2467\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4811 - accuracy: 0.3957 - val_loss: 2.0159 - val_accuracy: 0.2500\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4808 - accuracy: 0.3914 - val_loss: 2.0247 - val_accuracy: 0.2500\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4804 - accuracy: 0.3886 - val_loss: 2.0107 - val_accuracy: 0.2267\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4809 - accuracy: 0.3900 - val_loss: 2.0066 - val_accuracy: 0.2333\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4808 - accuracy: 0.3871 - val_loss: 2.0321 - val_accuracy: 0.2300\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4800 - accuracy: 0.3914 - val_loss: 2.0072 - val_accuracy: 0.2267\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4799 - accuracy: 0.4014 - val_loss: 2.0164 - val_accuracy: 0.2333\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4802 - accuracy: 0.3900 - val_loss: 2.0155 - val_accuracy: 0.2233\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4792 - accuracy: 0.4029 - val_loss: 2.0383 - val_accuracy: 0.2333\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4786 - accuracy: 0.3857 - val_loss: 2.0199 - val_accuracy: 0.2433\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4773 - accuracy: 0.3929 - val_loss: 2.0210 - val_accuracy: 0.2467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4763 - accuracy: 0.3886 - val_loss: 2.0652 - val_accuracy: 0.2367\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4775 - accuracy: 0.4014 - val_loss: 2.0415 - val_accuracy: 0.2367\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4780 - accuracy: 0.3929 - val_loss: 2.0389 - val_accuracy: 0.2367\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4782 - accuracy: 0.4000 - val_loss: 2.0378 - val_accuracy: 0.2300\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4760 - accuracy: 0.3943 - val_loss: 2.0391 - val_accuracy: 0.2267\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4766 - accuracy: 0.3957 - val_loss: 2.0315 - val_accuracy: 0.2267\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4757 - accuracy: 0.3971 - val_loss: 2.0373 - val_accuracy: 0.2267\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4754 - accuracy: 0.3957 - val_loss: 2.0319 - val_accuracy: 0.2400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4754 - accuracy: 0.3986 - val_loss: 2.0256 - val_accuracy: 0.2300\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4769 - accuracy: 0.3986 - val_loss: 2.0355 - val_accuracy: 0.2233\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4750 - accuracy: 0.3900 - val_loss: 2.0376 - val_accuracy: 0.2267\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4744 - accuracy: 0.3943 - val_loss: 2.0544 - val_accuracy: 0.2333\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4745 - accuracy: 0.3914 - val_loss: 2.0370 - val_accuracy: 0.2233\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4737 - accuracy: 0.4029 - val_loss: 2.0263 - val_accuracy: 0.2267\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4739 - accuracy: 0.3971 - val_loss: 2.0206 - val_accuracy: 0.2467\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4732 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2433\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4727 - accuracy: 0.4000 - val_loss: 2.0425 - val_accuracy: 0.2267\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4734 - accuracy: 0.4014 - val_loss: 2.0394 - val_accuracy: 0.2300\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4741 - accuracy: 0.3957 - val_loss: 2.0433 - val_accuracy: 0.2267\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4706 - accuracy: 0.3929 - val_loss: 2.0516 - val_accuracy: 0.2500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4740 - accuracy: 0.4000 - val_loss: 2.0528 - val_accuracy: 0.2267\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4727 - accuracy: 0.4043 - val_loss: 2.0387 - val_accuracy: 0.2300\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4718 - accuracy: 0.3957 - val_loss: 2.0482 - val_accuracy: 0.2400\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4713 - accuracy: 0.4129 - val_loss: 2.0242 - val_accuracy: 0.2333\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4725 - accuracy: 0.3986 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4721 - accuracy: 0.3929 - val_loss: 2.0464 - val_accuracy: 0.2267\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 2.0381 - val_accuracy: 0.2333\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4696 - accuracy: 0.4000 - val_loss: 2.0453 - val_accuracy: 0.2467\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4711 - accuracy: 0.4029 - val_loss: 2.0409 - val_accuracy: 0.2267\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4702 - accuracy: 0.3929 - val_loss: 2.0426 - val_accuracy: 0.2300\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4694 - accuracy: 0.4029 - val_loss: 2.0468 - val_accuracy: 0.2267\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4681 - accuracy: 0.3943 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4686 - accuracy: 0.4000 - val_loss: 2.0623 - val_accuracy: 0.2267\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4689 - accuracy: 0.3957 - val_loss: 2.0410 - val_accuracy: 0.2433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4690 - accuracy: 0.4014 - val_loss: 2.0542 - val_accuracy: 0.2433\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.4685 - accuracy: 0.4000 - val_loss: 2.0491 - val_accuracy: 0.2300\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4688 - accuracy: 0.3971 - val_loss: 2.0431 - val_accuracy: 0.2300\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4673 - accuracy: 0.4043 - val_loss: 2.0739 - val_accuracy: 0.2433\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4671 - accuracy: 0.4043 - val_loss: 2.0705 - val_accuracy: 0.2267\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.4676 - accuracy: 0.4029 - val_loss: 2.0477 - val_accuracy: 0.2300\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.4672 - accuracy: 0.3957 - val_loss: 2.0574 - val_accuracy: 0.2367\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.4691 - accuracy: 0.3943 - val_loss: 2.0508 - val_accuracy: 0.2267\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4678 - accuracy: 0.4014 - val_loss: 2.0620 - val_accuracy: 0.2267\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4667 - accuracy: 0.4014 - val_loss: 2.0590 - val_accuracy: 0.2267\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4665 - accuracy: 0.4057 - val_loss: 2.0668 - val_accuracy: 0.2433\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4670 - accuracy: 0.4000 - val_loss: 2.0490 - val_accuracy: 0.2333\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4657 - accuracy: 0.3943 - val_loss: 2.0425 - val_accuracy: 0.2367\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4665 - accuracy: 0.4014 - val_loss: 2.0537 - val_accuracy: 0.2300\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4635 - accuracy: 0.4000 - val_loss: 2.0713 - val_accuracy: 0.2533\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4657 - accuracy: 0.4000 - val_loss: 2.0779 - val_accuracy: 0.2400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4643 - accuracy: 0.3971 - val_loss: 2.0494 - val_accuracy: 0.2300\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4647 - accuracy: 0.4043 - val_loss: 2.0443 - val_accuracy: 0.2333\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4638 - accuracy: 0.4000 - val_loss: 2.0608 - val_accuracy: 0.2300\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4647 - accuracy: 0.4000 - val_loss: 2.0584 - val_accuracy: 0.2300\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4632 - accuracy: 0.4086 - val_loss: 2.0582 - val_accuracy: 0.2333\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4654 - accuracy: 0.4000 - val_loss: 2.0563 - val_accuracy: 0.2300\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4630 - accuracy: 0.3986 - val_loss: 2.0678 - val_accuracy: 0.2300\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4637 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2400\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4621 - accuracy: 0.4000 - val_loss: 2.0621 - val_accuracy: 0.2467\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4614 - accuracy: 0.4114 - val_loss: 2.0831 - val_accuracy: 0.2500\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4631 - accuracy: 0.4029 - val_loss: 2.0614 - val_accuracy: 0.2333\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4614 - accuracy: 0.4029 - val_loss: 2.0657 - val_accuracy: 0.2533\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4612 - accuracy: 0.4014 - val_loss: 2.0698 - val_accuracy: 0.2567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4623 - accuracy: 0.4100 - val_loss: 2.0637 - val_accuracy: 0.2267\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4619 - accuracy: 0.4029 - val_loss: 2.0546 - val_accuracy: 0.2300\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4613 - accuracy: 0.4000 - val_loss: 2.0600 - val_accuracy: 0.2267\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4611 - accuracy: 0.4071 - val_loss: 2.0795 - val_accuracy: 0.2300\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4603 - accuracy: 0.4043 - val_loss: 2.0619 - val_accuracy: 0.2333\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4620 - accuracy: 0.4100 - val_loss: 2.0743 - val_accuracy: 0.2300\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4599 - accuracy: 0.4171 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4598 - accuracy: 0.4057 - val_loss: 2.0765 - val_accuracy: 0.2433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4594 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4586 - accuracy: 0.4114 - val_loss: 2.0794 - val_accuracy: 0.2333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4588 - accuracy: 0.4043 - val_loss: 2.0763 - val_accuracy: 0.2300\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4580 - accuracy: 0.4014 - val_loss: 2.0652 - val_accuracy: 0.2333\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0851 - val_accuracy: 0.2533\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4597 - accuracy: 0.4043 - val_loss: 2.0670 - val_accuracy: 0.2500\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4597 - accuracy: 0.4114 - val_loss: 2.0723 - val_accuracy: 0.2267\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4586 - accuracy: 0.3957 - val_loss: 2.0748 - val_accuracy: 0.2300\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4583 - accuracy: 0.4014 - val_loss: 2.0725 - val_accuracy: 0.2300\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 57us/step - loss: 1.4577 - accuracy: 0.4071 - val_loss: 2.0727 - val_accuracy: 0.2367\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4584 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2267\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4574 - accuracy: 0.4086 - val_loss: 2.0834 - val_accuracy: 0.2367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4570 - accuracy: 0.4071 - val_loss: 2.0783 - val_accuracy: 0.2567\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4569 - accuracy: 0.4071 - val_loss: 2.0819 - val_accuracy: 0.2267\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4563 - accuracy: 0.4014 - val_loss: 2.0840 - val_accuracy: 0.2267\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4571 - accuracy: 0.4071 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4558 - accuracy: 0.4100 - val_loss: 2.0865 - val_accuracy: 0.2300\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4549 - accuracy: 0.4043 - val_loss: 2.0878 - val_accuracy: 0.2500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0871 - val_accuracy: 0.2333\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4560 - accuracy: 0.4043 - val_loss: 2.0902 - val_accuracy: 0.2300\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4553 - accuracy: 0.4057 - val_loss: 2.0906 - val_accuracy: 0.2267\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4553 - accuracy: 0.4014 - val_loss: 2.0836 - val_accuracy: 0.2300\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4554 - accuracy: 0.4086 - val_loss: 2.0946 - val_accuracy: 0.2267\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4544 - accuracy: 0.4086 - val_loss: 2.0885 - val_accuracy: 0.2333\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4546 - accuracy: 0.4057 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4540 - accuracy: 0.4129 - val_loss: 2.0828 - val_accuracy: 0.2333\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4543 - accuracy: 0.4057 - val_loss: 2.0905 - val_accuracy: 0.2433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4537 - accuracy: 0.4129 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0808 - val_accuracy: 0.2500\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4537 - accuracy: 0.3986 - val_loss: 2.0903 - val_accuracy: 0.2267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4541 - accuracy: 0.4043 - val_loss: 2.0796 - val_accuracy: 0.2333\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0989 - val_accuracy: 0.2300\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4523 - accuracy: 0.4129 - val_loss: 2.0981 - val_accuracy: 0.2433\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4526 - accuracy: 0.4029 - val_loss: 2.0933 - val_accuracy: 0.2333\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4527 - accuracy: 0.4114 - val_loss: 2.0824 - val_accuracy: 0.2400\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4525 - accuracy: 0.4029 - val_loss: 2.0809 - val_accuracy: 0.2433\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4516 - accuracy: 0.4057 - val_loss: 2.0888 - val_accuracy: 0.2367\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4517 - accuracy: 0.4100 - val_loss: 2.0793 - val_accuracy: 0.2333\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4518 - accuracy: 0.4100 - val_loss: 2.0931 - val_accuracy: 0.2300\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4515 - accuracy: 0.4071 - val_loss: 2.0832 - val_accuracy: 0.2367\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4500 - accuracy: 0.4157 - val_loss: 2.0998 - val_accuracy: 0.2567\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4507 - accuracy: 0.4129 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4508 - accuracy: 0.4129 - val_loss: 2.0975 - val_accuracy: 0.2367\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4506 - accuracy: 0.4086 - val_loss: 2.0951 - val_accuracy: 0.2433\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4505 - accuracy: 0.4086 - val_loss: 2.0964 - val_accuracy: 0.2300\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4496 - accuracy: 0.4129 - val_loss: 2.1080 - val_accuracy: 0.2500\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4502 - accuracy: 0.4129 - val_loss: 2.0887 - val_accuracy: 0.2533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4495 - accuracy: 0.4129 - val_loss: 2.1144 - val_accuracy: 0.2333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4480 - accuracy: 0.4157 - val_loss: 2.1039 - val_accuracy: 0.2533\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4491 - accuracy: 0.4014 - val_loss: 2.0963 - val_accuracy: 0.2400\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4479 - accuracy: 0.4114 - val_loss: 2.1056 - val_accuracy: 0.2333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4488 - accuracy: 0.4171 - val_loss: 2.0924 - val_accuracy: 0.2300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4487 - accuracy: 0.4129 - val_loss: 2.1158 - val_accuracy: 0.2333\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4476 - accuracy: 0.4114 - val_loss: 2.1155 - val_accuracy: 0.2367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4471 - accuracy: 0.4186 - val_loss: 2.1097 - val_accuracy: 0.2267\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4480 - accuracy: 0.4171 - val_loss: 2.1088 - val_accuracy: 0.2367\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4479 - accuracy: 0.4029 - val_loss: 2.1142 - val_accuracy: 0.2367\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4471 - accuracy: 0.4086 - val_loss: 2.0894 - val_accuracy: 0.2367\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4478 - accuracy: 0.4257 - val_loss: 2.1022 - val_accuracy: 0.2333\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4459 - accuracy: 0.4157 - val_loss: 2.0855 - val_accuracy: 0.2400\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4475 - accuracy: 0.4100 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4460 - accuracy: 0.4114 - val_loss: 2.0909 - val_accuracy: 0.2333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4468 - accuracy: 0.4114 - val_loss: 2.1271 - val_accuracy: 0.2400\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4467 - accuracy: 0.4086 - val_loss: 2.1177 - val_accuracy: 0.2400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4455 - accuracy: 0.4143 - val_loss: 2.1269 - val_accuracy: 0.2367\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4457 - accuracy: 0.4129 - val_loss: 2.1139 - val_accuracy: 0.2333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4444 - accuracy: 0.4071 - val_loss: 2.1061 - val_accuracy: 0.2567\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4463 - accuracy: 0.4129 - val_loss: 2.1088 - val_accuracy: 0.2333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4451 - accuracy: 0.4114 - val_loss: 2.1212 - val_accuracy: 0.2367\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4452 - accuracy: 0.4114 - val_loss: 2.1277 - val_accuracy: 0.2300\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4449 - accuracy: 0.4086 - val_loss: 2.1286 - val_accuracy: 0.2233\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4441 - accuracy: 0.4157 - val_loss: 2.0973 - val_accuracy: 0.2367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4437 - accuracy: 0.4143 - val_loss: 2.1183 - val_accuracy: 0.2467\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4448 - accuracy: 0.4100 - val_loss: 2.1281 - val_accuracy: 0.2433\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4439 - accuracy: 0.4129 - val_loss: 2.1331 - val_accuracy: 0.2300\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4440 - accuracy: 0.4129 - val_loss: 2.1148 - val_accuracy: 0.2367\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4432 - accuracy: 0.4186 - val_loss: 2.1250 - val_accuracy: 0.2333\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4414 - accuracy: 0.4114 - val_loss: 2.1179 - val_accuracy: 0.2567\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4423 - accuracy: 0.4114 - val_loss: 2.1133 - val_accuracy: 0.2367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4431 - accuracy: 0.4100 - val_loss: 2.1343 - val_accuracy: 0.2333\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4415 - accuracy: 0.4057 - val_loss: 2.1301 - val_accuracy: 0.2333\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4432 - accuracy: 0.4143 - val_loss: 2.1169 - val_accuracy: 0.2333\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4418 - accuracy: 0.4157 - val_loss: 2.1391 - val_accuracy: 0.2400\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4430 - accuracy: 0.4114 - val_loss: 2.1186 - val_accuracy: 0.2333\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4415 - accuracy: 0.4171 - val_loss: 2.1247 - val_accuracy: 0.2433\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4414 - accuracy: 0.4143 - val_loss: 2.1066 - val_accuracy: 0.2467\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4406 - accuracy: 0.4100 - val_loss: 2.1201 - val_accuracy: 0.2533\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4426 - accuracy: 0.4086 - val_loss: 2.1340 - val_accuracy: 0.2433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4409 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2300\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4409 - accuracy: 0.4143 - val_loss: 2.1242 - val_accuracy: 0.2367\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4404 - accuracy: 0.4186 - val_loss: 2.1269 - val_accuracy: 0.2467\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4409 - accuracy: 0.4100 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4418 - accuracy: 0.4086 - val_loss: 2.1221 - val_accuracy: 0.2367\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4410 - accuracy: 0.4000 - val_loss: 2.1275 - val_accuracy: 0.2367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4402 - accuracy: 0.4157 - val_loss: 2.1482 - val_accuracy: 0.2400\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4394 - accuracy: 0.4186 - val_loss: 2.1317 - val_accuracy: 0.2400\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4396 - accuracy: 0.4114 - val_loss: 2.1400 - val_accuracy: 0.2333\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4390 - accuracy: 0.4200 - val_loss: 2.1294 - val_accuracy: 0.2533\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4406 - accuracy: 0.4114 - val_loss: 2.1217 - val_accuracy: 0.2367\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4375 - accuracy: 0.4157 - val_loss: 2.1405 - val_accuracy: 0.2567\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4382 - accuracy: 0.4157 - val_loss: 2.1450 - val_accuracy: 0.2333\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4393 - accuracy: 0.4171 - val_loss: 2.1303 - val_accuracy: 0.2333\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1282 - val_accuracy: 0.2533\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4382 - accuracy: 0.4100 - val_loss: 2.1405 - val_accuracy: 0.2367\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4384 - accuracy: 0.4186 - val_loss: 2.1311 - val_accuracy: 0.2400\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4374 - accuracy: 0.4086 - val_loss: 2.1580 - val_accuracy: 0.2433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4366 - accuracy: 0.4214 - val_loss: 2.1570 - val_accuracy: 0.2533\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2567\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4360 - accuracy: 0.4143 - val_loss: 2.1505 - val_accuracy: 0.2300\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4355 - accuracy: 0.4200 - val_loss: 2.1176 - val_accuracy: 0.2333\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4369 - accuracy: 0.4257 - val_loss: 2.1406 - val_accuracy: 0.2367\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1416 - val_accuracy: 0.2400\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1307 - val_accuracy: 0.2400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4360 - accuracy: 0.4214 - val_loss: 2.1368 - val_accuracy: 0.2567\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4356 - accuracy: 0.4129 - val_loss: 2.1275 - val_accuracy: 0.2500\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4330 - accuracy: 0.4143 - val_loss: 2.1410 - val_accuracy: 0.2600\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4356 - accuracy: 0.4143 - val_loss: 2.1360 - val_accuracy: 0.2567\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4352 - accuracy: 0.4200 - val_loss: 2.1651 - val_accuracy: 0.2533\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4354 - accuracy: 0.4143 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4355 - accuracy: 0.4157 - val_loss: 2.1346 - val_accuracy: 0.2400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4348 - accuracy: 0.4200 - val_loss: 2.1469 - val_accuracy: 0.2367\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4345 - accuracy: 0.4143 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4337 - accuracy: 0.4229 - val_loss: 2.1496 - val_accuracy: 0.2333\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4339 - accuracy: 0.4186 - val_loss: 2.1345 - val_accuracy: 0.2400\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4345 - accuracy: 0.4171 - val_loss: 2.1337 - val_accuracy: 0.2400\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4335 - accuracy: 0.4186 - val_loss: 2.1663 - val_accuracy: 0.2467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4348 - accuracy: 0.4171 - val_loss: 2.1408 - val_accuracy: 0.2567\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4324 - accuracy: 0.4214 - val_loss: 2.1548 - val_accuracy: 0.2333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4337 - accuracy: 0.4186 - val_loss: 2.1654 - val_accuracy: 0.2467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4333 - accuracy: 0.4257 - val_loss: 2.1511 - val_accuracy: 0.2433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4328 - accuracy: 0.4214 - val_loss: 2.1524 - val_accuracy: 0.2400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4329 - accuracy: 0.4200 - val_loss: 2.1518 - val_accuracy: 0.2467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4316 - accuracy: 0.4171 - val_loss: 2.1483 - val_accuracy: 0.2433\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4327 - accuracy: 0.4129 - val_loss: 2.1556 - val_accuracy: 0.2367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4316 - accuracy: 0.4229 - val_loss: 2.1657 - val_accuracy: 0.2333\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4325 - accuracy: 0.4214 - val_loss: 2.1498 - val_accuracy: 0.2433\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4320 - accuracy: 0.4157 - val_loss: 2.1429 - val_accuracy: 0.2400\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4321 - accuracy: 0.4214 - val_loss: 2.1335 - val_accuracy: 0.2400\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4315 - accuracy: 0.4243 - val_loss: 2.1494 - val_accuracy: 0.2367\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4316 - accuracy: 0.4214 - val_loss: 2.1488 - val_accuracy: 0.2333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4296 - accuracy: 0.4186 - val_loss: 2.1794 - val_accuracy: 0.2533\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4314 - accuracy: 0.4229 - val_loss: 2.1527 - val_accuracy: 0.2467\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4304 - accuracy: 0.4186 - val_loss: 2.1542 - val_accuracy: 0.2367\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4300 - accuracy: 0.4214 - val_loss: 2.1636 - val_accuracy: 0.2567\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4310 - accuracy: 0.4186 - val_loss: 2.1410 - val_accuracy: 0.2400\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4305 - accuracy: 0.4243 - val_loss: 2.1585 - val_accuracy: 0.2367\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4282 - accuracy: 0.4243 - val_loss: 2.1502 - val_accuracy: 0.2600\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4305 - accuracy: 0.4157 - val_loss: 2.1677 - val_accuracy: 0.2367\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4297 - accuracy: 0.4157 - val_loss: 2.1621 - val_accuracy: 0.2367\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4289 - accuracy: 0.4186 - val_loss: 2.1916 - val_accuracy: 0.2533\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4303 - accuracy: 0.4186 - val_loss: 2.1728 - val_accuracy: 0.2400\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4295 - accuracy: 0.4214 - val_loss: 2.1658 - val_accuracy: 0.2367\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4291 - accuracy: 0.4200 - val_loss: 2.1649 - val_accuracy: 0.2433\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4286 - accuracy: 0.4200 - val_loss: 2.1653 - val_accuracy: 0.2367\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4282 - accuracy: 0.4214 - val_loss: 2.1490 - val_accuracy: 0.2400\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4281 - accuracy: 0.4257 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4277 - accuracy: 0.4229 - val_loss: 2.1819 - val_accuracy: 0.2433\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4278 - accuracy: 0.4257 - val_loss: 2.1563 - val_accuracy: 0.2367\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4273 - accuracy: 0.4214 - val_loss: 2.1938 - val_accuracy: 0.2333\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4276 - accuracy: 0.4200 - val_loss: 2.1558 - val_accuracy: 0.2400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4269 - accuracy: 0.4229 - val_loss: 2.1856 - val_accuracy: 0.2467\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4269 - accuracy: 0.4257 - val_loss: 2.1927 - val_accuracy: 0.2400\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4277 - accuracy: 0.4143 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4261 - accuracy: 0.4243 - val_loss: 2.1707 - val_accuracy: 0.2400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4263 - accuracy: 0.4286 - val_loss: 2.1618 - val_accuracy: 0.2400\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4271 - accuracy: 0.4214 - val_loss: 2.1844 - val_accuracy: 0.2400\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4261 - accuracy: 0.4286 - val_loss: 2.1732 - val_accuracy: 0.2367\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4249 - accuracy: 0.4300 - val_loss: 2.1629 - val_accuracy: 0.2400\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4265 - accuracy: 0.4229 - val_loss: 2.1866 - val_accuracy: 0.2433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4265 - accuracy: 0.4200 - val_loss: 2.1722 - val_accuracy: 0.2467\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4251 - accuracy: 0.4271 - val_loss: 2.1827 - val_accuracy: 0.2367\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4250 - accuracy: 0.4314 - val_loss: 2.1680 - val_accuracy: 0.2400\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4249 - accuracy: 0.4200 - val_loss: 2.1864 - val_accuracy: 0.2567\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4252 - accuracy: 0.4143 - val_loss: 2.1628 - val_accuracy: 0.2533\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4240 - accuracy: 0.4286 - val_loss: 2.1670 - val_accuracy: 0.2533\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4257 - accuracy: 0.4186 - val_loss: 2.1682 - val_accuracy: 0.2433\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4221 - accuracy: 0.4329 - val_loss: 2.1818 - val_accuracy: 0.2533\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4254 - accuracy: 0.4300 - val_loss: 2.1702 - val_accuracy: 0.2400\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4251 - accuracy: 0.4157 - val_loss: 2.1784 - val_accuracy: 0.2433\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4233 - accuracy: 0.4257 - val_loss: 2.2001 - val_accuracy: 0.2600\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4222 - accuracy: 0.4271 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4239 - accuracy: 0.4329 - val_loss: 2.1629 - val_accuracy: 0.2300\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4224 - accuracy: 0.4171 - val_loss: 2.1794 - val_accuracy: 0.2400\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4233 - accuracy: 0.4243 - val_loss: 2.1854 - val_accuracy: 0.2367\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4223 - accuracy: 0.4257 - val_loss: 2.2051 - val_accuracy: 0.2333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4235 - accuracy: 0.4271 - val_loss: 2.1869 - val_accuracy: 0.2333\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4221 - accuracy: 0.4386 - val_loss: 2.1849 - val_accuracy: 0.2467\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4223 - accuracy: 0.4143 - val_loss: 2.1829 - val_accuracy: 0.2400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4233 - accuracy: 0.4200 - val_loss: 2.1907 - val_accuracy: 0.2433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4220 - accuracy: 0.4300 - val_loss: 2.1885 - val_accuracy: 0.2433\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4221 - accuracy: 0.4271 - val_loss: 2.1786 - val_accuracy: 0.2400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4218 - accuracy: 0.4329 - val_loss: 2.1784 - val_accuracy: 0.2400\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4215 - accuracy: 0.4229 - val_loss: 2.2086 - val_accuracy: 0.2500\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4225 - accuracy: 0.4257 - val_loss: 2.1981 - val_accuracy: 0.2400\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4215 - accuracy: 0.4200 - val_loss: 2.1838 - val_accuracy: 0.2400\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4227 - accuracy: 0.4300 - val_loss: 2.2048 - val_accuracy: 0.2433\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4203 - accuracy: 0.4214 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4217 - accuracy: 0.4214 - val_loss: 2.1842 - val_accuracy: 0.2400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4217 - accuracy: 0.4257 - val_loss: 2.1846 - val_accuracy: 0.2367\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4205 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4207 - accuracy: 0.4243 - val_loss: 2.1856 - val_accuracy: 0.2367\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4200 - accuracy: 0.4214 - val_loss: 2.1758 - val_accuracy: 0.2333\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1942 - val_accuracy: 0.2367\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4202 - accuracy: 0.4229 - val_loss: 2.1983 - val_accuracy: 0.2433\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4200 - accuracy: 0.4229 - val_loss: 2.2066 - val_accuracy: 0.2500\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4191 - accuracy: 0.4243 - val_loss: 2.2019 - val_accuracy: 0.2400\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4182 - accuracy: 0.4286 - val_loss: 2.2032 - val_accuracy: 0.2533\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4193 - accuracy: 0.4271 - val_loss: 2.1977 - val_accuracy: 0.2467\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4177 - accuracy: 0.4314 - val_loss: 2.2090 - val_accuracy: 0.2333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4190 - accuracy: 0.4214 - val_loss: 2.1922 - val_accuracy: 0.2333\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4191 - accuracy: 0.4300 - val_loss: 2.1962 - val_accuracy: 0.2333\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4190 - accuracy: 0.4229 - val_loss: 2.1879 - val_accuracy: 0.2400\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1973 - val_accuracy: 0.2467\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4184 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4186 - accuracy: 0.4329 - val_loss: 2.2047 - val_accuracy: 0.2433\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4181 - accuracy: 0.4300 - val_loss: 2.2132 - val_accuracy: 0.2400\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4179 - accuracy: 0.4271 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4180 - accuracy: 0.4271 - val_loss: 2.1994 - val_accuracy: 0.2467\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4184 - accuracy: 0.4243 - val_loss: 2.1838 - val_accuracy: 0.2500\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4178 - accuracy: 0.4271 - val_loss: 2.1991 - val_accuracy: 0.2400\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4173 - accuracy: 0.4229 - val_loss: 2.1994 - val_accuracy: 0.2400\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4174 - accuracy: 0.4314 - val_loss: 2.2033 - val_accuracy: 0.2400\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4164 - accuracy: 0.4286 - val_loss: 2.2056 - val_accuracy: 0.2500\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4171 - accuracy: 0.4229 - val_loss: 2.1936 - val_accuracy: 0.2367\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4166 - accuracy: 0.4257 - val_loss: 2.2141 - val_accuracy: 0.2500\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3988 - accuracy: 0.30 - 0s 61us/step - loss: 1.4169 - accuracy: 0.4271 - val_loss: 2.2061 - val_accuracy: 0.2367\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4164 - accuracy: 0.4314 - val_loss: 2.2030 - val_accuracy: 0.2400\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4160 - accuracy: 0.4300 - val_loss: 2.2047 - val_accuracy: 0.2367\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4164 - accuracy: 0.4200 - val_loss: 2.2128 - val_accuracy: 0.2367\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4162 - accuracy: 0.4386 - val_loss: 2.2137 - val_accuracy: 0.2400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4152 - accuracy: 0.4329 - val_loss: 2.2049 - val_accuracy: 0.2567\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4159 - accuracy: 0.4200 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4159 - accuracy: 0.4329 - val_loss: 2.2122 - val_accuracy: 0.2333\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4158 - accuracy: 0.4329 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4146 - accuracy: 0.4271 - val_loss: 2.2121 - val_accuracy: 0.2600\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4148 - accuracy: 0.4243 - val_loss: 2.2039 - val_accuracy: 0.2433\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4143 - accuracy: 0.4329 - val_loss: 2.2054 - val_accuracy: 0.2467\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4148 - accuracy: 0.4357 - val_loss: 2.2052 - val_accuracy: 0.2400\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4148 - accuracy: 0.4386 - val_loss: 2.2125 - val_accuracy: 0.2500\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4143 - accuracy: 0.4314 - val_loss: 2.2125 - val_accuracy: 0.2400\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4150 - accuracy: 0.4229 - val_loss: 2.2137 - val_accuracy: 0.2467\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4139 - accuracy: 0.4357 - val_loss: 2.2157 - val_accuracy: 0.2367\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4142 - accuracy: 0.4314 - val_loss: 2.2169 - val_accuracy: 0.2400\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4141 - accuracy: 0.4271 - val_loss: 2.2032 - val_accuracy: 0.2400\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4139 - accuracy: 0.4329 - val_loss: 2.2245 - val_accuracy: 0.2400\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4131 - accuracy: 0.4286 - val_loss: 2.2157 - val_accuracy: 0.2533\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4139 - accuracy: 0.4314 - val_loss: 2.2224 - val_accuracy: 0.2467\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4136 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4116 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4123 - accuracy: 0.4286 - val_loss: 2.2243 - val_accuracy: 0.2367\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4110 - accuracy: 0.4357 - val_loss: 2.2386 - val_accuracy: 0.2600\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4131 - accuracy: 0.4329 - val_loss: 2.2190 - val_accuracy: 0.2567\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4129 - accuracy: 0.4300 - val_loss: 2.2348 - val_accuracy: 0.2467\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4130 - accuracy: 0.4329 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4114 - accuracy: 0.4271 - val_loss: 2.2264 - val_accuracy: 0.2433\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4110 - accuracy: 0.4300 - val_loss: 2.2265 - val_accuracy: 0.2433\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4112 - accuracy: 0.4314 - val_loss: 2.2452 - val_accuracy: 0.2467\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4122 - accuracy: 0.4271 - val_loss: 2.2332 - val_accuracy: 0.2467\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4112 - accuracy: 0.4300 - val_loss: 2.2318 - val_accuracy: 0.2400\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4118 - accuracy: 0.4343 - val_loss: 2.2184 - val_accuracy: 0.2367\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4111 - accuracy: 0.4314 - val_loss: 2.2233 - val_accuracy: 0.2433\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4104 - accuracy: 0.4271 - val_loss: 2.2284 - val_accuracy: 0.2400\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4105 - accuracy: 0.4443 - val_loss: 2.2469 - val_accuracy: 0.2467\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4111 - accuracy: 0.4343 - val_loss: 2.2477 - val_accuracy: 0.2500\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4110 - accuracy: 0.4243 - val_loss: 2.2534 - val_accuracy: 0.2467\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4106 - accuracy: 0.4329 - val_loss: 2.2659 - val_accuracy: 0.2433\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4095 - accuracy: 0.4300 - val_loss: 2.2260 - val_accuracy: 0.2367\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2500\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4102 - accuracy: 0.4300 - val_loss: 2.2211 - val_accuracy: 0.2433\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4107 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4088 - accuracy: 0.4300 - val_loss: 2.2353 - val_accuracy: 0.2367\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4081 - accuracy: 0.4343 - val_loss: 2.2224 - val_accuracy: 0.2433\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4092 - accuracy: 0.4371 - val_loss: 2.2331 - val_accuracy: 0.2367\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2487 - val_accuracy: 0.2500\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4090 - accuracy: 0.4314 - val_loss: 2.2326 - val_accuracy: 0.2367\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4082 - accuracy: 0.4300 - val_loss: 2.2510 - val_accuracy: 0.2367\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4088 - accuracy: 0.4314 - val_loss: 2.2242 - val_accuracy: 0.2367\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4092 - accuracy: 0.4357 - val_loss: 2.2349 - val_accuracy: 0.2400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4075 - accuracy: 0.4229 - val_loss: 2.2487 - val_accuracy: 0.2433\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4079 - accuracy: 0.4371 - val_loss: 2.2414 - val_accuracy: 0.2533\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4086 - accuracy: 0.4300 - val_loss: 2.2446 - val_accuracy: 0.2433\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4071 - accuracy: 0.4314 - val_loss: 2.2355 - val_accuracy: 0.2367\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4071 - accuracy: 0.4229 - val_loss: 2.2345 - val_accuracy: 0.2333\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.4086 - accuracy: 0.4371 - val_loss: 2.2389 - val_accuracy: 0.2433\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4066 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4046 - accuracy: 0.4371 - val_loss: 2.2682 - val_accuracy: 0.2600\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4074 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4074 - accuracy: 0.4357 - val_loss: 2.2498 - val_accuracy: 0.2500\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4067 - accuracy: 0.4286 - val_loss: 2.2486 - val_accuracy: 0.2467\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4066 - accuracy: 0.4343 - val_loss: 2.2459 - val_accuracy: 0.2367\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2438 - val_accuracy: 0.2367\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4057 - accuracy: 0.4357 - val_loss: 2.2736 - val_accuracy: 0.2533\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4064 - accuracy: 0.4343 - val_loss: 2.2575 - val_accuracy: 0.2433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4071 - accuracy: 0.4271 - val_loss: 2.2603 - val_accuracy: 0.2533\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4055 - accuracy: 0.4329 - val_loss: 2.2607 - val_accuracy: 0.2500\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4053 - accuracy: 0.4329 - val_loss: 2.2554 - val_accuracy: 0.2533\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4047 - accuracy: 0.4386 - val_loss: 2.2618 - val_accuracy: 0.2633\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4049 - accuracy: 0.4314 - val_loss: 2.2232 - val_accuracy: 0.2433\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2613 - val_accuracy: 0.2433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4054 - accuracy: 0.4357 - val_loss: 2.2531 - val_accuracy: 0.2467\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4050 - accuracy: 0.4386 - val_loss: 2.2509 - val_accuracy: 0.2400\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.4034 - accuracy: 0.4357 - val_loss: 2.2675 - val_accuracy: 0.2467\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4048 - accuracy: 0.4314 - val_loss: 2.2729 - val_accuracy: 0.2467\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4037 - accuracy: 0.4357 - val_loss: 2.2533 - val_accuracy: 0.2567\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2292 - val_accuracy: 0.2367\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4048 - accuracy: 0.4329 - val_loss: 2.2420 - val_accuracy: 0.2367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4038 - accuracy: 0.4329 - val_loss: 2.2705 - val_accuracy: 0.2467\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4035 - accuracy: 0.4314 - val_loss: 2.2423 - val_accuracy: 0.2433\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4037 - accuracy: 0.4271 - val_loss: 2.2683 - val_accuracy: 0.2367\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2634 - val_accuracy: 0.2400\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4012 - accuracy: 0.4371 - val_loss: 2.2625 - val_accuracy: 0.2400\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.4051 - accuracy: 0.4329 - val_loss: 2.2507 - val_accuracy: 0.2400\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.4035 - accuracy: 0.4429 - val_loss: 2.2849 - val_accuracy: 0.2500\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.4035 - accuracy: 0.4371 - val_loss: 2.2680 - val_accuracy: 0.2400\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4044 - accuracy: 0.4286 - val_loss: 2.2364 - val_accuracy: 0.2400\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4027 - accuracy: 0.4314 - val_loss: 2.2784 - val_accuracy: 0.2533\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.4031 - accuracy: 0.4314 - val_loss: 2.2322 - val_accuracy: 0.2433\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4036 - accuracy: 0.4386 - val_loss: 2.2614 - val_accuracy: 0.2467\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4026 - accuracy: 0.4371 - val_loss: 2.2456 - val_accuracy: 0.2367\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4027 - accuracy: 0.4357 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.4010 - accuracy: 0.4443 - val_loss: 2.2736 - val_accuracy: 0.2600\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4028 - accuracy: 0.4386 - val_loss: 2.2630 - val_accuracy: 0.2567\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4024 - accuracy: 0.4271 - val_loss: 2.2669 - val_accuracy: 0.2433\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4024 - accuracy: 0.4357 - val_loss: 2.2699 - val_accuracy: 0.2433\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4018 - accuracy: 0.4357 - val_loss: 2.2777 - val_accuracy: 0.2433\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.4020 - accuracy: 0.4429 - val_loss: 2.2620 - val_accuracy: 0.2400\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4012 - accuracy: 0.4343 - val_loss: 2.2655 - val_accuracy: 0.2467\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4014 - accuracy: 0.4357 - val_loss: 2.2715 - val_accuracy: 0.2600\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.4017 - accuracy: 0.4343 - val_loss: 2.2648 - val_accuracy: 0.2533\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4011 - accuracy: 0.4386 - val_loss: 2.2896 - val_accuracy: 0.2467\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4015 - accuracy: 0.4343 - val_loss: 2.2583 - val_accuracy: 0.2467\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4001 - accuracy: 0.4471 - val_loss: 2.2617 - val_accuracy: 0.2467\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3999 - accuracy: 0.4400 - val_loss: 2.2772 - val_accuracy: 0.2533\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4001 - accuracy: 0.4343 - val_loss: 2.2689 - val_accuracy: 0.2467\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3992 - accuracy: 0.4414 - val_loss: 2.2865 - val_accuracy: 0.2633\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3991 - accuracy: 0.4357 - val_loss: 2.2582 - val_accuracy: 0.2400\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.4010 - accuracy: 0.4400 - val_loss: 2.2543 - val_accuracy: 0.2400\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3998 - accuracy: 0.4371 - val_loss: 2.2494 - val_accuracy: 0.2367\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.4003 - accuracy: 0.4386 - val_loss: 2.2830 - val_accuracy: 0.2467\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3997 - accuracy: 0.4414 - val_loss: 2.2715 - val_accuracy: 0.2433\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3993 - accuracy: 0.4329 - val_loss: 2.2790 - val_accuracy: 0.2500\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4004 - accuracy: 0.4357 - val_loss: 2.2561 - val_accuracy: 0.2400\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3991 - accuracy: 0.4371 - val_loss: 2.2786 - val_accuracy: 0.2367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3995 - accuracy: 0.4400 - val_loss: 2.2665 - val_accuracy: 0.2367\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.4000 - accuracy: 0.4371 - val_loss: 2.2924 - val_accuracy: 0.2433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3988 - accuracy: 0.4386 - val_loss: 2.2909 - val_accuracy: 0.2567\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3990 - accuracy: 0.4343 - val_loss: 2.2737 - val_accuracy: 0.2467\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3987 - accuracy: 0.4386 - val_loss: 2.2810 - val_accuracy: 0.2400\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3978 - accuracy: 0.4400 - val_loss: 2.2807 - val_accuracy: 0.2400\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3970 - accuracy: 0.4386 - val_loss: 2.2802 - val_accuracy: 0.2533\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3984 - accuracy: 0.4329 - val_loss: 2.2901 - val_accuracy: 0.2433\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3988 - accuracy: 0.4343 - val_loss: 2.2681 - val_accuracy: 0.2500\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3984 - accuracy: 0.4357 - val_loss: 2.2706 - val_accuracy: 0.2400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3967 - accuracy: 0.4400 - val_loss: 2.2872 - val_accuracy: 0.2500\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3966 - accuracy: 0.4386 - val_loss: 2.2698 - val_accuracy: 0.2567\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3988 - accuracy: 0.4414 - val_loss: 2.2782 - val_accuracy: 0.2467\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3970 - accuracy: 0.4343 - val_loss: 2.2855 - val_accuracy: 0.2367\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3972 - accuracy: 0.4443 - val_loss: 2.2793 - val_accuracy: 0.2467\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3975 - accuracy: 0.4357 - val_loss: 2.2798 - val_accuracy: 0.2400\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3971 - accuracy: 0.4400 - val_loss: 2.3013 - val_accuracy: 0.2433\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3971 - accuracy: 0.4414 - val_loss: 2.2997 - val_accuracy: 0.2400\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3971 - accuracy: 0.4357 - val_loss: 2.2816 - val_accuracy: 0.2467\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3967 - accuracy: 0.4329 - val_loss: 2.2836 - val_accuracy: 0.2467\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3962 - accuracy: 0.4400 - val_loss: 2.2720 - val_accuracy: 0.2500\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3966 - accuracy: 0.4314 - val_loss: 2.2861 - val_accuracy: 0.2467\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3958 - accuracy: 0.4414 - val_loss: 2.2939 - val_accuracy: 0.2500\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3966 - accuracy: 0.4414 - val_loss: 2.2901 - val_accuracy: 0.2500\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3965 - accuracy: 0.4429 - val_loss: 2.2962 - val_accuracy: 0.2500\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3960 - accuracy: 0.4400 - val_loss: 2.2877 - val_accuracy: 0.2367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3953 - accuracy: 0.4443 - val_loss: 2.2991 - val_accuracy: 0.2500\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3953 - accuracy: 0.4386 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3960 - accuracy: 0.4343 - val_loss: 2.2826 - val_accuracy: 0.2400\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3957 - accuracy: 0.4343 - val_loss: 2.2917 - val_accuracy: 0.2400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3947 - accuracy: 0.4357 - val_loss: 2.2695 - val_accuracy: 0.2333\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3955 - accuracy: 0.4414 - val_loss: 2.3028 - val_accuracy: 0.2433\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3944 - accuracy: 0.4371 - val_loss: 2.3057 - val_accuracy: 0.2433\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3947 - accuracy: 0.4329 - val_loss: 2.3010 - val_accuracy: 0.2500\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3945 - accuracy: 0.4329 - val_loss: 2.2912 - val_accuracy: 0.2467\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3939 - accuracy: 0.4414 - val_loss: 2.3067 - val_accuracy: 0.2533\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3940 - accuracy: 0.4300 - val_loss: 2.2777 - val_accuracy: 0.2367\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3938 - accuracy: 0.4471 - val_loss: 2.2906 - val_accuracy: 0.2400\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3929 - accuracy: 0.4386 - val_loss: 2.2916 - val_accuracy: 0.2367\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3940 - accuracy: 0.4429 - val_loss: 2.3014 - val_accuracy: 0.2500\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3938 - accuracy: 0.4414 - val_loss: 2.2949 - val_accuracy: 0.2467\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3935 - accuracy: 0.4371 - val_loss: 2.3148 - val_accuracy: 0.2533\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3940 - accuracy: 0.4471 - val_loss: 2.2962 - val_accuracy: 0.2567\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3936 - accuracy: 0.4429 - val_loss: 2.3098 - val_accuracy: 0.2500\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3928 - accuracy: 0.4386 - val_loss: 2.3181 - val_accuracy: 0.2433\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3925 - accuracy: 0.4414 - val_loss: 2.2925 - val_accuracy: 0.2433\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3938 - accuracy: 0.4343 - val_loss: 2.3365 - val_accuracy: 0.2467\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3936 - accuracy: 0.4414 - val_loss: 2.2892 - val_accuracy: 0.2467\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3930 - accuracy: 0.4400 - val_loss: 2.3049 - val_accuracy: 0.2467\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.2714 - val_accuracy: 0.2467\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3931 - accuracy: 0.4400 - val_loss: 2.3025 - val_accuracy: 0.2467\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3926 - accuracy: 0.4386 - val_loss: 2.2963 - val_accuracy: 0.2500\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3919 - accuracy: 0.4357 - val_loss: 2.2856 - val_accuracy: 0.2433\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3913 - accuracy: 0.4414 - val_loss: 2.2959 - val_accuracy: 0.2533\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3924 - accuracy: 0.4429 - val_loss: 2.3148 - val_accuracy: 0.2567\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.3105 - val_accuracy: 0.2467\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3913 - accuracy: 0.4400 - val_loss: 2.2989 - val_accuracy: 0.2433\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3917 - accuracy: 0.4414 - val_loss: 2.3052 - val_accuracy: 0.2433\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3916 - accuracy: 0.4400 - val_loss: 2.3201 - val_accuracy: 0.2400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3916 - accuracy: 0.4414 - val_loss: 2.3001 - val_accuracy: 0.2467\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3913 - accuracy: 0.4386 - val_loss: 2.3213 - val_accuracy: 0.2333\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3901 - accuracy: 0.4400 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3908 - accuracy: 0.4386 - val_loss: 2.3123 - val_accuracy: 0.2500\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3907 - accuracy: 0.4443 - val_loss: 2.3262 - val_accuracy: 0.2500\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3905 - accuracy: 0.4429 - val_loss: 2.3076 - val_accuracy: 0.2500\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3905 - accuracy: 0.4343 - val_loss: 2.3044 - val_accuracy: 0.2400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3904 - accuracy: 0.4486 - val_loss: 2.3117 - val_accuracy: 0.2533\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3081 - val_accuracy: 0.2467\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3256 - val_accuracy: 0.2500\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3894 - accuracy: 0.4371 - val_loss: 2.3378 - val_accuracy: 0.2500\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3902 - accuracy: 0.4400 - val_loss: 2.3157 - val_accuracy: 0.2533\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3897 - accuracy: 0.4357 - val_loss: 2.3231 - val_accuracy: 0.2500\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3898 - accuracy: 0.4414 - val_loss: 2.3133 - val_accuracy: 0.2500\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3891 - accuracy: 0.4400 - val_loss: 2.3245 - val_accuracy: 0.2367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3985 - accuracy: 0.40 - 0s 61us/step - loss: 1.3891 - accuracy: 0.4414 - val_loss: 2.3228 - val_accuracy: 0.2500\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3887 - accuracy: 0.4414 - val_loss: 2.3043 - val_accuracy: 0.2400\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3886 - accuracy: 0.4429 - val_loss: 2.3385 - val_accuracy: 0.2633\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3903 - accuracy: 0.4357 - val_loss: 2.3375 - val_accuracy: 0.2533\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3887 - accuracy: 0.4443 - val_loss: 2.3547 - val_accuracy: 0.2533\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3890 - accuracy: 0.4471 - val_loss: 2.3138 - val_accuracy: 0.2433\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3888 - accuracy: 0.4371 - val_loss: 2.3301 - val_accuracy: 0.2400\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3885 - accuracy: 0.4457 - val_loss: 2.3353 - val_accuracy: 0.2533\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3885 - accuracy: 0.4357 - val_loss: 2.3073 - val_accuracy: 0.2367\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.3890 - accuracy: 0.4429 - val_loss: 2.3282 - val_accuracy: 0.2500\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3877 - accuracy: 0.4457 - val_loss: 2.3284 - val_accuracy: 0.2467\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3879 - accuracy: 0.4429 - val_loss: 2.3277 - val_accuracy: 0.2533\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3887 - accuracy: 0.4386 - val_loss: 2.3401 - val_accuracy: 0.2533\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3881 - accuracy: 0.4386 - val_loss: 2.3246 - val_accuracy: 0.2500\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3879 - accuracy: 0.4386 - val_loss: 2.3363 - val_accuracy: 0.2500\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3864 - accuracy: 0.4457 - val_loss: 2.3322 - val_accuracy: 0.2600\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3883 - accuracy: 0.4371 - val_loss: 2.3279 - val_accuracy: 0.2500\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3865 - accuracy: 0.4457 - val_loss: 2.3385 - val_accuracy: 0.2567\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3885 - accuracy: 0.4414 - val_loss: 2.3496 - val_accuracy: 0.2500\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3874 - accuracy: 0.4386 - val_loss: 2.3295 - val_accuracy: 0.2467\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3869 - accuracy: 0.4371 - val_loss: 2.3564 - val_accuracy: 0.2500\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3865 - accuracy: 0.4414 - val_loss: 2.3466 - val_accuracy: 0.2567\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3868 - accuracy: 0.4386 - val_loss: 2.3211 - val_accuracy: 0.2500\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3864 - accuracy: 0.4457 - val_loss: 2.3559 - val_accuracy: 0.2533\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3865 - accuracy: 0.4486 - val_loss: 2.3248 - val_accuracy: 0.2500\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3859 - accuracy: 0.4414 - val_loss: 2.3421 - val_accuracy: 0.2533\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3852 - accuracy: 0.4414 - val_loss: 2.3446 - val_accuracy: 0.2533\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3852 - accuracy: 0.4457 - val_loss: 2.3257 - val_accuracy: 0.2400\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3853 - accuracy: 0.4414 - val_loss: 2.3256 - val_accuracy: 0.2567\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3842 - accuracy: 0.4457 - val_loss: 2.3319 - val_accuracy: 0.2400\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3867 - accuracy: 0.4414 - val_loss: 2.3376 - val_accuracy: 0.2500\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3863 - accuracy: 0.4357 - val_loss: 2.3347 - val_accuracy: 0.2500\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3861 - accuracy: 0.4486 - val_loss: 2.3471 - val_accuracy: 0.2500\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3851 - accuracy: 0.4386 - val_loss: 2.3314 - val_accuracy: 0.2467\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3845 - accuracy: 0.4529 - val_loss: 2.3294 - val_accuracy: 0.2500\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.3853 - accuracy: 0.4429 - val_loss: 2.3389 - val_accuracy: 0.2533\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3842 - accuracy: 0.4514 - val_loss: 2.3396 - val_accuracy: 0.2400\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3855 - accuracy: 0.4414 - val_loss: 2.3287 - val_accuracy: 0.2467\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3850 - accuracy: 0.4529 - val_loss: 2.3287 - val_accuracy: 0.2433\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3844 - accuracy: 0.4443 - val_loss: 2.3350 - val_accuracy: 0.2533\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3848 - accuracy: 0.4457 - val_loss: 2.3112 - val_accuracy: 0.2433\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3841 - accuracy: 0.4457 - val_loss: 2.3445 - val_accuracy: 0.2500\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3842 - accuracy: 0.4386 - val_loss: 2.3323 - val_accuracy: 0.2433\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3844 - accuracy: 0.4443 - val_loss: 2.3308 - val_accuracy: 0.2467\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3835 - accuracy: 0.4500 - val_loss: 2.3470 - val_accuracy: 0.2500\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3834 - accuracy: 0.4443 - val_loss: 2.3523 - val_accuracy: 0.2567\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3846 - accuracy: 0.4443 - val_loss: 2.3494 - val_accuracy: 0.2433\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3843 - accuracy: 0.4429 - val_loss: 2.3703 - val_accuracy: 0.2467\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3822 - accuracy: 0.4443 - val_loss: 2.3406 - val_accuracy: 0.2333\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3842 - accuracy: 0.4443 - val_loss: 2.3459 - val_accuracy: 0.2533\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3837 - accuracy: 0.4486 - val_loss: 2.3452 - val_accuracy: 0.2500\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3830 - accuracy: 0.4429 - val_loss: 2.3415 - val_accuracy: 0.2400\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3838 - accuracy: 0.4443 - val_loss: 2.3751 - val_accuracy: 0.2567\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3835 - accuracy: 0.4443 - val_loss: 2.3524 - val_accuracy: 0.2467\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3832 - accuracy: 0.4414 - val_loss: 2.3506 - val_accuracy: 0.2467\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3825 - accuracy: 0.4414 - val_loss: 2.3684 - val_accuracy: 0.2500\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3814 - accuracy: 0.4400 - val_loss: 2.3343 - val_accuracy: 0.2467\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3835 - accuracy: 0.4400 - val_loss: 2.3604 - val_accuracy: 0.2533\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3825 - accuracy: 0.4429 - val_loss: 2.3520 - val_accuracy: 0.2467\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3802 - accuracy: 0.4386 - val_loss: 2.3440 - val_accuracy: 0.2333\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3831 - accuracy: 0.4514 - val_loss: 2.3538 - val_accuracy: 0.2433\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3808 - accuracy: 0.4457 - val_loss: 2.3428 - val_accuracy: 0.2367\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3824 - accuracy: 0.4400 - val_loss: 2.3375 - val_accuracy: 0.2433\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3818 - accuracy: 0.4414 - val_loss: 2.3480 - val_accuracy: 0.2500\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3808 - accuracy: 0.4471 - val_loss: 2.3605 - val_accuracy: 0.2433\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3821 - accuracy: 0.4471 - val_loss: 2.3487 - val_accuracy: 0.2467\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3810 - accuracy: 0.4357 - val_loss: 2.3688 - val_accuracy: 0.2433\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3814 - accuracy: 0.4443 - val_loss: 2.3598 - val_accuracy: 0.2467\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3808 - accuracy: 0.4486 - val_loss: 2.3476 - val_accuracy: 0.2500\n",
      "Epoch 1055/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3807 - accuracy: 0.4471 - val_loss: 2.3445 - val_accuracy: 0.2500\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3805 - accuracy: 0.4400 - val_loss: 2.3697 - val_accuracy: 0.2500\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3799 - accuracy: 0.4343 - val_loss: 2.3867 - val_accuracy: 0.2433\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3813 - accuracy: 0.4414 - val_loss: 2.3657 - val_accuracy: 0.2533\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3797 - accuracy: 0.4486 - val_loss: 2.3663 - val_accuracy: 0.2500\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3802 - accuracy: 0.4443 - val_loss: 2.3557 - val_accuracy: 0.2500\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3807 - accuracy: 0.4457 - val_loss: 2.3787 - val_accuracy: 0.2533\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3811 - accuracy: 0.4386 - val_loss: 2.3482 - val_accuracy: 0.2500\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3797 - accuracy: 0.4429 - val_loss: 2.3524 - val_accuracy: 0.2533\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3799 - accuracy: 0.4429 - val_loss: 2.3675 - val_accuracy: 0.2500\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3800 - accuracy: 0.4400 - val_loss: 2.3518 - val_accuracy: 0.2467\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3800 - accuracy: 0.4429 - val_loss: 2.3537 - val_accuracy: 0.2400\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4392 - accuracy: 0.40 - 0s 60us/step - loss: 1.3799 - accuracy: 0.4514 - val_loss: 2.3866 - val_accuracy: 0.2567\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3793 - accuracy: 0.4443 - val_loss: 2.3872 - val_accuracy: 0.2500\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3795 - accuracy: 0.4414 - val_loss: 2.3765 - val_accuracy: 0.2500\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3789 - accuracy: 0.4471 - val_loss: 2.3595 - val_accuracy: 0.2367\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3783 - accuracy: 0.4457 - val_loss: 2.3945 - val_accuracy: 0.2267\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3789 - accuracy: 0.4514 - val_loss: 2.3712 - val_accuracy: 0.2533\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3784 - accuracy: 0.4443 - val_loss: 2.3571 - val_accuracy: 0.2500\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3788 - accuracy: 0.4514 - val_loss: 2.3474 - val_accuracy: 0.2500\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3787 - accuracy: 0.4500 - val_loss: 2.3609 - val_accuracy: 0.2367\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3789 - accuracy: 0.4429 - val_loss: 2.3611 - val_accuracy: 0.2500\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3785 - accuracy: 0.4457 - val_loss: 2.3490 - val_accuracy: 0.2367\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3785 - accuracy: 0.4443 - val_loss: 2.3810 - val_accuracy: 0.2400\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3779 - accuracy: 0.4443 - val_loss: 2.3704 - val_accuracy: 0.2400\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3780 - accuracy: 0.4414 - val_loss: 2.3673 - val_accuracy: 0.2533\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3782 - accuracy: 0.4471 - val_loss: 2.3719 - val_accuracy: 0.2400\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3770 - accuracy: 0.4471 - val_loss: 2.3847 - val_accuracy: 0.2533\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3782 - accuracy: 0.4429 - val_loss: 2.3637 - val_accuracy: 0.2333\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3784 - accuracy: 0.4471 - val_loss: 2.3890 - val_accuracy: 0.2433\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3771 - accuracy: 0.4414 - val_loss: 2.3778 - val_accuracy: 0.2533\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3776 - accuracy: 0.4471 - val_loss: 2.3988 - val_accuracy: 0.2400\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3771 - accuracy: 0.4486 - val_loss: 2.3753 - val_accuracy: 0.2333\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3769 - accuracy: 0.4543 - val_loss: 2.3642 - val_accuracy: 0.2500\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3781 - accuracy: 0.4457 - val_loss: 2.3738 - val_accuracy: 0.2500\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3766 - accuracy: 0.4471 - val_loss: 2.3861 - val_accuracy: 0.2533\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3766 - accuracy: 0.4486 - val_loss: 2.3700 - val_accuracy: 0.2400\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3765 - accuracy: 0.4514 - val_loss: 2.3865 - val_accuracy: 0.2500\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3769 - accuracy: 0.4457 - val_loss: 2.3861 - val_accuracy: 0.2467\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3753 - accuracy: 0.4571 - val_loss: 2.3644 - val_accuracy: 0.2433\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3779 - accuracy: 0.4429 - val_loss: 2.3857 - val_accuracy: 0.2533\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3761 - accuracy: 0.4429 - val_loss: 2.3808 - val_accuracy: 0.2367\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3762 - accuracy: 0.4557 - val_loss: 2.3937 - val_accuracy: 0.2533\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3767 - accuracy: 0.4457 - val_loss: 2.4162 - val_accuracy: 0.2500\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3767 - accuracy: 0.4471 - val_loss: 2.4176 - val_accuracy: 0.2467\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3761 - accuracy: 0.4500 - val_loss: 2.3906 - val_accuracy: 0.2467\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3756 - accuracy: 0.4471 - val_loss: 2.3871 - val_accuracy: 0.2500\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3750 - accuracy: 0.4400 - val_loss: 2.3934 - val_accuracy: 0.2367\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3754 - accuracy: 0.4414 - val_loss: 2.4011 - val_accuracy: 0.2533\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3758 - accuracy: 0.4414 - val_loss: 2.3780 - val_accuracy: 0.2533\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3752 - accuracy: 0.4500 - val_loss: 2.3785 - val_accuracy: 0.2533\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3748 - accuracy: 0.4500 - val_loss: 2.4023 - val_accuracy: 0.2533\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3758 - accuracy: 0.4471 - val_loss: 2.3591 - val_accuracy: 0.2500\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3755 - accuracy: 0.4471 - val_loss: 2.3990 - val_accuracy: 0.2467\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3755 - accuracy: 0.4500 - val_loss: 2.4115 - val_accuracy: 0.2500\n",
      "Epoch 1110/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3746 - accuracy: 0.4414 - val_loss: 2.3729 - val_accuracy: 0.2433\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3742 - accuracy: 0.4543 - val_loss: 2.3964 - val_accuracy: 0.2500\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3742 - accuracy: 0.4457 - val_loss: 2.4009 - val_accuracy: 0.2400\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3738 - accuracy: 0.4486 - val_loss: 2.4031 - val_accuracy: 0.2533\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3746 - accuracy: 0.4486 - val_loss: 2.3946 - val_accuracy: 0.2533\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3756 - accuracy: 0.4457 - val_loss: 2.3857 - val_accuracy: 0.2533\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3737 - accuracy: 0.4500 - val_loss: 2.4026 - val_accuracy: 0.2500\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3737 - accuracy: 0.4529 - val_loss: 2.3940 - val_accuracy: 0.2467\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3739 - accuracy: 0.4557 - val_loss: 2.3943 - val_accuracy: 0.2467\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3732 - accuracy: 0.4386 - val_loss: 2.3894 - val_accuracy: 0.2333\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3733 - accuracy: 0.4543 - val_loss: 2.4235 - val_accuracy: 0.2500\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3744 - accuracy: 0.4471 - val_loss: 2.3780 - val_accuracy: 0.2433\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3736 - accuracy: 0.4486 - val_loss: 2.4027 - val_accuracy: 0.2533\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3730 - accuracy: 0.4514 - val_loss: 2.4025 - val_accuracy: 0.2467\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3739 - accuracy: 0.4500 - val_loss: 2.3965 - val_accuracy: 0.2400\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3735 - accuracy: 0.4471 - val_loss: 2.3919 - val_accuracy: 0.2533\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3722 - accuracy: 0.4529 - val_loss: 2.3982 - val_accuracy: 0.2533\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3730 - accuracy: 0.4586 - val_loss: 2.4060 - val_accuracy: 0.2533\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3737 - accuracy: 0.4457 - val_loss: 2.4372 - val_accuracy: 0.2500\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3720 - accuracy: 0.4457 - val_loss: 2.4131 - val_accuracy: 0.2333\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3727 - accuracy: 0.4429 - val_loss: 2.4031 - val_accuracy: 0.2433\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3773 - accuracy: 0.40 - 0s 64us/step - loss: 1.3709 - accuracy: 0.4457 - val_loss: 2.4240 - val_accuracy: 0.2533\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3738 - accuracy: 0.4514 - val_loss: 2.4069 - val_accuracy: 0.2467\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3715 - accuracy: 0.4514 - val_loss: 2.4214 - val_accuracy: 0.2467\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3717 - accuracy: 0.4457 - val_loss: 2.4085 - val_accuracy: 0.2333\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3726 - accuracy: 0.4514 - val_loss: 2.4087 - val_accuracy: 0.2467\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3718 - accuracy: 0.4514 - val_loss: 2.3966 - val_accuracy: 0.2467\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3726 - accuracy: 0.4500 - val_loss: 2.4056 - val_accuracy: 0.2467\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3716 - accuracy: 0.4471 - val_loss: 2.4076 - val_accuracy: 0.2433\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3717 - accuracy: 0.4557 - val_loss: 2.3976 - val_accuracy: 0.2467\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3701 - accuracy: 0.4557 - val_loss: 2.3885 - val_accuracy: 0.2300\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3715 - accuracy: 0.4500 - val_loss: 2.4364 - val_accuracy: 0.2500\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3718 - accuracy: 0.4557 - val_loss: 2.4286 - val_accuracy: 0.2500\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3707 - accuracy: 0.4457 - val_loss: 2.4246 - val_accuracy: 0.2433\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3686 - accuracy: 0.4443 - val_loss: 2.4378 - val_accuracy: 0.2367\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3718 - accuracy: 0.4529 - val_loss: 2.4172 - val_accuracy: 0.2467\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3705 - accuracy: 0.4514 - val_loss: 2.4258 - val_accuracy: 0.2333\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3702 - accuracy: 0.4529 - val_loss: 2.4031 - val_accuracy: 0.2333\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3715 - accuracy: 0.4543 - val_loss: 2.4235 - val_accuracy: 0.2467\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3712 - accuracy: 0.4457 - val_loss: 2.4239 - val_accuracy: 0.2367\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3713 - accuracy: 0.4486 - val_loss: 2.3925 - val_accuracy: 0.2400\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3712 - accuracy: 0.4514 - val_loss: 2.4041 - val_accuracy: 0.2433\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3697 - accuracy: 0.4529 - val_loss: 2.4164 - val_accuracy: 0.2533\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3711 - accuracy: 0.4471 - val_loss: 2.4291 - val_accuracy: 0.2467\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3699 - accuracy: 0.4543 - val_loss: 2.3820 - val_accuracy: 0.2367\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3697 - accuracy: 0.4514 - val_loss: 2.4190 - val_accuracy: 0.2433\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3706 - accuracy: 0.4457 - val_loss: 2.4048 - val_accuracy: 0.2300\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3707 - accuracy: 0.4529 - val_loss: 2.4173 - val_accuracy: 0.2433\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3696 - accuracy: 0.4543 - val_loss: 2.4481 - val_accuracy: 0.2533\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3697 - accuracy: 0.4457 - val_loss: 2.4223 - val_accuracy: 0.2433\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3708 - accuracy: 0.4543 - val_loss: 2.4358 - val_accuracy: 0.2333\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3693 - accuracy: 0.4571 - val_loss: 2.4256 - val_accuracy: 0.2467\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3693 - accuracy: 0.4571 - val_loss: 2.4286 - val_accuracy: 0.2467\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3691 - accuracy: 0.4543 - val_loss: 2.4364 - val_accuracy: 0.2467\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3688 - accuracy: 0.4586 - val_loss: 2.4378 - val_accuracy: 0.2333\n",
      "Epoch 1165/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3701 - accuracy: 0.4571 - val_loss: 2.3936 - val_accuracy: 0.2367\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3689 - accuracy: 0.4543 - val_loss: 2.4123 - val_accuracy: 0.2433\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3689 - accuracy: 0.4557 - val_loss: 2.4247 - val_accuracy: 0.2433\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3688 - accuracy: 0.4529 - val_loss: 2.4140 - val_accuracy: 0.2333\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3682 - accuracy: 0.4529 - val_loss: 2.4288 - val_accuracy: 0.2467\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3682 - accuracy: 0.4514 - val_loss: 2.4249 - val_accuracy: 0.2467\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3676 - accuracy: 0.4514 - val_loss: 2.4115 - val_accuracy: 0.2433\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3681 - accuracy: 0.4529 - val_loss: 2.4387 - val_accuracy: 0.2433\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3678 - accuracy: 0.4514 - val_loss: 2.4268 - val_accuracy: 0.2300\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3688 - accuracy: 0.4471 - val_loss: 2.4151 - val_accuracy: 0.2433\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3671 - accuracy: 0.4514 - val_loss: 2.4241 - val_accuracy: 0.2433\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3680 - accuracy: 0.4500 - val_loss: 2.4368 - val_accuracy: 0.2433\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3681 - accuracy: 0.4514 - val_loss: 2.4471 - val_accuracy: 0.2467\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3675 - accuracy: 0.4500 - val_loss: 2.4336 - val_accuracy: 0.2267\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3677 - accuracy: 0.4543 - val_loss: 2.4346 - val_accuracy: 0.2300\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3678 - accuracy: 0.4514 - val_loss: 2.4402 - val_accuracy: 0.2400\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3672 - accuracy: 0.4571 - val_loss: 2.4477 - val_accuracy: 0.2500\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3679 - accuracy: 0.4557 - val_loss: 2.4301 - val_accuracy: 0.2400\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3673 - accuracy: 0.4500 - val_loss: 2.4334 - val_accuracy: 0.2433\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3663 - accuracy: 0.4586 - val_loss: 2.4227 - val_accuracy: 0.2467\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3675 - accuracy: 0.4557 - val_loss: 2.4282 - val_accuracy: 0.2400\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3671 - accuracy: 0.4471 - val_loss: 2.4531 - val_accuracy: 0.2467\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3664 - accuracy: 0.4529 - val_loss: 2.4296 - val_accuracy: 0.2333\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3665 - accuracy: 0.4543 - val_loss: 2.4561 - val_accuracy: 0.2467\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3656 - accuracy: 0.4600 - val_loss: 2.4385 - val_accuracy: 0.2467\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3665 - accuracy: 0.4500 - val_loss: 2.4635 - val_accuracy: 0.2500\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3668 - accuracy: 0.4486 - val_loss: 2.4467 - val_accuracy: 0.2333\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3664 - accuracy: 0.4600 - val_loss: 2.4209 - val_accuracy: 0.2433\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3669 - accuracy: 0.4557 - val_loss: 2.4436 - val_accuracy: 0.2400\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3660 - accuracy: 0.4500 - val_loss: 2.4313 - val_accuracy: 0.2300\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3666 - accuracy: 0.4543 - val_loss: 2.4317 - val_accuracy: 0.2267\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3657 - accuracy: 0.4614 - val_loss: 2.4489 - val_accuracy: 0.2500\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3658 - accuracy: 0.4557 - val_loss: 2.4299 - val_accuracy: 0.2433\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3653 - accuracy: 0.4529 - val_loss: 2.4437 - val_accuracy: 0.2467\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3656 - accuracy: 0.4543 - val_loss: 2.4290 - val_accuracy: 0.2300\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3662 - accuracy: 0.4500 - val_loss: 2.4460 - val_accuracy: 0.2400\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3651 - accuracy: 0.4600 - val_loss: 2.4490 - val_accuracy: 0.2433\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3660 - accuracy: 0.4529 - val_loss: 2.4605 - val_accuracy: 0.2467\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3653 - accuracy: 0.4571 - val_loss: 2.4225 - val_accuracy: 0.2467\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3654 - accuracy: 0.4643 - val_loss: 2.4242 - val_accuracy: 0.2467\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3639 - accuracy: 0.4571 - val_loss: 2.4371 - val_accuracy: 0.2433\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3649 - accuracy: 0.4600 - val_loss: 2.4495 - val_accuracy: 0.2433\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3637 - accuracy: 0.4571 - val_loss: 2.4561 - val_accuracy: 0.2233\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3636 - accuracy: 0.4514 - val_loss: 2.4504 - val_accuracy: 0.2267\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3630 - accuracy: 0.4600 - val_loss: 2.4415 - val_accuracy: 0.2433\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3648 - accuracy: 0.4557 - val_loss: 2.4462 - val_accuracy: 0.2433\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3645 - accuracy: 0.4586 - val_loss: 2.4559 - val_accuracy: 0.2433\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3631 - accuracy: 0.4471 - val_loss: 2.4737 - val_accuracy: 0.2500\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3655 - accuracy: 0.4557 - val_loss: 2.4452 - val_accuracy: 0.2433\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3634 - accuracy: 0.4557 - val_loss: 2.4679 - val_accuracy: 0.2467\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3633 - accuracy: 0.4529 - val_loss: 2.4549 - val_accuracy: 0.2467\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3637 - accuracy: 0.4571 - val_loss: 2.4434 - val_accuracy: 0.2433\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3636 - accuracy: 0.4514 - val_loss: 2.4625 - val_accuracy: 0.2433\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3634 - accuracy: 0.4586 - val_loss: 2.4542 - val_accuracy: 0.2433\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3632 - accuracy: 0.4529 - val_loss: 2.4596 - val_accuracy: 0.2467\n",
      "Epoch 1220/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3642 - accuracy: 0.4529 - val_loss: 2.4367 - val_accuracy: 0.2433\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3633 - accuracy: 0.4614 - val_loss: 2.4614 - val_accuracy: 0.2300\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3633 - accuracy: 0.4586 - val_loss: 2.4712 - val_accuracy: 0.2433\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3632 - accuracy: 0.4586 - val_loss: 2.4696 - val_accuracy: 0.2467\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3625 - accuracy: 0.4571 - val_loss: 2.4725 - val_accuracy: 0.2467\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3621 - accuracy: 0.4529 - val_loss: 2.4651 - val_accuracy: 0.2300\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3636 - accuracy: 0.4629 - val_loss: 2.4592 - val_accuracy: 0.2433\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3609 - accuracy: 0.4543 - val_loss: 2.4483 - val_accuracy: 0.2433\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3626 - accuracy: 0.4614 - val_loss: 2.4718 - val_accuracy: 0.2433\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3630 - accuracy: 0.4543 - val_loss: 2.4582 - val_accuracy: 0.2433\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3624 - accuracy: 0.4600 - val_loss: 2.4488 - val_accuracy: 0.2467\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3629 - accuracy: 0.4571 - val_loss: 2.4342 - val_accuracy: 0.2333\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3626 - accuracy: 0.4543 - val_loss: 2.4819 - val_accuracy: 0.2500\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3632 - accuracy: 0.4586 - val_loss: 2.4497 - val_accuracy: 0.2433\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3616 - accuracy: 0.4686 - val_loss: 2.4396 - val_accuracy: 0.2467\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3618 - accuracy: 0.4571 - val_loss: 2.4482 - val_accuracy: 0.2400\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3620 - accuracy: 0.4543 - val_loss: 2.4448 - val_accuracy: 0.2367\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3622 - accuracy: 0.4486 - val_loss: 2.4273 - val_accuracy: 0.2500\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3610 - accuracy: 0.4586 - val_loss: 2.4741 - val_accuracy: 0.2467\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3620 - accuracy: 0.4514 - val_loss: 2.4538 - val_accuracy: 0.2400\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3614 - accuracy: 0.4557 - val_loss: 2.4519 - val_accuracy: 0.2433\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3614 - accuracy: 0.4557 - val_loss: 2.4660 - val_accuracy: 0.2400\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3609 - accuracy: 0.4514 - val_loss: 2.4591 - val_accuracy: 0.2433\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3612 - accuracy: 0.4614 - val_loss: 2.4818 - val_accuracy: 0.2467\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3611 - accuracy: 0.4529 - val_loss: 2.4443 - val_accuracy: 0.2467\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3607 - accuracy: 0.4614 - val_loss: 2.4528 - val_accuracy: 0.2433\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3603 - accuracy: 0.4600 - val_loss: 2.4831 - val_accuracy: 0.2433\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3601 - accuracy: 0.4614 - val_loss: 2.4707 - val_accuracy: 0.2433\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3607 - accuracy: 0.4557 - val_loss: 2.4791 - val_accuracy: 0.2400\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3611 - accuracy: 0.4557 - val_loss: 2.4662 - val_accuracy: 0.2400\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3596 - accuracy: 0.4571 - val_loss: 2.5088 - val_accuracy: 0.2300\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3608 - accuracy: 0.4586 - val_loss: 2.4743 - val_accuracy: 0.2400\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3597 - accuracy: 0.4643 - val_loss: 2.4841 - val_accuracy: 0.2433\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3609 - accuracy: 0.4500 - val_loss: 2.4688 - val_accuracy: 0.2400\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3600 - accuracy: 0.4614 - val_loss: 2.4605 - val_accuracy: 0.2433\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3602 - accuracy: 0.4571 - val_loss: 2.4620 - val_accuracy: 0.2433\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3592 - accuracy: 0.4586 - val_loss: 2.4859 - val_accuracy: 0.2333\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3599 - accuracy: 0.4586 - val_loss: 2.4925 - val_accuracy: 0.2467\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3600 - accuracy: 0.4686 - val_loss: 2.4568 - val_accuracy: 0.2433\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3597 - accuracy: 0.4600 - val_loss: 2.4545 - val_accuracy: 0.2433\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3592 - accuracy: 0.4600 - val_loss: 2.4853 - val_accuracy: 0.2467\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3599 - accuracy: 0.4586 - val_loss: 2.4733 - val_accuracy: 0.2400\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3597 - accuracy: 0.4571 - val_loss: 2.4772 - val_accuracy: 0.2400\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3590 - accuracy: 0.4700 - val_loss: 2.4737 - val_accuracy: 0.2400\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3593 - accuracy: 0.4586 - val_loss: 2.4638 - val_accuracy: 0.2333\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3593 - accuracy: 0.4614 - val_loss: 2.4736 - val_accuracy: 0.2367\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3591 - accuracy: 0.4571 - val_loss: 2.4519 - val_accuracy: 0.2467\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3586 - accuracy: 0.4571 - val_loss: 2.4640 - val_accuracy: 0.2400\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3596 - accuracy: 0.4629 - val_loss: 2.4807 - val_accuracy: 0.2433\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3588 - accuracy: 0.4643 - val_loss: 2.4991 - val_accuracy: 0.2500\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3584 - accuracy: 0.4614 - val_loss: 2.4851 - val_accuracy: 0.2433\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3589 - accuracy: 0.4557 - val_loss: 2.4717 - val_accuracy: 0.2400\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3581 - accuracy: 0.4629 - val_loss: 2.4797 - val_accuracy: 0.2433\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3584 - accuracy: 0.4571 - val_loss: 2.4822 - val_accuracy: 0.2433\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3586 - accuracy: 0.4614 - val_loss: 2.4796 - val_accuracy: 0.2433\n",
      "Epoch 1275/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3575 - accuracy: 0.4629 - val_loss: 2.4867 - val_accuracy: 0.2433\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3587 - accuracy: 0.4600 - val_loss: 2.4842 - val_accuracy: 0.2433\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3580 - accuracy: 0.4600 - val_loss: 2.4837 - val_accuracy: 0.2467\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3575 - accuracy: 0.4614 - val_loss: 2.5011 - val_accuracy: 0.2467\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3575 - accuracy: 0.4557 - val_loss: 2.4813 - val_accuracy: 0.2400\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3577 - accuracy: 0.4614 - val_loss: 2.4975 - val_accuracy: 0.2433\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3572 - accuracy: 0.4514 - val_loss: 2.4804 - val_accuracy: 0.2433\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3576 - accuracy: 0.4586 - val_loss: 2.4914 - val_accuracy: 0.2433\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3573 - accuracy: 0.4671 - val_loss: 2.5163 - val_accuracy: 0.2467\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3573 - accuracy: 0.4629 - val_loss: 2.5124 - val_accuracy: 0.2533\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3548 - accuracy: 0.4571 - val_loss: 2.4656 - val_accuracy: 0.2333\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3547 - accuracy: 0.4643 - val_loss: 2.5010 - val_accuracy: 0.2500\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3574 - accuracy: 0.4629 - val_loss: 2.5161 - val_accuracy: 0.2500\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3565 - accuracy: 0.4571 - val_loss: 2.4953 - val_accuracy: 0.2467\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3569 - accuracy: 0.4671 - val_loss: 2.4891 - val_accuracy: 0.2467\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3569 - accuracy: 0.4629 - val_loss: 2.4831 - val_accuracy: 0.2400\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3571 - accuracy: 0.4629 - val_loss: 2.5058 - val_accuracy: 0.2400\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3563 - accuracy: 0.4600 - val_loss: 2.5124 - val_accuracy: 0.2533\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3565 - accuracy: 0.4614 - val_loss: 2.4972 - val_accuracy: 0.2400\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3566 - accuracy: 0.4643 - val_loss: 2.5009 - val_accuracy: 0.2367\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3556 - accuracy: 0.4671 - val_loss: 2.4956 - val_accuracy: 0.2433\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3567 - accuracy: 0.4671 - val_loss: 2.4943 - val_accuracy: 0.2400\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3561 - accuracy: 0.4700 - val_loss: 2.4860 - val_accuracy: 0.2433\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3563 - accuracy: 0.4643 - val_loss: 2.4872 - val_accuracy: 0.2400\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3549 - accuracy: 0.4657 - val_loss: 2.5103 - val_accuracy: 0.2400\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3547 - accuracy: 0.4671 - val_loss: 2.4812 - val_accuracy: 0.2333\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3544 - accuracy: 0.4529 - val_loss: 2.4786 - val_accuracy: 0.2400\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3560 - accuracy: 0.4614 - val_loss: 2.5031 - val_accuracy: 0.2467\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3560 - accuracy: 0.4643 - val_loss: 2.5031 - val_accuracy: 0.2400\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3556 - accuracy: 0.4729 - val_loss: 2.5089 - val_accuracy: 0.2433\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3548 - accuracy: 0.4643 - val_loss: 2.5116 - val_accuracy: 0.2500\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3550 - accuracy: 0.4586 - val_loss: 2.4953 - val_accuracy: 0.2467\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3555 - accuracy: 0.4643 - val_loss: 2.4956 - val_accuracy: 0.2433\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3541 - accuracy: 0.4600 - val_loss: 2.4838 - val_accuracy: 0.2400\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3540 - accuracy: 0.4643 - val_loss: 2.5008 - val_accuracy: 0.2300\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3551 - accuracy: 0.4643 - val_loss: 2.5070 - val_accuracy: 0.2467\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3555 - accuracy: 0.4671 - val_loss: 2.5050 - val_accuracy: 0.2433\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3545 - accuracy: 0.4614 - val_loss: 2.5020 - val_accuracy: 0.2467\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3544 - accuracy: 0.4614 - val_loss: 2.4838 - val_accuracy: 0.2400\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3540 - accuracy: 0.4571 - val_loss: 2.5158 - val_accuracy: 0.2367\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3536 - accuracy: 0.4657 - val_loss: 2.4860 - val_accuracy: 0.2467\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3545 - accuracy: 0.4643 - val_loss: 2.5217 - val_accuracy: 0.2500\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3538 - accuracy: 0.4586 - val_loss: 2.4960 - val_accuracy: 0.2300\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3545 - accuracy: 0.4657 - val_loss: 2.4824 - val_accuracy: 0.2433\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3545 - accuracy: 0.4700 - val_loss: 2.5131 - val_accuracy: 0.2533\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3541 - accuracy: 0.4600 - val_loss: 2.4959 - val_accuracy: 0.2433\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3534 - accuracy: 0.4657 - val_loss: 2.5010 - val_accuracy: 0.2500\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3536 - accuracy: 0.4629 - val_loss: 2.4931 - val_accuracy: 0.2400\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3532 - accuracy: 0.4643 - val_loss: 2.5518 - val_accuracy: 0.2467\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3539 - accuracy: 0.4629 - val_loss: 2.5080 - val_accuracy: 0.2400\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3525 - accuracy: 0.4629 - val_loss: 2.5249 - val_accuracy: 0.2367\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3539 - accuracy: 0.4657 - val_loss: 2.5024 - val_accuracy: 0.2400\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3532 - accuracy: 0.4671 - val_loss: 2.4968 - val_accuracy: 0.2400\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3529 - accuracy: 0.4643 - val_loss: 2.5416 - val_accuracy: 0.2500\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3532 - accuracy: 0.4657 - val_loss: 2.5075 - val_accuracy: 0.2500\n",
      "Epoch 1330/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3533 - accuracy: 0.4600 - val_loss: 2.5370 - val_accuracy: 0.2400\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3532 - accuracy: 0.4643 - val_loss: 2.5303 - val_accuracy: 0.2533\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3528 - accuracy: 0.4671 - val_loss: 2.5211 - val_accuracy: 0.2433\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3525 - accuracy: 0.4643 - val_loss: 2.4991 - val_accuracy: 0.2400\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3520 - accuracy: 0.4657 - val_loss: 2.5432 - val_accuracy: 0.2500\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3530 - accuracy: 0.4586 - val_loss: 2.4993 - val_accuracy: 0.2400\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3532 - accuracy: 0.4714 - val_loss: 2.5237 - val_accuracy: 0.2433\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3524 - accuracy: 0.4629 - val_loss: 2.5068 - val_accuracy: 0.2433\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3520 - accuracy: 0.4586 - val_loss: 2.5152 - val_accuracy: 0.2400\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3520 - accuracy: 0.4671 - val_loss: 2.5497 - val_accuracy: 0.2467\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3180 - accuracy: 0.60 - 0s 61us/step - loss: 1.3526 - accuracy: 0.4643 - val_loss: 2.5148 - val_accuracy: 0.2467\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3521 - accuracy: 0.4714 - val_loss: 2.5249 - val_accuracy: 0.2467\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3523 - accuracy: 0.4700 - val_loss: 2.5136 - val_accuracy: 0.2433\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3514 - accuracy: 0.4629 - val_loss: 2.5182 - val_accuracy: 0.2467\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3517 - accuracy: 0.4629 - val_loss: 2.5268 - val_accuracy: 0.2500\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3512 - accuracy: 0.4714 - val_loss: 2.5456 - val_accuracy: 0.2500\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3513 - accuracy: 0.4600 - val_loss: 2.4946 - val_accuracy: 0.2400\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3523 - accuracy: 0.4700 - val_loss: 2.5174 - val_accuracy: 0.2467\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3506 - accuracy: 0.4643 - val_loss: 2.5170 - val_accuracy: 0.2433\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3508 - accuracy: 0.4643 - val_loss: 2.5316 - val_accuracy: 0.2467\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3514 - accuracy: 0.4657 - val_loss: 2.5330 - val_accuracy: 0.2433\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3512 - accuracy: 0.4686 - val_loss: 2.5341 - val_accuracy: 0.2500\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3513 - accuracy: 0.4714 - val_loss: 2.5058 - val_accuracy: 0.2400\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3507 - accuracy: 0.4686 - val_loss: 2.5294 - val_accuracy: 0.2433\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3513 - accuracy: 0.4629 - val_loss: 2.5016 - val_accuracy: 0.2400\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3500 - accuracy: 0.4700 - val_loss: 2.5319 - val_accuracy: 0.2433\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3512 - accuracy: 0.4643 - val_loss: 2.5323 - val_accuracy: 0.2400\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3517 - accuracy: 0.4686 - val_loss: 2.5376 - val_accuracy: 0.2467\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3506 - accuracy: 0.4643 - val_loss: 2.5133 - val_accuracy: 0.2433\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3497 - accuracy: 0.4671 - val_loss: 2.5463 - val_accuracy: 0.2400\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3507 - accuracy: 0.4657 - val_loss: 2.5322 - val_accuracy: 0.2433\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3510 - accuracy: 0.4629 - val_loss: 2.5432 - val_accuracy: 0.2467\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3497 - accuracy: 0.4629 - val_loss: 2.5164 - val_accuracy: 0.2433\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3506 - accuracy: 0.4714 - val_loss: 2.5269 - val_accuracy: 0.2433\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3498 - accuracy: 0.4643 - val_loss: 2.5448 - val_accuracy: 0.2467\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3505 - accuracy: 0.4729 - val_loss: 2.5087 - val_accuracy: 0.2400\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3499 - accuracy: 0.4686 - val_loss: 2.5339 - val_accuracy: 0.2433\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3499 - accuracy: 0.4757 - val_loss: 2.5131 - val_accuracy: 0.2433\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3504 - accuracy: 0.4671 - val_loss: 2.5416 - val_accuracy: 0.2467\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3505 - accuracy: 0.4686 - val_loss: 2.5629 - val_accuracy: 0.2433\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3490 - accuracy: 0.4657 - val_loss: 2.5629 - val_accuracy: 0.2467\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3502 - accuracy: 0.4714 - val_loss: 2.5404 - val_accuracy: 0.2400\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3495 - accuracy: 0.4686 - val_loss: 2.5402 - val_accuracy: 0.2400\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3495 - accuracy: 0.4714 - val_loss: 2.5460 - val_accuracy: 0.2533\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3494 - accuracy: 0.4643 - val_loss: 2.5523 - val_accuracy: 0.2500\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3496 - accuracy: 0.4743 - val_loss: 2.5248 - val_accuracy: 0.2433\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3488 - accuracy: 0.4700 - val_loss: 2.5314 - val_accuracy: 0.2500\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3495 - accuracy: 0.4686 - val_loss: 2.5093 - val_accuracy: 0.2433\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3490 - accuracy: 0.4714 - val_loss: 2.5521 - val_accuracy: 0.2500\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3487 - accuracy: 0.4643 - val_loss: 2.5612 - val_accuracy: 0.2433\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3483 - accuracy: 0.4671 - val_loss: 2.5491 - val_accuracy: 0.2467\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3487 - accuracy: 0.4686 - val_loss: 2.5499 - val_accuracy: 0.2433\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3470 - accuracy: 0.4729 - val_loss: 2.5616 - val_accuracy: 0.2467\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3481 - accuracy: 0.4643 - val_loss: 2.5498 - val_accuracy: 0.2433\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3487 - accuracy: 0.4700 - val_loss: 2.5387 - val_accuracy: 0.2433\n",
      "Epoch 1385/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3475 - accuracy: 0.4743 - val_loss: 2.5509 - val_accuracy: 0.2467\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3480 - accuracy: 0.4600 - val_loss: 2.5393 - val_accuracy: 0.2333\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3478 - accuracy: 0.4700 - val_loss: 2.5598 - val_accuracy: 0.2300\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3481 - accuracy: 0.4657 - val_loss: 2.5517 - val_accuracy: 0.2433\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3471 - accuracy: 0.4671 - val_loss: 2.5614 - val_accuracy: 0.2467\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3481 - accuracy: 0.4657 - val_loss: 2.5490 - val_accuracy: 0.2433\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3483 - accuracy: 0.4657 - val_loss: 2.5623 - val_accuracy: 0.2467\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3483 - accuracy: 0.4600 - val_loss: 2.5656 - val_accuracy: 0.2400\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3475 - accuracy: 0.4700 - val_loss: 2.5671 - val_accuracy: 0.2467\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3463 - accuracy: 0.4586 - val_loss: 2.5563 - val_accuracy: 0.2267\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3475 - accuracy: 0.4671 - val_loss: 2.5644 - val_accuracy: 0.2300\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3483 - accuracy: 0.4643 - val_loss: 2.5414 - val_accuracy: 0.2500\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3462 - accuracy: 0.4657 - val_loss: 2.5557 - val_accuracy: 0.2467\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3474 - accuracy: 0.4657 - val_loss: 2.5734 - val_accuracy: 0.2500\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3466 - accuracy: 0.4757 - val_loss: 2.5919 - val_accuracy: 0.2500\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3460 - accuracy: 0.4657 - val_loss: 2.6060 - val_accuracy: 0.2467\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.2157 - accuracy: 0.50 - 0s 66us/step - loss: 1.3471 - accuracy: 0.4714 - val_loss: 2.5623 - val_accuracy: 0.2500\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3464 - accuracy: 0.4714 - val_loss: 2.5495 - val_accuracy: 0.2433\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3450 - accuracy: 0.4671 - val_loss: 2.5464 - val_accuracy: 0.2467\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3467 - accuracy: 0.4586 - val_loss: 2.5844 - val_accuracy: 0.2467\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3465 - accuracy: 0.4614 - val_loss: 2.5606 - val_accuracy: 0.2467\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3466 - accuracy: 0.4671 - val_loss: 2.5438 - val_accuracy: 0.2400\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3464 - accuracy: 0.4714 - val_loss: 2.5516 - val_accuracy: 0.2433\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3459 - accuracy: 0.4686 - val_loss: 2.5539 - val_accuracy: 0.2467\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3458 - accuracy: 0.4657 - val_loss: 2.5339 - val_accuracy: 0.2467\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3464 - accuracy: 0.4686 - val_loss: 2.5373 - val_accuracy: 0.2467\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5891 - val_accuracy: 0.2467\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3462 - accuracy: 0.4729 - val_loss: 2.5486 - val_accuracy: 0.2467\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3458 - accuracy: 0.4643 - val_loss: 2.5771 - val_accuracy: 0.2400\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3466 - accuracy: 0.4657 - val_loss: 2.5414 - val_accuracy: 0.2433\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3458 - accuracy: 0.4743 - val_loss: 2.5668 - val_accuracy: 0.2500\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5674 - val_accuracy: 0.2500\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3462 - accuracy: 0.4714 - val_loss: 2.5347 - val_accuracy: 0.2500\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3449 - accuracy: 0.4629 - val_loss: 2.5530 - val_accuracy: 0.2467\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3457 - accuracy: 0.4686 - val_loss: 2.5247 - val_accuracy: 0.2433\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3458 - accuracy: 0.4714 - val_loss: 2.5874 - val_accuracy: 0.2433\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3458 - accuracy: 0.4657 - val_loss: 2.5665 - val_accuracy: 0.2433\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3439 - accuracy: 0.4700 - val_loss: 2.5543 - val_accuracy: 0.2467\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.3447 - accuracy: 0.4643 - val_loss: 2.5797 - val_accuracy: 0.2400\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3454 - accuracy: 0.4700 - val_loss: 2.5645 - val_accuracy: 0.2433\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3439 - accuracy: 0.4614 - val_loss: 2.5740 - val_accuracy: 0.2333\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3446 - accuracy: 0.4714 - val_loss: 2.5718 - val_accuracy: 0.2467\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3441 - accuracy: 0.4686 - val_loss: 2.5912 - val_accuracy: 0.2467\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3446 - accuracy: 0.4729 - val_loss: 2.5646 - val_accuracy: 0.2467\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3446 - accuracy: 0.4657 - val_loss: 2.5360 - val_accuracy: 0.2433\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3445 - accuracy: 0.4671 - val_loss: 2.5871 - val_accuracy: 0.2467\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3437 - accuracy: 0.4771 - val_loss: 2.5388 - val_accuracy: 0.2400\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3444 - accuracy: 0.4714 - val_loss: 2.5817 - val_accuracy: 0.2433\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3449 - accuracy: 0.4686 - val_loss: 2.5714 - val_accuracy: 0.2467\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3447 - accuracy: 0.4686 - val_loss: 2.5630 - val_accuracy: 0.2467\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3447 - accuracy: 0.4643 - val_loss: 2.5701 - val_accuracy: 0.2433\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3424 - accuracy: 0.4643 - val_loss: 2.5874 - val_accuracy: 0.2467\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3446 - accuracy: 0.4743 - val_loss: 2.5755 - val_accuracy: 0.2467\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3442 - accuracy: 0.4643 - val_loss: 2.5609 - val_accuracy: 0.2433\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3439 - accuracy: 0.4729 - val_loss: 2.5808 - val_accuracy: 0.2500\n",
      "Epoch 1440/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3440 - accuracy: 0.4671 - val_loss: 2.5737 - val_accuracy: 0.2467\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3436 - accuracy: 0.4714 - val_loss: 2.5730 - val_accuracy: 0.2400\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3440 - accuracy: 0.4729 - val_loss: 2.5866 - val_accuracy: 0.2433\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3433 - accuracy: 0.4686 - val_loss: 2.5838 - val_accuracy: 0.2433\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3439 - accuracy: 0.4686 - val_loss: 2.5707 - val_accuracy: 0.2500\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3425 - accuracy: 0.4600 - val_loss: 2.5708 - val_accuracy: 0.2333\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3433 - accuracy: 0.4743 - val_loss: 2.6016 - val_accuracy: 0.2467\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3436 - accuracy: 0.4643 - val_loss: 2.5811 - val_accuracy: 0.2433\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3422 - accuracy: 0.4671 - val_loss: 2.5787 - val_accuracy: 0.2367\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3428 - accuracy: 0.4671 - val_loss: 2.5523 - val_accuracy: 0.2433\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3432 - accuracy: 0.4814 - val_loss: 2.5552 - val_accuracy: 0.2433\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3425 - accuracy: 0.4714 - val_loss: 2.5922 - val_accuracy: 0.2467\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3429 - accuracy: 0.4686 - val_loss: 2.5733 - val_accuracy: 0.2433\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3423 - accuracy: 0.4657 - val_loss: 2.5708 - val_accuracy: 0.2433\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3429 - accuracy: 0.4771 - val_loss: 2.5675 - val_accuracy: 0.2433\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3427 - accuracy: 0.4757 - val_loss: 2.5933 - val_accuracy: 0.2467\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3430 - accuracy: 0.4757 - val_loss: 2.5798 - val_accuracy: 0.2400\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3425 - accuracy: 0.4643 - val_loss: 2.5912 - val_accuracy: 0.2500\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3428 - accuracy: 0.4629 - val_loss: 2.5766 - val_accuracy: 0.2400\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3425 - accuracy: 0.4686 - val_loss: 2.5751 - val_accuracy: 0.2500\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3414 - accuracy: 0.4714 - val_loss: 2.5802 - val_accuracy: 0.2367\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3412 - accuracy: 0.4671 - val_loss: 2.5682 - val_accuracy: 0.2533\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3418 - accuracy: 0.4757 - val_loss: 2.6162 - val_accuracy: 0.2467\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3418 - accuracy: 0.4657 - val_loss: 2.5876 - val_accuracy: 0.2433\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3417 - accuracy: 0.4657 - val_loss: 2.5726 - val_accuracy: 0.2467\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3418 - accuracy: 0.4700 - val_loss: 2.6127 - val_accuracy: 0.2433\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3417 - accuracy: 0.4671 - val_loss: 2.5952 - val_accuracy: 0.2433\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3396 - accuracy: 0.4729 - val_loss: 2.5920 - val_accuracy: 0.2433\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3431 - accuracy: 0.4714 - val_loss: 2.5850 - val_accuracy: 0.2500\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3417 - accuracy: 0.4686 - val_loss: 2.5990 - val_accuracy: 0.2433\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3412 - accuracy: 0.4714 - val_loss: 2.5959 - val_accuracy: 0.2433\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3403 - accuracy: 0.4700 - val_loss: 2.5983 - val_accuracy: 0.2500\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3413 - accuracy: 0.4643 - val_loss: 2.6075 - val_accuracy: 0.2433\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3407 - accuracy: 0.4686 - val_loss: 2.5796 - val_accuracy: 0.2433\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3404 - accuracy: 0.4714 - val_loss: 2.5906 - val_accuracy: 0.2500\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3403 - accuracy: 0.4714 - val_loss: 2.6062 - val_accuracy: 0.2500\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3409 - accuracy: 0.4671 - val_loss: 2.5975 - val_accuracy: 0.2433\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3411 - accuracy: 0.4657 - val_loss: 2.6012 - val_accuracy: 0.2400\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3401 - accuracy: 0.4729 - val_loss: 2.5700 - val_accuracy: 0.2533\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3403 - accuracy: 0.4629 - val_loss: 2.5874 - val_accuracy: 0.2433\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3408 - accuracy: 0.4700 - val_loss: 2.5913 - val_accuracy: 0.2433\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3400 - accuracy: 0.4657 - val_loss: 2.5908 - val_accuracy: 0.2367\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3401 - accuracy: 0.4714 - val_loss: 2.6251 - val_accuracy: 0.2500\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3409 - accuracy: 0.4743 - val_loss: 2.6065 - val_accuracy: 0.2433\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3397 - accuracy: 0.4686 - val_loss: 2.5875 - val_accuracy: 0.2367\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3396 - accuracy: 0.4657 - val_loss: 2.6126 - val_accuracy: 0.2267\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3402 - accuracy: 0.4700 - val_loss: 2.5930 - val_accuracy: 0.2500\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3396 - accuracy: 0.4686 - val_loss: 2.6135 - val_accuracy: 0.2467\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3391 - accuracy: 0.4629 - val_loss: 2.5694 - val_accuracy: 0.2400\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3399 - accuracy: 0.4700 - val_loss: 2.6190 - val_accuracy: 0.2367\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3390 - accuracy: 0.4686 - val_loss: 2.6249 - val_accuracy: 0.2467\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3395 - accuracy: 0.4714 - val_loss: 2.6218 - val_accuracy: 0.2433\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3378 - accuracy: 0.4714 - val_loss: 2.6114 - val_accuracy: 0.2367\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3412 - accuracy: 0.4614 - val_loss: 2.6008 - val_accuracy: 0.2500\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3398 - accuracy: 0.4743 - val_loss: 2.5969 - val_accuracy: 0.2500\n",
      "Epoch 1495/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3383 - accuracy: 0.4686 - val_loss: 2.5987 - val_accuracy: 0.2433\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3393 - accuracy: 0.4714 - val_loss: 2.5972 - val_accuracy: 0.2500\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3383 - accuracy: 0.4671 - val_loss: 2.6129 - val_accuracy: 0.2433\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3387 - accuracy: 0.4743 - val_loss: 2.6393 - val_accuracy: 0.2500\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3395 - accuracy: 0.4700 - val_loss: 2.6042 - val_accuracy: 0.2467\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3388 - accuracy: 0.4771 - val_loss: 2.6116 - val_accuracy: 0.2433\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3389 - accuracy: 0.4729 - val_loss: 2.6054 - val_accuracy: 0.2467\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3390 - accuracy: 0.4714 - val_loss: 2.6098 - val_accuracy: 0.2467\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3390 - accuracy: 0.4657 - val_loss: 2.6042 - val_accuracy: 0.2433\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3381 - accuracy: 0.4743 - val_loss: 2.6240 - val_accuracy: 0.2433\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3386 - accuracy: 0.4686 - val_loss: 2.6131 - val_accuracy: 0.2400\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3391 - accuracy: 0.4786 - val_loss: 2.5983 - val_accuracy: 0.2433\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3382 - accuracy: 0.4714 - val_loss: 2.6043 - val_accuracy: 0.2367\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3387 - accuracy: 0.4643 - val_loss: 2.6308 - val_accuracy: 0.2467\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3382 - accuracy: 0.4757 - val_loss: 2.6092 - val_accuracy: 0.2433\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3384 - accuracy: 0.4743 - val_loss: 2.6532 - val_accuracy: 0.2467\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3379 - accuracy: 0.4729 - val_loss: 2.6494 - val_accuracy: 0.2500\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3368 - accuracy: 0.4714 - val_loss: 2.6204 - val_accuracy: 0.2433\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3380 - accuracy: 0.4686 - val_loss: 2.5901 - val_accuracy: 0.2433\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3381 - accuracy: 0.4671 - val_loss: 2.6135 - val_accuracy: 0.2433\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3377 - accuracy: 0.4757 - val_loss: 2.6393 - val_accuracy: 0.2500\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3395 - accuracy: 0.4743 - val_loss: 2.6289 - val_accuracy: 0.2467\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3373 - accuracy: 0.4743 - val_loss: 2.6084 - val_accuracy: 0.2467\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3371 - accuracy: 0.4757 - val_loss: 2.5965 - val_accuracy: 0.2500\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3370 - accuracy: 0.4757 - val_loss: 2.5948 - val_accuracy: 0.2367\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3373 - accuracy: 0.4700 - val_loss: 2.6313 - val_accuracy: 0.2467\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3368 - accuracy: 0.4800 - val_loss: 2.5999 - val_accuracy: 0.2433\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3379 - accuracy: 0.4714 - val_loss: 2.6182 - val_accuracy: 0.2467\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3371 - accuracy: 0.4743 - val_loss: 2.6055 - val_accuracy: 0.2467\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3374 - accuracy: 0.4714 - val_loss: 2.6326 - val_accuracy: 0.2467\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3370 - accuracy: 0.4729 - val_loss: 2.6146 - val_accuracy: 0.2467\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3369 - accuracy: 0.4743 - val_loss: 2.6632 - val_accuracy: 0.2467\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3354 - accuracy: 0.4686 - val_loss: 2.6116 - val_accuracy: 0.2333\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3370 - accuracy: 0.4786 - val_loss: 2.6319 - val_accuracy: 0.2467\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3375 - accuracy: 0.4657 - val_loss: 2.6297 - val_accuracy: 0.2433\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3369 - accuracy: 0.4643 - val_loss: 2.6194 - val_accuracy: 0.2433\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3366 - accuracy: 0.4757 - val_loss: 2.6224 - val_accuracy: 0.2433\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3364 - accuracy: 0.4800 - val_loss: 2.6019 - val_accuracy: 0.2500\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3365 - accuracy: 0.4729 - val_loss: 2.6190 - val_accuracy: 0.2433\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3370 - accuracy: 0.4700 - val_loss: 2.6057 - val_accuracy: 0.2500\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3368 - accuracy: 0.4771 - val_loss: 2.6405 - val_accuracy: 0.2400\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3360 - accuracy: 0.4757 - val_loss: 2.6244 - val_accuracy: 0.2400\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3359 - accuracy: 0.4743 - val_loss: 2.6217 - val_accuracy: 0.2467\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3354 - accuracy: 0.4729 - val_loss: 2.6127 - val_accuracy: 0.2433\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3354 - accuracy: 0.4671 - val_loss: 2.6013 - val_accuracy: 0.2500\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3358 - accuracy: 0.4714 - val_loss: 2.6026 - val_accuracy: 0.2500\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3362 - accuracy: 0.4714 - val_loss: 2.6284 - val_accuracy: 0.2433\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3357 - accuracy: 0.4729 - val_loss: 2.6263 - val_accuracy: 0.2367\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3357 - accuracy: 0.4757 - val_loss: 2.6158 - val_accuracy: 0.2433\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3362 - accuracy: 0.4800 - val_loss: 2.6253 - val_accuracy: 0.2433\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3352 - accuracy: 0.4729 - val_loss: 2.6046 - val_accuracy: 0.2433\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3357 - accuracy: 0.4800 - val_loss: 2.6308 - val_accuracy: 0.2367\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3356 - accuracy: 0.4757 - val_loss: 2.6498 - val_accuracy: 0.2433\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3358 - accuracy: 0.4714 - val_loss: 2.6463 - val_accuracy: 0.2500\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3343 - accuracy: 0.4729 - val_loss: 2.6542 - val_accuracy: 0.2433\n",
      "Epoch 1550/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3352 - accuracy: 0.4700 - val_loss: 2.6547 - val_accuracy: 0.2433\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3351 - accuracy: 0.4743 - val_loss: 2.6209 - val_accuracy: 0.2367\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3348 - accuracy: 0.4729 - val_loss: 2.6499 - val_accuracy: 0.2500\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3348 - accuracy: 0.4771 - val_loss: 2.6502 - val_accuracy: 0.2467\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3352 - accuracy: 0.4700 - val_loss: 2.6340 - val_accuracy: 0.2367\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3350 - accuracy: 0.4714 - val_loss: 2.6340 - val_accuracy: 0.2400\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3342 - accuracy: 0.4729 - val_loss: 2.6275 - val_accuracy: 0.2467\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3339 - accuracy: 0.4729 - val_loss: 2.6351 - val_accuracy: 0.2433\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3342 - accuracy: 0.4743 - val_loss: 2.5980 - val_accuracy: 0.2533\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3345 - accuracy: 0.4757 - val_loss: 2.6485 - val_accuracy: 0.2467\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3347 - accuracy: 0.4729 - val_loss: 2.6310 - val_accuracy: 0.2433\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3337 - accuracy: 0.4714 - val_loss: 2.6370 - val_accuracy: 0.2467\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3343 - accuracy: 0.4700 - val_loss: 2.6726 - val_accuracy: 0.2500\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3350 - accuracy: 0.4757 - val_loss: 2.6434 - val_accuracy: 0.2467\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3328 - accuracy: 0.4757 - val_loss: 2.6319 - val_accuracy: 0.2400\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.3350 - accuracy: 0.4757 - val_loss: 2.6307 - val_accuracy: 0.2467\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3334 - accuracy: 0.4771 - val_loss: 2.6387 - val_accuracy: 0.2367\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3343 - accuracy: 0.4757 - val_loss: 2.6435 - val_accuracy: 0.2400\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3337 - accuracy: 0.4729 - val_loss: 2.6328 - val_accuracy: 0.2433\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3342 - accuracy: 0.4786 - val_loss: 2.6693 - val_accuracy: 0.2467\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3330 - accuracy: 0.4814 - val_loss: 2.6782 - val_accuracy: 0.2433\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3347 - accuracy: 0.4714 - val_loss: 2.6616 - val_accuracy: 0.2433\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3339 - accuracy: 0.4771 - val_loss: 2.6387 - val_accuracy: 0.2367\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3335 - accuracy: 0.4757 - val_loss: 2.6814 - val_accuracy: 0.2433\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3339 - accuracy: 0.4671 - val_loss: 2.6534 - val_accuracy: 0.2433\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3327 - accuracy: 0.4757 - val_loss: 2.6278 - val_accuracy: 0.2467\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3330 - accuracy: 0.4771 - val_loss: 2.6691 - val_accuracy: 0.2467\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3337 - accuracy: 0.4700 - val_loss: 2.6356 - val_accuracy: 0.2400\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3320 - accuracy: 0.4771 - val_loss: 2.6465 - val_accuracy: 0.2433\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3331 - accuracy: 0.4714 - val_loss: 2.6453 - val_accuracy: 0.2467\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3321 - accuracy: 0.4800 - val_loss: 2.6620 - val_accuracy: 0.2467\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3335 - accuracy: 0.4671 - val_loss: 2.6603 - val_accuracy: 0.2400\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3330 - accuracy: 0.4771 - val_loss: 2.6338 - val_accuracy: 0.2433\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3323 - accuracy: 0.4743 - val_loss: 2.6476 - val_accuracy: 0.2433\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3336 - accuracy: 0.4757 - val_loss: 2.6591 - val_accuracy: 0.2433\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3327 - accuracy: 0.4700 - val_loss: 2.6486 - val_accuracy: 0.2500\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3318 - accuracy: 0.4729 - val_loss: 2.6663 - val_accuracy: 0.2333\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3321 - accuracy: 0.4714 - val_loss: 2.6713 - val_accuracy: 0.2400\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3320 - accuracy: 0.4800 - val_loss: 2.6373 - val_accuracy: 0.2467\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3324 - accuracy: 0.4786 - val_loss: 2.6690 - val_accuracy: 0.2400\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3316 - accuracy: 0.4714 - val_loss: 2.6570 - val_accuracy: 0.2500\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3324 - accuracy: 0.4800 - val_loss: 2.6426 - val_accuracy: 0.2433\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3319 - accuracy: 0.4686 - val_loss: 2.6602 - val_accuracy: 0.2467\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3310 - accuracy: 0.4700 - val_loss: 2.6723 - val_accuracy: 0.2400\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3321 - accuracy: 0.4771 - val_loss: 2.6611 - val_accuracy: 0.2433\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3310 - accuracy: 0.4771 - val_loss: 2.6530 - val_accuracy: 0.2433\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3315 - accuracy: 0.4729 - val_loss: 2.6219 - val_accuracy: 0.2467\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3311 - accuracy: 0.4757 - val_loss: 2.6387 - val_accuracy: 0.2433\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3323 - accuracy: 0.4829 - val_loss: 2.6641 - val_accuracy: 0.2400\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3313 - accuracy: 0.4686 - val_loss: 2.6547 - val_accuracy: 0.2333\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3315 - accuracy: 0.4771 - val_loss: 2.6646 - val_accuracy: 0.2333\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3320 - accuracy: 0.4771 - val_loss: 2.6424 - val_accuracy: 0.2467\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3307 - accuracy: 0.4729 - val_loss: 2.6798 - val_accuracy: 0.2467\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3313 - accuracy: 0.4714 - val_loss: 2.6782 - val_accuracy: 0.2500\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3311 - accuracy: 0.4757 - val_loss: 2.6673 - val_accuracy: 0.2433\n",
      "Epoch 1605/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3313 - accuracy: 0.4800 - val_loss: 2.6857 - val_accuracy: 0.2500\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3307 - accuracy: 0.4786 - val_loss: 2.6368 - val_accuracy: 0.2400\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3324 - accuracy: 0.4800 - val_loss: 2.6526 - val_accuracy: 0.2467\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3294 - accuracy: 0.4786 - val_loss: 2.6625 - val_accuracy: 0.2467\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3308 - accuracy: 0.4786 - val_loss: 2.7004 - val_accuracy: 0.2500\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3312 - accuracy: 0.4729 - val_loss: 2.6731 - val_accuracy: 0.2433\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3299 - accuracy: 0.4743 - val_loss: 2.6899 - val_accuracy: 0.2433\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3306 - accuracy: 0.4729 - val_loss: 2.6726 - val_accuracy: 0.2433\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3300 - accuracy: 0.4743 - val_loss: 2.6727 - val_accuracy: 0.2333\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3304 - accuracy: 0.4700 - val_loss: 2.6780 - val_accuracy: 0.2467\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3310 - accuracy: 0.4800 - val_loss: 2.6939 - val_accuracy: 0.2467\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3307 - accuracy: 0.4786 - val_loss: 2.6709 - val_accuracy: 0.2433\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3293 - accuracy: 0.4757 - val_loss: 2.6457 - val_accuracy: 0.2433\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3312 - accuracy: 0.4729 - val_loss: 2.6711 - val_accuracy: 0.2400\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3300 - accuracy: 0.4743 - val_loss: 2.6753 - val_accuracy: 0.2467\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3300 - accuracy: 0.4757 - val_loss: 2.6782 - val_accuracy: 0.2400\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3298 - accuracy: 0.4800 - val_loss: 2.7107 - val_accuracy: 0.2467\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3293 - accuracy: 0.4743 - val_loss: 2.6503 - val_accuracy: 0.2467\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3291 - accuracy: 0.4729 - val_loss: 2.6661 - val_accuracy: 0.2400\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3281 - accuracy: 0.4757 - val_loss: 2.6819 - val_accuracy: 0.2400\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3376 - accuracy: 0.20 - 0s 58us/step - loss: 1.3297 - accuracy: 0.4743 - val_loss: 2.6781 - val_accuracy: 0.2367\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3291 - accuracy: 0.4771 - val_loss: 2.6668 - val_accuracy: 0.2400\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3291 - accuracy: 0.4771 - val_loss: 2.7246 - val_accuracy: 0.2433\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3292 - accuracy: 0.4800 - val_loss: 2.6879 - val_accuracy: 0.2400\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3294 - accuracy: 0.4814 - val_loss: 2.6605 - val_accuracy: 0.2433\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3292 - accuracy: 0.4743 - val_loss: 2.6890 - val_accuracy: 0.2400\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3295 - accuracy: 0.4800 - val_loss: 2.6815 - val_accuracy: 0.2433\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3282 - accuracy: 0.4771 - val_loss: 2.7149 - val_accuracy: 0.2433\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3291 - accuracy: 0.4729 - val_loss: 2.6811 - val_accuracy: 0.2400\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3282 - accuracy: 0.4771 - val_loss: 2.7043 - val_accuracy: 0.2500\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3278 - accuracy: 0.4714 - val_loss: 2.6794 - val_accuracy: 0.2400\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3288 - accuracy: 0.4743 - val_loss: 2.7085 - val_accuracy: 0.2500\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3265 - accuracy: 0.4714 - val_loss: 2.7041 - val_accuracy: 0.2433\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3279 - accuracy: 0.4786 - val_loss: 2.7136 - val_accuracy: 0.2467\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3275 - accuracy: 0.4686 - val_loss: 2.7062 - val_accuracy: 0.2400\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3276 - accuracy: 0.4757 - val_loss: 2.7232 - val_accuracy: 0.2467\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3284 - accuracy: 0.4814 - val_loss: 2.6766 - val_accuracy: 0.2400\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3278 - accuracy: 0.4786 - val_loss: 2.6917 - val_accuracy: 0.2433\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3274 - accuracy: 0.4814 - val_loss: 2.7086 - val_accuracy: 0.2467\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3273 - accuracy: 0.4757 - val_loss: 2.6862 - val_accuracy: 0.2400\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3257 - accuracy: 0.4829 - val_loss: 2.6932 - val_accuracy: 0.2433\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3263 - accuracy: 0.4686 - val_loss: 2.6691 - val_accuracy: 0.2367\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3266 - accuracy: 0.4843 - val_loss: 2.7287 - val_accuracy: 0.2433\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3275 - accuracy: 0.4771 - val_loss: 2.7117 - val_accuracy: 0.2400\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3265 - accuracy: 0.4743 - val_loss: 2.7074 - val_accuracy: 0.2400\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3260 - accuracy: 0.4857 - val_loss: 2.6888 - val_accuracy: 0.2433\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3276 - accuracy: 0.4729 - val_loss: 2.6837 - val_accuracy: 0.2467\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3268 - accuracy: 0.4743 - val_loss: 2.6958 - val_accuracy: 0.2400\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3259 - accuracy: 0.4743 - val_loss: 2.7185 - val_accuracy: 0.2500\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3285 - accuracy: 0.4786 - val_loss: 2.6946 - val_accuracy: 0.2467\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.3257 - accuracy: 0.4771 - val_loss: 2.6982 - val_accuracy: 0.2400\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3273 - accuracy: 0.4786 - val_loss: 2.6948 - val_accuracy: 0.2400\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3268 - accuracy: 0.4829 - val_loss: 2.6933 - val_accuracy: 0.2467\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3263 - accuracy: 0.4786 - val_loss: 2.7085 - val_accuracy: 0.2400\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3266 - accuracy: 0.4857 - val_loss: 2.6862 - val_accuracy: 0.2400\n",
      "Epoch 1660/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3262 - accuracy: 0.4757 - val_loss: 2.7058 - val_accuracy: 0.2400\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3259 - accuracy: 0.4786 - val_loss: 2.6907 - val_accuracy: 0.2433\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3261 - accuracy: 0.4757 - val_loss: 2.6995 - val_accuracy: 0.2433\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3263 - accuracy: 0.4800 - val_loss: 2.7092 - val_accuracy: 0.2433\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3267 - accuracy: 0.4757 - val_loss: 2.7177 - val_accuracy: 0.2467\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3258 - accuracy: 0.4657 - val_loss: 2.6972 - val_accuracy: 0.2467\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3258 - accuracy: 0.4814 - val_loss: 2.6991 - val_accuracy: 0.2467\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3253 - accuracy: 0.4786 - val_loss: 2.6890 - val_accuracy: 0.2400\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3255 - accuracy: 0.4729 - val_loss: 2.6885 - val_accuracy: 0.2400\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3258 - accuracy: 0.4829 - val_loss: 2.7045 - val_accuracy: 0.2400\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3249 - accuracy: 0.4814 - val_loss: 2.7292 - val_accuracy: 0.2433\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3256 - accuracy: 0.4757 - val_loss: 2.7207 - val_accuracy: 0.2433\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3252 - accuracy: 0.4814 - val_loss: 2.7174 - val_accuracy: 0.2433\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3248 - accuracy: 0.4771 - val_loss: 2.7509 - val_accuracy: 0.2533\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3242 - accuracy: 0.4871 - val_loss: 2.7321 - val_accuracy: 0.2433\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3251 - accuracy: 0.4786 - val_loss: 2.6973 - val_accuracy: 0.2400\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3255 - accuracy: 0.4771 - val_loss: 2.7175 - val_accuracy: 0.2400\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3237 - accuracy: 0.4771 - val_loss: 2.6928 - val_accuracy: 0.2467\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3250 - accuracy: 0.4771 - val_loss: 2.7118 - val_accuracy: 0.2433\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3245 - accuracy: 0.4757 - val_loss: 2.7226 - val_accuracy: 0.2400\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3245 - accuracy: 0.4814 - val_loss: 2.7060 - val_accuracy: 0.2433\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3249 - accuracy: 0.4800 - val_loss: 2.7123 - val_accuracy: 0.2400\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3248 - accuracy: 0.4800 - val_loss: 2.7110 - val_accuracy: 0.2433\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3248 - accuracy: 0.4829 - val_loss: 2.7117 - val_accuracy: 0.2400\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3234 - accuracy: 0.4843 - val_loss: 2.7466 - val_accuracy: 0.2467\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3248 - accuracy: 0.4786 - val_loss: 2.7151 - val_accuracy: 0.2433\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3238 - accuracy: 0.4729 - val_loss: 2.7518 - val_accuracy: 0.2500\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3245 - accuracy: 0.4871 - val_loss: 2.7195 - val_accuracy: 0.2400\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3245 - accuracy: 0.4886 - val_loss: 2.7087 - val_accuracy: 0.2400\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3250 - accuracy: 0.4757 - val_loss: 2.7209 - val_accuracy: 0.2433\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3244 - accuracy: 0.4814 - val_loss: 2.7116 - val_accuracy: 0.2367\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3233 - accuracy: 0.4829 - val_loss: 2.7133 - val_accuracy: 0.2433\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3240 - accuracy: 0.4786 - val_loss: 2.7283 - val_accuracy: 0.2433\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3237 - accuracy: 0.4757 - val_loss: 2.7456 - val_accuracy: 0.2400\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3243 - accuracy: 0.4829 - val_loss: 2.7446 - val_accuracy: 0.2467\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3240 - accuracy: 0.4786 - val_loss: 2.7232 - val_accuracy: 0.2433\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3234 - accuracy: 0.4786 - val_loss: 2.6872 - val_accuracy: 0.2467\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3235 - accuracy: 0.4871 - val_loss: 2.7205 - val_accuracy: 0.2433\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3234 - accuracy: 0.4829 - val_loss: 2.7329 - val_accuracy: 0.2400\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3238 - accuracy: 0.4786 - val_loss: 2.7470 - val_accuracy: 0.2467\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3229 - accuracy: 0.4771 - val_loss: 2.7461 - val_accuracy: 0.2500\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3228 - accuracy: 0.4814 - val_loss: 2.7329 - val_accuracy: 0.2433\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3235 - accuracy: 0.4743 - val_loss: 2.7110 - val_accuracy: 0.2433\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3229 - accuracy: 0.4714 - val_loss: 2.7191 - val_accuracy: 0.2400\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3225 - accuracy: 0.4786 - val_loss: 2.7292 - val_accuracy: 0.2400\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3232 - accuracy: 0.4829 - val_loss: 2.7529 - val_accuracy: 0.2467\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3226 - accuracy: 0.4800 - val_loss: 2.7202 - val_accuracy: 0.2433\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3232 - accuracy: 0.4814 - val_loss: 2.7391 - val_accuracy: 0.2467\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3217 - accuracy: 0.4786 - val_loss: 2.7271 - val_accuracy: 0.2433\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3221 - accuracy: 0.4771 - val_loss: 2.7326 - val_accuracy: 0.2433\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3226 - accuracy: 0.4771 - val_loss: 2.7145 - val_accuracy: 0.2433\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3225 - accuracy: 0.4800 - val_loss: 2.7277 - val_accuracy: 0.2433\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3231 - accuracy: 0.4786 - val_loss: 2.7367 - val_accuracy: 0.2433\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3219 - accuracy: 0.4757 - val_loss: 2.7637 - val_accuracy: 0.2500\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3233 - accuracy: 0.4814 - val_loss: 2.7087 - val_accuracy: 0.2433\n",
      "Epoch 1715/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3225 - accuracy: 0.4857 - val_loss: 2.7605 - val_accuracy: 0.2533\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3221 - accuracy: 0.4800 - val_loss: 2.7636 - val_accuracy: 0.2533\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3220 - accuracy: 0.4800 - val_loss: 2.7174 - val_accuracy: 0.2433\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3229 - accuracy: 0.4886 - val_loss: 2.7441 - val_accuracy: 0.2467\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3224 - accuracy: 0.4857 - val_loss: 2.6847 - val_accuracy: 0.2433\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3212 - accuracy: 0.4814 - val_loss: 2.7311 - val_accuracy: 0.2433\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3220 - accuracy: 0.4800 - val_loss: 2.7231 - val_accuracy: 0.2433\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3227 - accuracy: 0.4757 - val_loss: 2.7074 - val_accuracy: 0.2400\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3219 - accuracy: 0.4800 - val_loss: 2.7116 - val_accuracy: 0.2400\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3210 - accuracy: 0.4857 - val_loss: 2.7300 - val_accuracy: 0.2367\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3217 - accuracy: 0.4857 - val_loss: 2.7403 - val_accuracy: 0.2433\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3212 - accuracy: 0.4814 - val_loss: 2.7482 - val_accuracy: 0.2467\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3221 - accuracy: 0.4829 - val_loss: 2.7459 - val_accuracy: 0.2500\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3212 - accuracy: 0.4743 - val_loss: 2.7464 - val_accuracy: 0.2433\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3219 - accuracy: 0.4757 - val_loss: 2.7380 - val_accuracy: 0.2400\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3210 - accuracy: 0.4843 - val_loss: 2.7198 - val_accuracy: 0.2400\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3213 - accuracy: 0.4814 - val_loss: 2.7584 - val_accuracy: 0.2500\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3210 - accuracy: 0.4829 - val_loss: 2.7479 - val_accuracy: 0.2467\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3201 - accuracy: 0.4800 - val_loss: 2.7631 - val_accuracy: 0.2467\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3212 - accuracy: 0.4757 - val_loss: 2.7523 - val_accuracy: 0.2433\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3217 - accuracy: 0.4814 - val_loss: 2.7310 - val_accuracy: 0.2433\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3209 - accuracy: 0.4829 - val_loss: 2.7489 - val_accuracy: 0.2433\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3194 - accuracy: 0.4843 - val_loss: 2.7576 - val_accuracy: 0.2433\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3210 - accuracy: 0.4814 - val_loss: 2.7733 - val_accuracy: 0.2533\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3208 - accuracy: 0.4800 - val_loss: 2.7405 - val_accuracy: 0.2400\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3207 - accuracy: 0.4829 - val_loss: 2.7729 - val_accuracy: 0.2500\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3206 - accuracy: 0.4857 - val_loss: 2.7087 - val_accuracy: 0.2400\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3199 - accuracy: 0.4843 - val_loss: 2.7658 - val_accuracy: 0.2500\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3208 - accuracy: 0.4814 - val_loss: 2.7667 - val_accuracy: 0.2467\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3204 - accuracy: 0.4771 - val_loss: 2.7543 - val_accuracy: 0.2467\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3201 - accuracy: 0.4843 - val_loss: 2.7372 - val_accuracy: 0.2400\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3205 - accuracy: 0.4786 - val_loss: 2.7724 - val_accuracy: 0.2500\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3201 - accuracy: 0.4814 - val_loss: 2.7602 - val_accuracy: 0.2433\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3194 - accuracy: 0.4743 - val_loss: 2.7610 - val_accuracy: 0.2400\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3201 - accuracy: 0.4800 - val_loss: 2.7603 - val_accuracy: 0.2467\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3192 - accuracy: 0.4814 - val_loss: 2.7131 - val_accuracy: 0.2433\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3200 - accuracy: 0.4829 - val_loss: 2.7128 - val_accuracy: 0.2433\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3188 - accuracy: 0.4800 - val_loss: 2.7201 - val_accuracy: 0.2433\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3199 - accuracy: 0.4771 - val_loss: 2.7706 - val_accuracy: 0.2433\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3200 - accuracy: 0.4843 - val_loss: 2.7730 - val_accuracy: 0.2433\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3186 - accuracy: 0.4843 - val_loss: 2.7610 - val_accuracy: 0.2467\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3196 - accuracy: 0.4771 - val_loss: 2.7295 - val_accuracy: 0.2433\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3193 - accuracy: 0.4871 - val_loss: 2.7785 - val_accuracy: 0.2467\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3192 - accuracy: 0.4857 - val_loss: 2.7427 - val_accuracy: 0.2433\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3191 - accuracy: 0.4814 - val_loss: 2.8140 - val_accuracy: 0.2500\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3197 - accuracy: 0.4843 - val_loss: 2.7251 - val_accuracy: 0.2467\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3201 - accuracy: 0.4900 - val_loss: 2.7417 - val_accuracy: 0.2433\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3190 - accuracy: 0.4814 - val_loss: 2.7799 - val_accuracy: 0.2433\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3190 - accuracy: 0.4771 - val_loss: 2.7540 - val_accuracy: 0.2400\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3179 - accuracy: 0.4857 - val_loss: 2.7600 - val_accuracy: 0.2433\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3197 - accuracy: 0.4800 - val_loss: 2.7545 - val_accuracy: 0.2467\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3186 - accuracy: 0.4800 - val_loss: 2.7405 - val_accuracy: 0.2433\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3192 - accuracy: 0.4829 - val_loss: 2.7429 - val_accuracy: 0.2433\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3189 - accuracy: 0.4843 - val_loss: 2.7533 - val_accuracy: 0.2433\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3183 - accuracy: 0.4829 - val_loss: 2.7567 - val_accuracy: 0.2467\n",
      "Epoch 1770/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3190 - accuracy: 0.4929 - val_loss: 2.7751 - val_accuracy: 0.2467\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3186 - accuracy: 0.4843 - val_loss: 2.7471 - val_accuracy: 0.2433\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3185 - accuracy: 0.4814 - val_loss: 2.7740 - val_accuracy: 0.2467\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3183 - accuracy: 0.4843 - val_loss: 2.7609 - val_accuracy: 0.2400\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3187 - accuracy: 0.4900 - val_loss: 2.7597 - val_accuracy: 0.2467\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3187 - accuracy: 0.4829 - val_loss: 2.7884 - val_accuracy: 0.2533\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3193 - accuracy: 0.4800 - val_loss: 2.7104 - val_accuracy: 0.2433\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3178 - accuracy: 0.4871 - val_loss: 2.7617 - val_accuracy: 0.2400\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3177 - accuracy: 0.4829 - val_loss: 2.7374 - val_accuracy: 0.2400\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3184 - accuracy: 0.4886 - val_loss: 2.7702 - val_accuracy: 0.2400\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3184 - accuracy: 0.4814 - val_loss: 2.7890 - val_accuracy: 0.2467\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3174 - accuracy: 0.4871 - val_loss: 2.7951 - val_accuracy: 0.2467\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3183 - accuracy: 0.4814 - val_loss: 2.7286 - val_accuracy: 0.2400\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3176 - accuracy: 0.4914 - val_loss: 2.7833 - val_accuracy: 0.2467\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3174 - accuracy: 0.4829 - val_loss: 2.7522 - val_accuracy: 0.2367\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3179 - accuracy: 0.4857 - val_loss: 2.7539 - val_accuracy: 0.2467\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3182 - accuracy: 0.4843 - val_loss: 2.7619 - val_accuracy: 0.2433\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3176 - accuracy: 0.4914 - val_loss: 2.7564 - val_accuracy: 0.2433\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3180 - accuracy: 0.4829 - val_loss: 2.7652 - val_accuracy: 0.2400\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3178 - accuracy: 0.4843 - val_loss: 2.7345 - val_accuracy: 0.2400\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3175 - accuracy: 0.4857 - val_loss: 2.7287 - val_accuracy: 0.2400\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3179 - accuracy: 0.4814 - val_loss: 2.7616 - val_accuracy: 0.2400\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3168 - accuracy: 0.4814 - val_loss: 2.7972 - val_accuracy: 0.2467\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3170 - accuracy: 0.4814 - val_loss: 2.7817 - val_accuracy: 0.2467\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3168 - accuracy: 0.4857 - val_loss: 2.7729 - val_accuracy: 0.2433\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3173 - accuracy: 0.4814 - val_loss: 2.7766 - val_accuracy: 0.2433\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3167 - accuracy: 0.4814 - val_loss: 2.8113 - val_accuracy: 0.2533\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3163 - accuracy: 0.4800 - val_loss: 2.7876 - val_accuracy: 0.2433\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3176 - accuracy: 0.4871 - val_loss: 2.7636 - val_accuracy: 0.2433\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3168 - accuracy: 0.4900 - val_loss: 2.8183 - val_accuracy: 0.2467\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3170 - accuracy: 0.4843 - val_loss: 2.7988 - val_accuracy: 0.2467\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3162 - accuracy: 0.4857 - val_loss: 2.7613 - val_accuracy: 0.2400\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3164 - accuracy: 0.4857 - val_loss: 2.7926 - val_accuracy: 0.2467\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3160 - accuracy: 0.4843 - val_loss: 2.7755 - val_accuracy: 0.2467\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3167 - accuracy: 0.4886 - val_loss: 2.7658 - val_accuracy: 0.2433\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3167 - accuracy: 0.4843 - val_loss: 2.7955 - val_accuracy: 0.2467\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3164 - accuracy: 0.4814 - val_loss: 2.7665 - val_accuracy: 0.2400\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3162 - accuracy: 0.4800 - val_loss: 2.7949 - val_accuracy: 0.2467\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3157 - accuracy: 0.4771 - val_loss: 2.7954 - val_accuracy: 0.2500\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3164 - accuracy: 0.4814 - val_loss: 2.7507 - val_accuracy: 0.2367\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3163 - accuracy: 0.4843 - val_loss: 2.7758 - val_accuracy: 0.2400\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3158 - accuracy: 0.4871 - val_loss: 2.7749 - val_accuracy: 0.2433\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3160 - accuracy: 0.4829 - val_loss: 2.7721 - val_accuracy: 0.2467\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3169 - accuracy: 0.4771 - val_loss: 2.7732 - val_accuracy: 0.2400\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3167 - accuracy: 0.4771 - val_loss: 2.7828 - val_accuracy: 0.2467\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3155 - accuracy: 0.4871 - val_loss: 2.7902 - val_accuracy: 0.2467\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3148 - accuracy: 0.4857 - val_loss: 2.7706 - val_accuracy: 0.2400\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3150 - accuracy: 0.4843 - val_loss: 2.7923 - val_accuracy: 0.2433\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3162 - accuracy: 0.4800 - val_loss: 2.7727 - val_accuracy: 0.2400\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3158 - accuracy: 0.4871 - val_loss: 2.7900 - val_accuracy: 0.2433\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3166 - accuracy: 0.4829 - val_loss: 2.7606 - val_accuracy: 0.2400\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3147 - accuracy: 0.4829 - val_loss: 2.8329 - val_accuracy: 0.2467\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3144 - accuracy: 0.4857 - val_loss: 2.7680 - val_accuracy: 0.2467\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3142 - accuracy: 0.4786 - val_loss: 2.8176 - val_accuracy: 0.2433\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3154 - accuracy: 0.4829 - val_loss: 2.8274 - val_accuracy: 0.2500\n",
      "Epoch 1825/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.3146 - accuracy: 0.4814 - val_loss: 2.8094 - val_accuracy: 0.2500\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3144 - accuracy: 0.4829 - val_loss: 2.7718 - val_accuracy: 0.2400\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3151 - accuracy: 0.4857 - val_loss: 2.7812 - val_accuracy: 0.2433\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3131 - accuracy: 0.4843 - val_loss: 2.7838 - val_accuracy: 0.2433\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3153 - accuracy: 0.4800 - val_loss: 2.7718 - val_accuracy: 0.2433\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3139 - accuracy: 0.4843 - val_loss: 2.7901 - val_accuracy: 0.2433\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3138 - accuracy: 0.4871 - val_loss: 2.7782 - val_accuracy: 0.2400\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3138 - accuracy: 0.4857 - val_loss: 2.7998 - val_accuracy: 0.2467\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 2.8160 - val_accuracy: 0.2433\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3137 - accuracy: 0.4814 - val_loss: 2.8138 - val_accuracy: 0.2433\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3134 - accuracy: 0.4871 - val_loss: 2.7999 - val_accuracy: 0.2433\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3140 - accuracy: 0.4886 - val_loss: 2.7753 - val_accuracy: 0.2400\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 2.7887 - val_accuracy: 0.2400\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3133 - accuracy: 0.4800 - val_loss: 2.7816 - val_accuracy: 0.2400\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3124 - accuracy: 0.4900 - val_loss: 2.8309 - val_accuracy: 0.2467\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3137 - accuracy: 0.4900 - val_loss: 2.7936 - val_accuracy: 0.2367\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3119 - accuracy: 0.4843 - val_loss: 2.7613 - val_accuracy: 0.2433\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3132 - accuracy: 0.4800 - val_loss: 2.8177 - val_accuracy: 0.2433\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3129 - accuracy: 0.4857 - val_loss: 2.7970 - val_accuracy: 0.2367\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3129 - accuracy: 0.4814 - val_loss: 2.8158 - val_accuracy: 0.2500\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3125 - accuracy: 0.4829 - val_loss: 2.7741 - val_accuracy: 0.2400\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3129 - accuracy: 0.4886 - val_loss: 2.8062 - val_accuracy: 0.2433\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3133 - accuracy: 0.4943 - val_loss: 2.7454 - val_accuracy: 0.2467\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3131 - accuracy: 0.4857 - val_loss: 2.8078 - val_accuracy: 0.2433\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3129 - accuracy: 0.4886 - val_loss: 2.7887 - val_accuracy: 0.2400\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3125 - accuracy: 0.4843 - val_loss: 2.8107 - val_accuracy: 0.2400\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3125 - accuracy: 0.4871 - val_loss: 2.8048 - val_accuracy: 0.2433\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3127 - accuracy: 0.4886 - val_loss: 2.8206 - val_accuracy: 0.2433\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3130 - accuracy: 0.4857 - val_loss: 2.7899 - val_accuracy: 0.2400\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3123 - accuracy: 0.4886 - val_loss: 2.7942 - val_accuracy: 0.2500\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3122 - accuracy: 0.4857 - val_loss: 2.8018 - val_accuracy: 0.2467\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3108 - accuracy: 0.4871 - val_loss: 2.7939 - val_accuracy: 0.2467\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3127 - accuracy: 0.4857 - val_loss: 2.7873 - val_accuracy: 0.2400\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3124 - accuracy: 0.4857 - val_loss: 2.8183 - val_accuracy: 0.2433\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3116 - accuracy: 0.4857 - val_loss: 2.8009 - val_accuracy: 0.2367\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3115 - accuracy: 0.4829 - val_loss: 2.8136 - val_accuracy: 0.2500\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3121 - accuracy: 0.4957 - val_loss: 2.8175 - val_accuracy: 0.2433\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3122 - accuracy: 0.4900 - val_loss: 2.7980 - val_accuracy: 0.2400\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3121 - accuracy: 0.4886 - val_loss: 2.7967 - val_accuracy: 0.2400\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3112 - accuracy: 0.4886 - val_loss: 2.8054 - val_accuracy: 0.2400\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3112 - accuracy: 0.4886 - val_loss: 2.8361 - val_accuracy: 0.2467\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3115 - accuracy: 0.4857 - val_loss: 2.8192 - val_accuracy: 0.2467\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3118 - accuracy: 0.4886 - val_loss: 2.8251 - val_accuracy: 0.2433\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3116 - accuracy: 0.4871 - val_loss: 2.8125 - val_accuracy: 0.2333\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3108 - accuracy: 0.4929 - val_loss: 2.8443 - val_accuracy: 0.2500\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3118 - accuracy: 0.4829 - val_loss: 2.7841 - val_accuracy: 0.2400\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3113 - accuracy: 0.4829 - val_loss: 2.7913 - val_accuracy: 0.2400\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3114 - accuracy: 0.4843 - val_loss: 2.7903 - val_accuracy: 0.2400\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3111 - accuracy: 0.4871 - val_loss: 2.8482 - val_accuracy: 0.2467\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3110 - accuracy: 0.4943 - val_loss: 2.8149 - val_accuracy: 0.2467\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3110 - accuracy: 0.4971 - val_loss: 2.8357 - val_accuracy: 0.2467\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3108 - accuracy: 0.4771 - val_loss: 2.8073 - val_accuracy: 0.2367\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3113 - accuracy: 0.4843 - val_loss: 2.7962 - val_accuracy: 0.2467\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3110 - accuracy: 0.4886 - val_loss: 2.8292 - val_accuracy: 0.2500\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3105 - accuracy: 0.4886 - val_loss: 2.8224 - val_accuracy: 0.2400\n",
      "Epoch 1880/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3104 - accuracy: 0.4957 - val_loss: 2.8272 - val_accuracy: 0.2467\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3104 - accuracy: 0.4900 - val_loss: 2.8498 - val_accuracy: 0.2467\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3106 - accuracy: 0.4786 - val_loss: 2.7938 - val_accuracy: 0.2400\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3107 - accuracy: 0.4843 - val_loss: 2.8107 - val_accuracy: 0.2433\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3104 - accuracy: 0.4914 - val_loss: 2.8013 - val_accuracy: 0.2400\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3099 - accuracy: 0.4857 - val_loss: 2.7881 - val_accuracy: 0.2433\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3106 - accuracy: 0.4857 - val_loss: 2.8056 - val_accuracy: 0.2433\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3101 - accuracy: 0.4886 - val_loss: 2.8165 - val_accuracy: 0.2400\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3091 - accuracy: 0.4900 - val_loss: 2.8411 - val_accuracy: 0.2433\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3106 - accuracy: 0.4886 - val_loss: 2.7948 - val_accuracy: 0.2467\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3101 - accuracy: 0.4929 - val_loss: 2.8211 - val_accuracy: 0.2433\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3102 - accuracy: 0.4900 - val_loss: 2.8212 - val_accuracy: 0.2433\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3098 - accuracy: 0.4886 - val_loss: 2.8131 - val_accuracy: 0.2433\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3093 - accuracy: 0.4843 - val_loss: 2.8456 - val_accuracy: 0.2500\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3097 - accuracy: 0.4871 - val_loss: 2.8119 - val_accuracy: 0.2400\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3099 - accuracy: 0.4914 - val_loss: 2.8029 - val_accuracy: 0.2433\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3097 - accuracy: 0.4871 - val_loss: 2.8489 - val_accuracy: 0.2467\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3096 - accuracy: 0.4914 - val_loss: 2.8088 - val_accuracy: 0.2467\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3097 - accuracy: 0.4829 - val_loss: 2.7960 - val_accuracy: 0.2433\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3095 - accuracy: 0.4871 - val_loss: 2.8084 - val_accuracy: 0.2500\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3092 - accuracy: 0.4914 - val_loss: 2.8463 - val_accuracy: 0.2467\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3096 - accuracy: 0.4843 - val_loss: 2.8045 - val_accuracy: 0.2433\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3094 - accuracy: 0.4843 - val_loss: 2.8558 - val_accuracy: 0.2433\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3084 - accuracy: 0.4886 - val_loss: 2.8097 - val_accuracy: 0.2433\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3091 - accuracy: 0.4929 - val_loss: 2.8486 - val_accuracy: 0.2500\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3096 - accuracy: 0.4871 - val_loss: 2.8503 - val_accuracy: 0.2467\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3101 - accuracy: 0.4914 - val_loss: 2.8367 - val_accuracy: 0.2467\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3085 - accuracy: 0.4886 - val_loss: 2.8391 - val_accuracy: 0.2500\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3100 - accuracy: 0.4843 - val_loss: 2.8508 - val_accuracy: 0.2467\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3083 - accuracy: 0.4829 - val_loss: 2.8309 - val_accuracy: 0.2400\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3090 - accuracy: 0.4900 - val_loss: 2.8291 - val_accuracy: 0.2400\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3083 - accuracy: 0.4986 - val_loss: 2.8184 - val_accuracy: 0.2367\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3087 - accuracy: 0.4886 - val_loss: 2.8391 - val_accuracy: 0.2500\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3084 - accuracy: 0.4900 - val_loss: 2.8394 - val_accuracy: 0.2400\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3074 - accuracy: 0.4871 - val_loss: 2.8482 - val_accuracy: 0.2500\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3086 - accuracy: 0.4857 - val_loss: 2.8231 - val_accuracy: 0.2433\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3084 - accuracy: 0.4886 - val_loss: 2.8078 - val_accuracy: 0.2400\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3087 - accuracy: 0.4871 - val_loss: 2.8301 - val_accuracy: 0.2500\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3084 - accuracy: 0.4929 - val_loss: 2.8409 - val_accuracy: 0.2400\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3081 - accuracy: 0.4886 - val_loss: 2.8454 - val_accuracy: 0.2400\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3092 - accuracy: 0.4900 - val_loss: 2.8403 - val_accuracy: 0.2433\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3079 - accuracy: 0.4929 - val_loss: 2.8347 - val_accuracy: 0.2433\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3073 - accuracy: 0.4886 - val_loss: 2.8219 - val_accuracy: 0.2467\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3081 - accuracy: 0.4957 - val_loss: 2.8438 - val_accuracy: 0.2433\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3076 - accuracy: 0.4843 - val_loss: 2.8003 - val_accuracy: 0.2433\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3076 - accuracy: 0.4929 - val_loss: 2.8544 - val_accuracy: 0.2400\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3071 - accuracy: 0.4871 - val_loss: 2.8218 - val_accuracy: 0.2433\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3075 - accuracy: 0.4914 - val_loss: 2.8277 - val_accuracy: 0.2467\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3070 - accuracy: 0.4900 - val_loss: 2.8586 - val_accuracy: 0.2467\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3079 - accuracy: 0.4929 - val_loss: 2.8490 - val_accuracy: 0.2433\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3082 - accuracy: 0.4829 - val_loss: 2.8390 - val_accuracy: 0.2433\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3078 - accuracy: 0.4929 - val_loss: 2.8290 - val_accuracy: 0.2400\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3072 - accuracy: 0.4886 - val_loss: 2.8522 - val_accuracy: 0.2467\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3068 - accuracy: 0.4929 - val_loss: 2.8398 - val_accuracy: 0.2467\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3075 - accuracy: 0.4814 - val_loss: 2.8384 - val_accuracy: 0.2500\n",
      "Epoch 1935/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3069 - accuracy: 0.4914 - val_loss: 2.8372 - val_accuracy: 0.2467\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3071 - accuracy: 0.4886 - val_loss: 2.8738 - val_accuracy: 0.2467\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3067 - accuracy: 0.4957 - val_loss: 2.8457 - val_accuracy: 0.2467\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3071 - accuracy: 0.4886 - val_loss: 2.8680 - val_accuracy: 0.2467\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3071 - accuracy: 0.4929 - val_loss: 2.8414 - val_accuracy: 0.2467\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3071 - accuracy: 0.4914 - val_loss: 2.8538 - val_accuracy: 0.2467\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3066 - accuracy: 0.4857 - val_loss: 2.8291 - val_accuracy: 0.2467\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3066 - accuracy: 0.4914 - val_loss: 2.8601 - val_accuracy: 0.2467\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3066 - accuracy: 0.4900 - val_loss: 2.8644 - val_accuracy: 0.2467\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3065 - accuracy: 0.4929 - val_loss: 2.8741 - val_accuracy: 0.2467\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3064 - accuracy: 0.4929 - val_loss: 2.8441 - val_accuracy: 0.2400\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3068 - accuracy: 0.4871 - val_loss: 2.8646 - val_accuracy: 0.2500\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3073 - accuracy: 0.4857 - val_loss: 2.8327 - val_accuracy: 0.2467\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3059 - accuracy: 0.4914 - val_loss: 2.8601 - val_accuracy: 0.2467\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3074 - accuracy: 0.4900 - val_loss: 2.8628 - val_accuracy: 0.2433\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3072 - accuracy: 0.4914 - val_loss: 2.8465 - val_accuracy: 0.2400\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3056 - accuracy: 0.4857 - val_loss: 2.8831 - val_accuracy: 0.2500\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3065 - accuracy: 0.4857 - val_loss: 2.8920 - val_accuracy: 0.2467\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3060 - accuracy: 0.4871 - val_loss: 2.8458 - val_accuracy: 0.2467\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3061 - accuracy: 0.4929 - val_loss: 2.8430 - val_accuracy: 0.2500\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3063 - accuracy: 0.4886 - val_loss: 2.8634 - val_accuracy: 0.2433\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3058 - accuracy: 0.4914 - val_loss: 2.8676 - val_accuracy: 0.2467\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3057 - accuracy: 0.4886 - val_loss: 2.8187 - val_accuracy: 0.2433\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3062 - accuracy: 0.4914 - val_loss: 2.8320 - val_accuracy: 0.2433\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3057 - accuracy: 0.4943 - val_loss: 2.8322 - val_accuracy: 0.2433\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3060 - accuracy: 0.4971 - val_loss: 2.8572 - val_accuracy: 0.2400\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3058 - accuracy: 0.4843 - val_loss: 2.8839 - val_accuracy: 0.2467\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3055 - accuracy: 0.4943 - val_loss: 2.8521 - val_accuracy: 0.2467\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3049 - accuracy: 0.4900 - val_loss: 2.8646 - val_accuracy: 0.2467\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3056 - accuracy: 0.4886 - val_loss: 2.8605 - val_accuracy: 0.2400\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3054 - accuracy: 0.4829 - val_loss: 2.8708 - val_accuracy: 0.2467\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3055 - accuracy: 0.4900 - val_loss: 2.8691 - val_accuracy: 0.2433\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3053 - accuracy: 0.4929 - val_loss: 2.8624 - val_accuracy: 0.2433\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3047 - accuracy: 0.4886 - val_loss: 2.8806 - val_accuracy: 0.2500\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3059 - accuracy: 0.4943 - val_loss: 2.8855 - val_accuracy: 0.2467\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3051 - accuracy: 0.4857 - val_loss: 2.8786 - val_accuracy: 0.2467\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.3051 - accuracy: 0.4914 - val_loss: 2.8770 - val_accuracy: 0.2467\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3040 - accuracy: 0.4900 - val_loss: 2.8643 - val_accuracy: 0.2433\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3055 - accuracy: 0.4971 - val_loss: 2.8736 - val_accuracy: 0.2467\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3048 - accuracy: 0.4929 - val_loss: 2.8328 - val_accuracy: 0.2433\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3050 - accuracy: 0.4929 - val_loss: 2.8568 - val_accuracy: 0.2500\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3051 - accuracy: 0.4857 - val_loss: 2.8777 - val_accuracy: 0.2467\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3049 - accuracy: 0.4914 - val_loss: 2.8717 - val_accuracy: 0.2433\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3052 - accuracy: 0.4943 - val_loss: 2.8666 - val_accuracy: 0.2433\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3040 - accuracy: 0.4943 - val_loss: 2.8949 - val_accuracy: 0.2467\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3033 - accuracy: 0.4900 - val_loss: 2.8520 - val_accuracy: 0.2467\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3044 - accuracy: 0.4900 - val_loss: 2.8652 - val_accuracy: 0.2433\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3043 - accuracy: 0.4900 - val_loss: 2.8490 - val_accuracy: 0.2500\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3045 - accuracy: 0.4886 - val_loss: 2.8584 - val_accuracy: 0.2467\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3045 - accuracy: 0.4943 - val_loss: 2.8657 - val_accuracy: 0.2433\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3039 - accuracy: 0.4957 - val_loss: 2.8935 - val_accuracy: 0.2467\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3048 - accuracy: 0.4886 - val_loss: 2.8810 - val_accuracy: 0.2433\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3042 - accuracy: 0.4957 - val_loss: 2.8605 - val_accuracy: 0.2500\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3054 - accuracy: 0.4886 - val_loss: 2.9012 - val_accuracy: 0.2467\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3043 - accuracy: 0.4986 - val_loss: 2.8706 - val_accuracy: 0.2433\n",
      "Epoch 1990/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3037 - accuracy: 0.4857 - val_loss: 2.8657 - val_accuracy: 0.2433\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3039 - accuracy: 0.4957 - val_loss: 2.8685 - val_accuracy: 0.2433\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3033 - accuracy: 0.4871 - val_loss: 2.9042 - val_accuracy: 0.2533\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3037 - accuracy: 0.4914 - val_loss: 2.8293 - val_accuracy: 0.2500\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3043 - accuracy: 0.4929 - val_loss: 2.8735 - val_accuracy: 0.2467\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3036 - accuracy: 0.4886 - val_loss: 2.8896 - val_accuracy: 0.2467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3034 - accuracy: 0.4914 - val_loss: 2.8969 - val_accuracy: 0.2467\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3035 - accuracy: 0.4914 - val_loss: 2.8496 - val_accuracy: 0.2433\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3031 - accuracy: 0.4914 - val_loss: 2.9240 - val_accuracy: 0.2433\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3040 - accuracy: 0.4900 - val_loss: 2.9074 - val_accuracy: 0.2467\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.3034 - accuracy: 0.4914 - val_loss: 2.8850 - val_accuracy: 0.2467\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3033 - accuracy: 0.4900 - val_loss: 2.8375 - val_accuracy: 0.2433\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3039 - accuracy: 0.4914 - val_loss: 2.8816 - val_accuracy: 0.2433\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3038 - accuracy: 0.4886 - val_loss: 2.9124 - val_accuracy: 0.2433\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3034 - accuracy: 0.4857 - val_loss: 2.8708 - val_accuracy: 0.2433\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3029 - accuracy: 0.4900 - val_loss: 2.8974 - val_accuracy: 0.2467\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3026 - accuracy: 0.4871 - val_loss: 2.9059 - val_accuracy: 0.2467\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3022 - accuracy: 0.4943 - val_loss: 2.8725 - val_accuracy: 0.2400\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3024 - accuracy: 0.4914 - val_loss: 2.9234 - val_accuracy: 0.2500\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3035 - accuracy: 0.4929 - val_loss: 2.8806 - val_accuracy: 0.2400\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3025 - accuracy: 0.4900 - val_loss: 2.8812 - val_accuracy: 0.2467\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3033 - accuracy: 0.4943 - val_loss: 2.9064 - val_accuracy: 0.2500\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3027 - accuracy: 0.4886 - val_loss: 2.8612 - val_accuracy: 0.2467\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3023 - accuracy: 0.4929 - val_loss: 2.8897 - val_accuracy: 0.2433\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3021 - accuracy: 0.4971 - val_loss: 2.9538 - val_accuracy: 0.2433\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3021 - accuracy: 0.4929 - val_loss: 2.8762 - val_accuracy: 0.2467\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3024 - accuracy: 0.4900 - val_loss: 2.9218 - val_accuracy: 0.2467\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.3022 - accuracy: 0.4957 - val_loss: 2.8549 - val_accuracy: 0.2367\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3023 - accuracy: 0.4900 - val_loss: 2.9003 - val_accuracy: 0.2467\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3026 - accuracy: 0.4871 - val_loss: 2.8540 - val_accuracy: 0.2433\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3025 - accuracy: 0.4943 - val_loss: 2.9057 - val_accuracy: 0.2467\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3021 - accuracy: 0.4986 - val_loss: 2.9067 - val_accuracy: 0.2467\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.3027 - accuracy: 0.4929 - val_loss: 2.8875 - val_accuracy: 0.2433\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3020 - accuracy: 0.4943 - val_loss: 2.8703 - val_accuracy: 0.2467\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3024 - accuracy: 0.4914 - val_loss: 2.9283 - val_accuracy: 0.2433\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3024 - accuracy: 0.4943 - val_loss: 2.9028 - val_accuracy: 0.2467\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.3018 - accuracy: 0.4971 - val_loss: 2.8720 - val_accuracy: 0.2433\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3022 - accuracy: 0.4971 - val_loss: 2.8811 - val_accuracy: 0.2400\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3016 - accuracy: 0.4929 - val_loss: 2.9233 - val_accuracy: 0.2467\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3013 - accuracy: 0.4971 - val_loss: 2.8877 - val_accuracy: 0.2400\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3011 - accuracy: 0.4957 - val_loss: 2.9335 - val_accuracy: 0.2433\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3013 - accuracy: 0.4914 - val_loss: 2.8518 - val_accuracy: 0.2433\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3018 - accuracy: 0.4929 - val_loss: 2.8966 - val_accuracy: 0.2467\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3014 - accuracy: 0.4957 - val_loss: 2.9316 - val_accuracy: 0.2467\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3018 - accuracy: 0.4843 - val_loss: 2.8761 - val_accuracy: 0.2467\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3012 - accuracy: 0.4943 - val_loss: 2.8715 - val_accuracy: 0.2433\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3017 - accuracy: 0.4900 - val_loss: 2.8901 - val_accuracy: 0.2500\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3005 - accuracy: 0.4957 - val_loss: 2.8875 - val_accuracy: 0.2467\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3009 - accuracy: 0.4914 - val_loss: 2.8858 - val_accuracy: 0.2433\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3018 - accuracy: 0.4986 - val_loss: 2.9216 - val_accuracy: 0.2500\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3015 - accuracy: 0.4929 - val_loss: 2.9108 - val_accuracy: 0.2467\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3005 - accuracy: 0.4943 - val_loss: 2.9133 - val_accuracy: 0.2467\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3011 - accuracy: 0.4957 - val_loss: 2.9282 - val_accuracy: 0.2467\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3007 - accuracy: 0.4914 - val_loss: 2.9261 - val_accuracy: 0.2467\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3010 - accuracy: 0.4914 - val_loss: 2.9057 - val_accuracy: 0.2500\n",
      "Epoch 2045/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3015 - accuracy: 0.4957 - val_loss: 2.9395 - val_accuracy: 0.2433\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.3007 - accuracy: 0.4971 - val_loss: 2.8818 - val_accuracy: 0.2467\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3000 - accuracy: 0.4929 - val_loss: 2.9029 - val_accuracy: 0.2500\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3000 - accuracy: 0.4943 - val_loss: 2.8693 - val_accuracy: 0.2433\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.3026 - accuracy: 0.4929 - val_loss: 2.9239 - val_accuracy: 0.2467\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.3009 - accuracy: 0.4900 - val_loss: 2.9248 - val_accuracy: 0.2433\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3010 - accuracy: 0.4929 - val_loss: 2.8964 - val_accuracy: 0.2400\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3012 - accuracy: 0.4943 - val_loss: 2.8942 - val_accuracy: 0.2433\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3008 - accuracy: 0.4900 - val_loss: 2.8887 - val_accuracy: 0.2400\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.3000 - accuracy: 0.4971 - val_loss: 2.9069 - val_accuracy: 0.2433\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.3011 - accuracy: 0.4943 - val_loss: 2.8985 - val_accuracy: 0.2400\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2995 - accuracy: 0.4986 - val_loss: 2.9264 - val_accuracy: 0.2433\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3007 - accuracy: 0.4900 - val_loss: 2.9170 - val_accuracy: 0.2467\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2994 - accuracy: 0.4971 - val_loss: 2.9365 - val_accuracy: 0.2467\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.3001 - accuracy: 0.4929 - val_loss: 2.9158 - val_accuracy: 0.2467\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2999 - accuracy: 0.4929 - val_loss: 2.9154 - val_accuracy: 0.2467\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2998 - accuracy: 0.4900 - val_loss: 2.9118 - val_accuracy: 0.2467\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.3000 - accuracy: 0.4914 - val_loss: 2.9181 - val_accuracy: 0.2467\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2993 - accuracy: 0.4943 - val_loss: 2.9160 - val_accuracy: 0.2467\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2996 - accuracy: 0.4886 - val_loss: 2.9179 - val_accuracy: 0.2467\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2999 - accuracy: 0.4943 - val_loss: 2.9116 - val_accuracy: 0.2467\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2999 - accuracy: 0.4971 - val_loss: 2.9345 - val_accuracy: 0.2433\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2997 - accuracy: 0.4943 - val_loss: 2.9195 - val_accuracy: 0.2500\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2996 - accuracy: 0.4929 - val_loss: 2.9196 - val_accuracy: 0.2433\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2989 - accuracy: 0.4986 - val_loss: 2.9798 - val_accuracy: 0.2467\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2995 - accuracy: 0.4929 - val_loss: 2.9306 - val_accuracy: 0.2467\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2994 - accuracy: 0.4929 - val_loss: 2.9406 - val_accuracy: 0.2433\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2995 - accuracy: 0.4914 - val_loss: 2.9463 - val_accuracy: 0.2433\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2994 - accuracy: 0.4857 - val_loss: 2.9272 - val_accuracy: 0.2500\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2990 - accuracy: 0.4971 - val_loss: 2.9164 - val_accuracy: 0.2467\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2994 - accuracy: 0.4943 - val_loss: 2.9045 - val_accuracy: 0.2467\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2993 - accuracy: 0.4900 - val_loss: 2.9156 - val_accuracy: 0.2433\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2988 - accuracy: 0.4929 - val_loss: 2.9379 - val_accuracy: 0.2467\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2990 - accuracy: 0.4914 - val_loss: 2.9233 - val_accuracy: 0.2400\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2988 - accuracy: 0.4929 - val_loss: 2.9485 - val_accuracy: 0.2400\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2992 - accuracy: 0.4943 - val_loss: 2.9444 - val_accuracy: 0.2433\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2999 - accuracy: 0.4957 - val_loss: 2.9589 - val_accuracy: 0.2467\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2988 - accuracy: 0.4857 - val_loss: 2.8897 - val_accuracy: 0.2367\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2994 - accuracy: 0.4943 - val_loss: 2.9204 - val_accuracy: 0.2467\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2980 - accuracy: 0.4943 - val_loss: 2.9091 - val_accuracy: 0.2533\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2987 - accuracy: 0.4929 - val_loss: 2.8924 - val_accuracy: 0.2400\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2982 - accuracy: 0.4914 - val_loss: 2.9158 - val_accuracy: 0.2467\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2988 - accuracy: 0.4971 - val_loss: 2.9633 - val_accuracy: 0.2500\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2989 - accuracy: 0.4943 - val_loss: 2.9321 - val_accuracy: 0.2433\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2991 - accuracy: 0.4914 - val_loss: 2.9388 - val_accuracy: 0.2467\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2979 - accuracy: 0.4943 - val_loss: 2.9819 - val_accuracy: 0.2433\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2980 - accuracy: 0.4929 - val_loss: 2.9268 - val_accuracy: 0.2467\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2981 - accuracy: 0.4943 - val_loss: 2.9507 - val_accuracy: 0.2467\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2984 - accuracy: 0.4886 - val_loss: 2.9404 - val_accuracy: 0.2467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2987 - accuracy: 0.4943 - val_loss: 2.9301 - val_accuracy: 0.2433\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2974 - accuracy: 0.4971 - val_loss: 2.9619 - val_accuracy: 0.2467\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2979 - accuracy: 0.4914 - val_loss: 2.9437 - val_accuracy: 0.2467\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2974 - accuracy: 0.4929 - val_loss: 2.9237 - val_accuracy: 0.2467\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2968 - accuracy: 0.4943 - val_loss: 2.9134 - val_accuracy: 0.2433\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2982 - accuracy: 0.4929 - val_loss: 2.9367 - val_accuracy: 0.2467\n",
      "Epoch 2100/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2977 - accuracy: 0.4943 - val_loss: 2.9300 - val_accuracy: 0.2433\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2982 - accuracy: 0.5000 - val_loss: 2.9465 - val_accuracy: 0.2467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2982 - accuracy: 0.4957 - val_loss: 2.9457 - val_accuracy: 0.2433\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2974 - accuracy: 0.4957 - val_loss: 2.9532 - val_accuracy: 0.2467\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2977 - accuracy: 0.4971 - val_loss: 2.9145 - val_accuracy: 0.2467\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2971 - accuracy: 0.4900 - val_loss: 2.9387 - val_accuracy: 0.2500\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2978 - accuracy: 0.4957 - val_loss: 2.9099 - val_accuracy: 0.2467\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2973 - accuracy: 0.4900 - val_loss: 2.9215 - val_accuracy: 0.2433\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2976 - accuracy: 0.4943 - val_loss: 2.9449 - val_accuracy: 0.2467\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2976 - accuracy: 0.4914 - val_loss: 2.9393 - val_accuracy: 0.2500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2986 - accuracy: 0.4971 - val_loss: 2.9343 - val_accuracy: 0.2433\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2983 - accuracy: 0.4900 - val_loss: 2.9255 - val_accuracy: 0.2433\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2969 - accuracy: 0.4914 - val_loss: 2.9790 - val_accuracy: 0.2433\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2976 - accuracy: 0.4943 - val_loss: 2.9396 - val_accuracy: 0.2467\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2966 - accuracy: 0.4957 - val_loss: 2.9319 - val_accuracy: 0.2433\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2973 - accuracy: 0.4957 - val_loss: 2.9676 - val_accuracy: 0.2400\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2970 - accuracy: 0.4986 - val_loss: 2.9529 - val_accuracy: 0.2467\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2973 - accuracy: 0.4957 - val_loss: 2.9742 - val_accuracy: 0.2467\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2965 - accuracy: 0.4943 - val_loss: 2.9443 - val_accuracy: 0.2467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2968 - accuracy: 0.4929 - val_loss: 2.9473 - val_accuracy: 0.2467\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2965 - accuracy: 0.4957 - val_loss: 2.9546 - val_accuracy: 0.2467\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2965 - accuracy: 0.4986 - val_loss: 2.9825 - val_accuracy: 0.2400\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2968 - accuracy: 0.4971 - val_loss: 2.9642 - val_accuracy: 0.2433\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2964 - accuracy: 0.4971 - val_loss: 2.9346 - val_accuracy: 0.2433\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2967 - accuracy: 0.4957 - val_loss: 2.9504 - val_accuracy: 0.2467\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2961 - accuracy: 0.4986 - val_loss: 2.9483 - val_accuracy: 0.2433\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2971 - accuracy: 0.4943 - val_loss: 2.9473 - val_accuracy: 0.2433\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2966 - accuracy: 0.4914 - val_loss: 2.9366 - val_accuracy: 0.2400\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2964 - accuracy: 0.4971 - val_loss: 2.9706 - val_accuracy: 0.2433\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2964 - accuracy: 0.4871 - val_loss: 2.9183 - val_accuracy: 0.2433\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2965 - accuracy: 0.5000 - val_loss: 2.9546 - val_accuracy: 0.2400\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2964 - accuracy: 0.4914 - val_loss: 2.9450 - val_accuracy: 0.2467\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2969 - accuracy: 0.4943 - val_loss: 2.9399 - val_accuracy: 0.2400\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2960 - accuracy: 0.4943 - val_loss: 2.9527 - val_accuracy: 0.2500\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2963 - accuracy: 0.5000 - val_loss: 2.9459 - val_accuracy: 0.2433\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2956 - accuracy: 0.4943 - val_loss: 2.9504 - val_accuracy: 0.2467\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2964 - accuracy: 0.4914 - val_loss: 2.9276 - val_accuracy: 0.2433\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2958 - accuracy: 0.4986 - val_loss: 2.9637 - val_accuracy: 0.2433\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2973 - accuracy: 0.4914 - val_loss: 2.9705 - val_accuracy: 0.2467\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2959 - accuracy: 0.5014 - val_loss: 2.9424 - val_accuracy: 0.2467\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2955 - accuracy: 0.4914 - val_loss: 2.9643 - val_accuracy: 0.2433\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2966 - accuracy: 0.4943 - val_loss: 2.9626 - val_accuracy: 0.2467\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2956 - accuracy: 0.4943 - val_loss: 2.9579 - val_accuracy: 0.2467\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2959 - accuracy: 0.4957 - val_loss: 2.9831 - val_accuracy: 0.2433\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2957 - accuracy: 0.4957 - val_loss: 2.9599 - val_accuracy: 0.2467\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2950 - accuracy: 0.4914 - val_loss: 2.9394 - val_accuracy: 0.2500\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2946 - accuracy: 0.4914 - val_loss: 2.9126 - val_accuracy: 0.2467\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2953 - accuracy: 0.5014 - val_loss: 2.9672 - val_accuracy: 0.2433\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2964 - accuracy: 0.4857 - val_loss: 2.9567 - val_accuracy: 0.2467\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2947 - accuracy: 0.5000 - val_loss: 2.9089 - val_accuracy: 0.2467\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2951 - accuracy: 0.4929 - val_loss: 2.9311 - val_accuracy: 0.2533\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2954 - accuracy: 0.4929 - val_loss: 2.9897 - val_accuracy: 0.2367\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2947 - accuracy: 0.4914 - val_loss: 2.9873 - val_accuracy: 0.2467\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2953 - accuracy: 0.4943 - val_loss: 2.9586 - val_accuracy: 0.2467\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2949 - accuracy: 0.4957 - val_loss: 2.9991 - val_accuracy: 0.2367\n",
      "Epoch 2155/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2951 - accuracy: 0.4971 - val_loss: 2.9910 - val_accuracy: 0.2433\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2943 - accuracy: 0.4986 - val_loss: 2.9977 - val_accuracy: 0.2433\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2946 - accuracy: 0.4871 - val_loss: 2.9287 - val_accuracy: 0.2467\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2944 - accuracy: 0.4971 - val_loss: 3.0044 - val_accuracy: 0.2433\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2942 - accuracy: 0.4971 - val_loss: 2.9445 - val_accuracy: 0.2467\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2951 - accuracy: 0.4943 - val_loss: 2.9919 - val_accuracy: 0.2467\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2946 - accuracy: 0.5014 - val_loss: 2.9727 - val_accuracy: 0.2467\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2941 - accuracy: 0.4929 - val_loss: 2.9620 - val_accuracy: 0.2400\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2946 - accuracy: 0.4914 - val_loss: 2.9412 - val_accuracy: 0.2433\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2953 - accuracy: 0.4986 - val_loss: 2.9747 - val_accuracy: 0.2467\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2945 - accuracy: 0.4914 - val_loss: 2.9616 - val_accuracy: 0.2500\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2949 - accuracy: 0.4957 - val_loss: 2.9696 - val_accuracy: 0.2467\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2942 - accuracy: 0.4943 - val_loss: 2.9640 - val_accuracy: 0.2467\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2945 - accuracy: 0.5014 - val_loss: 2.9832 - val_accuracy: 0.2433\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2940 - accuracy: 0.4957 - val_loss: 2.9874 - val_accuracy: 0.2500\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2939 - accuracy: 0.5000 - val_loss: 2.9851 - val_accuracy: 0.2433\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2935 - accuracy: 0.5000 - val_loss: 2.9433 - val_accuracy: 0.2533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2937 - accuracy: 0.4971 - val_loss: 3.0003 - val_accuracy: 0.2467\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2931 - accuracy: 0.4971 - val_loss: 2.9833 - val_accuracy: 0.2467\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2940 - accuracy: 0.5014 - val_loss: 2.9685 - val_accuracy: 0.2400\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2931 - accuracy: 0.4914 - val_loss: 2.9362 - val_accuracy: 0.2500\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2936 - accuracy: 0.4957 - val_loss: 2.9328 - val_accuracy: 0.2467\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2940 - accuracy: 0.4957 - val_loss: 2.9792 - val_accuracy: 0.2533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2939 - accuracy: 0.4957 - val_loss: 2.9736 - val_accuracy: 0.2467\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2930 - accuracy: 0.4986 - val_loss: 2.9691 - val_accuracy: 0.2467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2945 - accuracy: 0.4886 - val_loss: 2.9722 - val_accuracy: 0.2467\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2933 - accuracy: 0.5000 - val_loss: 2.9766 - val_accuracy: 0.2367\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2934 - accuracy: 0.4971 - val_loss: 2.9911 - val_accuracy: 0.2433\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2932 - accuracy: 0.4971 - val_loss: 3.0172 - val_accuracy: 0.2433\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2942 - accuracy: 0.4957 - val_loss: 2.9783 - val_accuracy: 0.2500\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2927 - accuracy: 0.4929 - val_loss: 2.9729 - val_accuracy: 0.2433\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2939 - accuracy: 0.4957 - val_loss: 2.9794 - val_accuracy: 0.2533\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2933 - accuracy: 0.5014 - val_loss: 2.9947 - val_accuracy: 0.2467\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2945 - accuracy: 0.4986 - val_loss: 3.0096 - val_accuracy: 0.2433\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2932 - accuracy: 0.4914 - val_loss: 3.0249 - val_accuracy: 0.2433\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2924 - accuracy: 0.4957 - val_loss: 2.9966 - val_accuracy: 0.2400\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2927 - accuracy: 0.4900 - val_loss: 2.9930 - val_accuracy: 0.2400\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2929 - accuracy: 0.4986 - val_loss: 2.9564 - val_accuracy: 0.2433\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2929 - accuracy: 0.5000 - val_loss: 2.9775 - val_accuracy: 0.2400\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2934 - accuracy: 0.4986 - val_loss: 3.0012 - val_accuracy: 0.2433\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2925 - accuracy: 0.4929 - val_loss: 2.9939 - val_accuracy: 0.2433\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2931 - accuracy: 0.5000 - val_loss: 3.0017 - val_accuracy: 0.2467\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2928 - accuracy: 0.5014 - val_loss: 2.9959 - val_accuracy: 0.2467\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2929 - accuracy: 0.4943 - val_loss: 2.9731 - val_accuracy: 0.2433\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2930 - accuracy: 0.5014 - val_loss: 3.0075 - val_accuracy: 0.2433\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2931 - accuracy: 0.4957 - val_loss: 2.9801 - val_accuracy: 0.2400\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 59us/step - loss: 1.2926 - accuracy: 0.4971 - val_loss: 3.0237 - val_accuracy: 0.2500\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2908 - accuracy: 0.4957 - val_loss: 2.9923 - val_accuracy: 0.2500\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2929 - accuracy: 0.4929 - val_loss: 3.0029 - val_accuracy: 0.2433\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2920 - accuracy: 0.4943 - val_loss: 2.9536 - val_accuracy: 0.2367\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2919 - accuracy: 0.4957 - val_loss: 3.0053 - val_accuracy: 0.2433\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2924 - accuracy: 0.4971 - val_loss: 2.9827 - val_accuracy: 0.2467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2921 - accuracy: 0.4957 - val_loss: 3.0116 - val_accuracy: 0.2433\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2923 - accuracy: 0.5014 - val_loss: 2.9527 - val_accuracy: 0.2400\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2917 - accuracy: 0.4943 - val_loss: 2.9438 - val_accuracy: 0.2533\n",
      "Epoch 2210/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2926 - accuracy: 0.4914 - val_loss: 2.9870 - val_accuracy: 0.2467\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2922 - accuracy: 0.4914 - val_loss: 2.9898 - val_accuracy: 0.2467\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2917 - accuracy: 0.4986 - val_loss: 3.0150 - val_accuracy: 0.2500\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2918 - accuracy: 0.4929 - val_loss: 2.9788 - val_accuracy: 0.2400\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2908 - accuracy: 0.5014 - val_loss: 3.0061 - val_accuracy: 0.2433\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2919 - accuracy: 0.4971 - val_loss: 2.9813 - val_accuracy: 0.2433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2924 - accuracy: 0.4929 - val_loss: 2.9775 - val_accuracy: 0.2433\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2916 - accuracy: 0.4957 - val_loss: 2.9995 - val_accuracy: 0.2467\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2913 - accuracy: 0.5043 - val_loss: 3.0070 - val_accuracy: 0.2367\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2918 - accuracy: 0.4971 - val_loss: 2.9868 - val_accuracy: 0.2433\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2905 - accuracy: 0.5014 - val_loss: 2.9751 - val_accuracy: 0.2500\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2909 - accuracy: 0.5057 - val_loss: 2.9880 - val_accuracy: 0.2533\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2930 - accuracy: 0.4943 - val_loss: 2.9567 - val_accuracy: 0.2433\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2917 - accuracy: 0.4986 - val_loss: 3.0000 - val_accuracy: 0.2533\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2912 - accuracy: 0.4971 - val_loss: 3.0005 - val_accuracy: 0.2467\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2907 - accuracy: 0.4971 - val_loss: 2.9930 - val_accuracy: 0.2500\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2911 - accuracy: 0.4971 - val_loss: 3.0288 - val_accuracy: 0.2500\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2912 - accuracy: 0.5014 - val_loss: 2.9850 - val_accuracy: 0.2433\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2913 - accuracy: 0.4943 - val_loss: 3.0042 - val_accuracy: 0.2500\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2908 - accuracy: 0.5043 - val_loss: 2.9709 - val_accuracy: 0.2400\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2913 - accuracy: 0.5029 - val_loss: 2.9943 - val_accuracy: 0.2433\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2905 - accuracy: 0.5014 - val_loss: 2.9890 - val_accuracy: 0.2500\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2912 - accuracy: 0.4957 - val_loss: 3.0006 - val_accuracy: 0.2467\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2909 - accuracy: 0.4914 - val_loss: 3.0033 - val_accuracy: 0.2500\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2911 - accuracy: 0.4971 - val_loss: 2.9738 - val_accuracy: 0.2433\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2904 - accuracy: 0.5014 - val_loss: 3.0174 - val_accuracy: 0.2433\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2903 - accuracy: 0.4971 - val_loss: 2.9764 - val_accuracy: 0.2400\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2906 - accuracy: 0.4986 - val_loss: 3.0356 - val_accuracy: 0.2400\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2909 - accuracy: 0.4986 - val_loss: 3.0531 - val_accuracy: 0.2367\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2900 - accuracy: 0.4943 - val_loss: 2.9887 - val_accuracy: 0.2567\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2908 - accuracy: 0.5000 - val_loss: 3.0257 - val_accuracy: 0.2433\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2909 - accuracy: 0.4957 - val_loss: 2.9856 - val_accuracy: 0.2467\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2901 - accuracy: 0.4971 - val_loss: 3.0020 - val_accuracy: 0.2467\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2903 - accuracy: 0.4971 - val_loss: 3.0035 - val_accuracy: 0.2467\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2904 - accuracy: 0.4957 - val_loss: 2.9939 - val_accuracy: 0.2433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2894 - accuracy: 0.5014 - val_loss: 3.0497 - val_accuracy: 0.2433\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2898 - accuracy: 0.5000 - val_loss: 3.0106 - val_accuracy: 0.2433\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2900 - accuracy: 0.4971 - val_loss: 3.0019 - val_accuracy: 0.2467\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2903 - accuracy: 0.4943 - val_loss: 3.0819 - val_accuracy: 0.2367\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2910 - accuracy: 0.4986 - val_loss: 3.0042 - val_accuracy: 0.2533\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2896 - accuracy: 0.4986 - val_loss: 2.9994 - val_accuracy: 0.2467\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2908 - accuracy: 0.4929 - val_loss: 3.0059 - val_accuracy: 0.2467\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2899 - accuracy: 0.4957 - val_loss: 2.9869 - val_accuracy: 0.2400\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2888 - accuracy: 0.4957 - val_loss: 3.0356 - val_accuracy: 0.2467\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2902 - accuracy: 0.4943 - val_loss: 3.0290 - val_accuracy: 0.2500\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2895 - accuracy: 0.4986 - val_loss: 3.0367 - val_accuracy: 0.2400\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2899 - accuracy: 0.4986 - val_loss: 3.0064 - val_accuracy: 0.2400\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2898 - accuracy: 0.5000 - val_loss: 3.0487 - val_accuracy: 0.2367\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2894 - accuracy: 0.5029 - val_loss: 2.9942 - val_accuracy: 0.2500\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2886 - accuracy: 0.5014 - val_loss: 3.0578 - val_accuracy: 0.2433\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2896 - accuracy: 0.4957 - val_loss: 3.0301 - val_accuracy: 0.2500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2889 - accuracy: 0.4957 - val_loss: 3.0184 - val_accuracy: 0.2433\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2894 - accuracy: 0.5057 - val_loss: 3.0172 - val_accuracy: 0.2433\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2893 - accuracy: 0.4971 - val_loss: 3.0454 - val_accuracy: 0.2367\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2892 - accuracy: 0.5000 - val_loss: 3.0688 - val_accuracy: 0.2400\n",
      "Epoch 2265/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2898 - accuracy: 0.4971 - val_loss: 3.0117 - val_accuracy: 0.2467\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2890 - accuracy: 0.5014 - val_loss: 3.0649 - val_accuracy: 0.2400\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2899 - accuracy: 0.4929 - val_loss: 3.0009 - val_accuracy: 0.2433\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2891 - accuracy: 0.4986 - val_loss: 2.9907 - val_accuracy: 0.2433\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2879 - accuracy: 0.4971 - val_loss: 3.0618 - val_accuracy: 0.2500\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2895 - accuracy: 0.5014 - val_loss: 3.0078 - val_accuracy: 0.2533\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2893 - accuracy: 0.4929 - val_loss: 3.0545 - val_accuracy: 0.2433\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2883 - accuracy: 0.4971 - val_loss: 3.0627 - val_accuracy: 0.2433\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2890 - accuracy: 0.4971 - val_loss: 3.0107 - val_accuracy: 0.2433\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2892 - accuracy: 0.4957 - val_loss: 3.0373 - val_accuracy: 0.2533\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2885 - accuracy: 0.5014 - val_loss: 3.0313 - val_accuracy: 0.2433\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2889 - accuracy: 0.4957 - val_loss: 3.0383 - val_accuracy: 0.2467\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2895 - accuracy: 0.4957 - val_loss: 3.0362 - val_accuracy: 0.2400\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2883 - accuracy: 0.4914 - val_loss: 3.0252 - val_accuracy: 0.2433\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.9902 - accuracy: 0.60 - 0s 67us/step - loss: 1.2885 - accuracy: 0.4929 - val_loss: 3.0419 - val_accuracy: 0.2400\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2882 - accuracy: 0.4943 - val_loss: 3.0568 - val_accuracy: 0.2333\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2872 - accuracy: 0.5000 - val_loss: 3.0381 - val_accuracy: 0.2500\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2883 - accuracy: 0.4943 - val_loss: 3.0309 - val_accuracy: 0.2467\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2874 - accuracy: 0.5000 - val_loss: 2.9868 - val_accuracy: 0.2500\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2892 - accuracy: 0.5014 - val_loss: 3.0288 - val_accuracy: 0.2533\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2895 - accuracy: 0.4914 - val_loss: 3.0528 - val_accuracy: 0.2400\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2882 - accuracy: 0.4971 - val_loss: 3.0373 - val_accuracy: 0.2467\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2886 - accuracy: 0.4943 - val_loss: 3.0176 - val_accuracy: 0.2400\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2885 - accuracy: 0.5000 - val_loss: 3.0210 - val_accuracy: 0.2433\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2888 - accuracy: 0.5029 - val_loss: 3.0571 - val_accuracy: 0.2467\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2882 - accuracy: 0.4943 - val_loss: 3.0391 - val_accuracy: 0.2400\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2880 - accuracy: 0.4971 - val_loss: 3.0480 - val_accuracy: 0.2433\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2874 - accuracy: 0.5029 - val_loss: 3.0390 - val_accuracy: 0.2400\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2876 - accuracy: 0.5014 - val_loss: 3.0286 - val_accuracy: 0.2467\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2877 - accuracy: 0.5043 - val_loss: 3.0477 - val_accuracy: 0.2500\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2881 - accuracy: 0.4943 - val_loss: 3.0455 - val_accuracy: 0.2400\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2880 - accuracy: 0.4971 - val_loss: 3.0204 - val_accuracy: 0.2467\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2871 - accuracy: 0.4957 - val_loss: 3.0416 - val_accuracy: 0.2433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2871 - accuracy: 0.5000 - val_loss: 3.0597 - val_accuracy: 0.2467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2879 - accuracy: 0.5057 - val_loss: 3.0562 - val_accuracy: 0.2500\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2869 - accuracy: 0.5014 - val_loss: 3.0270 - val_accuracy: 0.2367\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2885 - accuracy: 0.4943 - val_loss: 3.0287 - val_accuracy: 0.2433\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2873 - accuracy: 0.4986 - val_loss: 3.0734 - val_accuracy: 0.2433\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2873 - accuracy: 0.4971 - val_loss: 3.0177 - val_accuracy: 0.2367\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2878 - accuracy: 0.5000 - val_loss: 3.0454 - val_accuracy: 0.2533\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2870 - accuracy: 0.4943 - val_loss: 3.1095 - val_accuracy: 0.2433\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2878 - accuracy: 0.5000 - val_loss: 2.9850 - val_accuracy: 0.2400\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2875 - accuracy: 0.5014 - val_loss: 3.0265 - val_accuracy: 0.2433\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2874 - accuracy: 0.5014 - val_loss: 3.0221 - val_accuracy: 0.2500\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2874 - accuracy: 0.4943 - val_loss: 3.0661 - val_accuracy: 0.2500\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2868 - accuracy: 0.4986 - val_loss: 3.0606 - val_accuracy: 0.2400\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2870 - accuracy: 0.4914 - val_loss: 3.0431 - val_accuracy: 0.2433\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2867 - accuracy: 0.4986 - val_loss: 3.0720 - val_accuracy: 0.2400\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2864 - accuracy: 0.4971 - val_loss: 3.0546 - val_accuracy: 0.2500\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2877 - accuracy: 0.4986 - val_loss: 3.0405 - val_accuracy: 0.2433\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2871 - accuracy: 0.5014 - val_loss: 3.0297 - val_accuracy: 0.2400\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2867 - accuracy: 0.4943 - val_loss: 3.0755 - val_accuracy: 0.2367\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2853 - accuracy: 0.5014 - val_loss: 3.0473 - val_accuracy: 0.2500\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2869 - accuracy: 0.5000 - val_loss: 3.0520 - val_accuracy: 0.2433\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2869 - accuracy: 0.4943 - val_loss: 3.0260 - val_accuracy: 0.2400\n",
      "Epoch 2320/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2868 - accuracy: 0.4943 - val_loss: 3.0513 - val_accuracy: 0.2533\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2864 - accuracy: 0.5000 - val_loss: 3.0604 - val_accuracy: 0.2400\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2866 - accuracy: 0.4957 - val_loss: 3.0595 - val_accuracy: 0.2400\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2866 - accuracy: 0.5000 - val_loss: 3.0060 - val_accuracy: 0.2500\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2865 - accuracy: 0.5000 - val_loss: 3.0846 - val_accuracy: 0.2400\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2866 - accuracy: 0.4943 - val_loss: 3.0392 - val_accuracy: 0.2467\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2867 - accuracy: 0.5000 - val_loss: 3.0619 - val_accuracy: 0.2433\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2865 - accuracy: 0.5043 - val_loss: 3.0423 - val_accuracy: 0.2367\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2865 - accuracy: 0.4971 - val_loss: 3.0824 - val_accuracy: 0.2333\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2867 - accuracy: 0.4986 - val_loss: 3.0841 - val_accuracy: 0.2367\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2861 - accuracy: 0.5014 - val_loss: 3.0891 - val_accuracy: 0.2467\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2855 - accuracy: 0.5014 - val_loss: 3.0540 - val_accuracy: 0.2500\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2870 - accuracy: 0.4986 - val_loss: 3.0503 - val_accuracy: 0.2533\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2861 - accuracy: 0.5029 - val_loss: 3.0665 - val_accuracy: 0.2433\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2863 - accuracy: 0.4971 - val_loss: 3.0518 - val_accuracy: 0.2467\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2850 - accuracy: 0.5029 - val_loss: 3.0615 - val_accuracy: 0.2367\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2858 - accuracy: 0.4914 - val_loss: 3.0845 - val_accuracy: 0.2467\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2875 - accuracy: 0.4986 - val_loss: 3.0611 - val_accuracy: 0.2433\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2860 - accuracy: 0.4943 - val_loss: 3.0657 - val_accuracy: 0.2467\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2855 - accuracy: 0.4943 - val_loss: 3.0896 - val_accuracy: 0.2433\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2853 - accuracy: 0.4957 - val_loss: 3.0997 - val_accuracy: 0.2467\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.2857 - accuracy: 0.4943 - val_loss: 3.0681 - val_accuracy: 0.2500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2857 - accuracy: 0.4986 - val_loss: 3.0439 - val_accuracy: 0.2500\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2856 - accuracy: 0.5029 - val_loss: 3.0690 - val_accuracy: 0.2500\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2852 - accuracy: 0.4971 - val_loss: 3.0570 - val_accuracy: 0.2500\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2856 - accuracy: 0.5029 - val_loss: 3.0680 - val_accuracy: 0.2533\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2858 - accuracy: 0.5000 - val_loss: 3.0885 - val_accuracy: 0.2433\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2856 - accuracy: 0.5000 - val_loss: 3.0657 - val_accuracy: 0.2467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2848 - accuracy: 0.5014 - val_loss: 3.0438 - val_accuracy: 0.2433\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2855 - accuracy: 0.4957 - val_loss: 3.0639 - val_accuracy: 0.2500\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2845 - accuracy: 0.4929 - val_loss: 3.0773 - val_accuracy: 0.2533\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2854 - accuracy: 0.4971 - val_loss: 3.0739 - val_accuracy: 0.2433\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4890 - accuracy: 0.40 - 0s 77us/step - loss: 1.2866 - accuracy: 0.4971 - val_loss: 3.0754 - val_accuracy: 0.2467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2848 - accuracy: 0.4986 - val_loss: 3.0475 - val_accuracy: 0.2500\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2845 - accuracy: 0.4971 - val_loss: 3.0899 - val_accuracy: 0.2300\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2850 - accuracy: 0.4986 - val_loss: 3.0844 - val_accuracy: 0.2367\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2842 - accuracy: 0.4971 - val_loss: 3.0599 - val_accuracy: 0.2433\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2851 - accuracy: 0.4986 - val_loss: 3.0903 - val_accuracy: 0.2367\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2850 - accuracy: 0.4971 - val_loss: 3.0877 - val_accuracy: 0.2400\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2852 - accuracy: 0.5029 - val_loss: 3.0643 - val_accuracy: 0.2533\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2846 - accuracy: 0.4957 - val_loss: 3.0870 - val_accuracy: 0.2400\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2851 - accuracy: 0.5014 - val_loss: 3.0751 - val_accuracy: 0.2400\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2846 - accuracy: 0.4957 - val_loss: 3.0374 - val_accuracy: 0.2467\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2837 - accuracy: 0.5014 - val_loss: 3.0564 - val_accuracy: 0.2433\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2844 - accuracy: 0.5029 - val_loss: 3.0695 - val_accuracy: 0.2367\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2838 - accuracy: 0.5000 - val_loss: 3.1309 - val_accuracy: 0.2467\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2843 - accuracy: 0.5043 - val_loss: 3.0905 - val_accuracy: 0.2300\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2844 - accuracy: 0.4986 - val_loss: 3.0719 - val_accuracy: 0.2333\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2848 - accuracy: 0.5043 - val_loss: 3.0823 - val_accuracy: 0.2333\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2842 - accuracy: 0.5000 - val_loss: 3.0686 - val_accuracy: 0.2400\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2830 - accuracy: 0.5029 - val_loss: 3.0698 - val_accuracy: 0.2467\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2847 - accuracy: 0.5000 - val_loss: 3.0548 - val_accuracy: 0.2533\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2836 - accuracy: 0.5000 - val_loss: 3.0844 - val_accuracy: 0.2433\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2851 - accuracy: 0.4929 - val_loss: 3.1075 - val_accuracy: 0.2467\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2840 - accuracy: 0.5014 - val_loss: 3.1001 - val_accuracy: 0.2367\n",
      "Epoch 2375/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2842 - accuracy: 0.4957 - val_loss: 3.0825 - val_accuracy: 0.2467\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2841 - accuracy: 0.5014 - val_loss: 3.0905 - val_accuracy: 0.2433\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2842 - accuracy: 0.4943 - val_loss: 3.0604 - val_accuracy: 0.2433\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2836 - accuracy: 0.5014 - val_loss: 3.0401 - val_accuracy: 0.2467\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2840 - accuracy: 0.5000 - val_loss: 3.0907 - val_accuracy: 0.2433\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2832 - accuracy: 0.5014 - val_loss: 3.0667 - val_accuracy: 0.2467\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2839 - accuracy: 0.5057 - val_loss: 3.0906 - val_accuracy: 0.2500\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2836 - accuracy: 0.5014 - val_loss: 3.0918 - val_accuracy: 0.2467\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2837 - accuracy: 0.5000 - val_loss: 3.0909 - val_accuracy: 0.2433\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2835 - accuracy: 0.4971 - val_loss: 3.0886 - val_accuracy: 0.2467\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2835 - accuracy: 0.5029 - val_loss: 3.1000 - val_accuracy: 0.2500\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2828 - accuracy: 0.5014 - val_loss: 3.0926 - val_accuracy: 0.2433\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2834 - accuracy: 0.5029 - val_loss: 3.0636 - val_accuracy: 0.2500\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2831 - accuracy: 0.5029 - val_loss: 3.1069 - val_accuracy: 0.2400\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2837 - accuracy: 0.5000 - val_loss: 3.0696 - val_accuracy: 0.2367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2831 - accuracy: 0.4914 - val_loss: 3.1220 - val_accuracy: 0.2433\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2830 - accuracy: 0.4986 - val_loss: 3.1081 - val_accuracy: 0.2467\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.2842 - accuracy: 0.5000 - val_loss: 3.0988 - val_accuracy: 0.2433\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2829 - accuracy: 0.5014 - val_loss: 3.0932 - val_accuracy: 0.2467\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2833 - accuracy: 0.5057 - val_loss: 3.1029 - val_accuracy: 0.2467\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2830 - accuracy: 0.4986 - val_loss: 3.1141 - val_accuracy: 0.2433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2828 - accuracy: 0.5043 - val_loss: 3.1331 - val_accuracy: 0.2433\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2828 - accuracy: 0.5029 - val_loss: 3.1119 - val_accuracy: 0.2433\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2829 - accuracy: 0.5071 - val_loss: 3.0591 - val_accuracy: 0.2500\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2828 - accuracy: 0.5029 - val_loss: 3.1394 - val_accuracy: 0.2433\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2825 - accuracy: 0.5000 - val_loss: 3.1111 - val_accuracy: 0.2433\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2824 - accuracy: 0.4986 - val_loss: 3.1263 - val_accuracy: 0.2433\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2838 - accuracy: 0.4943 - val_loss: 3.0616 - val_accuracy: 0.2433\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2829 - accuracy: 0.4986 - val_loss: 3.0919 - val_accuracy: 0.2467\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2819 - accuracy: 0.5014 - val_loss: 3.0945 - val_accuracy: 0.2500\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2833 - accuracy: 0.5029 - val_loss: 3.0704 - val_accuracy: 0.2467\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2828 - accuracy: 0.5000 - val_loss: 3.0973 - val_accuracy: 0.2467\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2820 - accuracy: 0.5043 - val_loss: 3.0906 - val_accuracy: 0.2367\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2819 - accuracy: 0.5057 - val_loss: 3.1130 - val_accuracy: 0.2500\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2827 - accuracy: 0.4986 - val_loss: 3.0946 - val_accuracy: 0.2467\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2820 - accuracy: 0.4986 - val_loss: 3.1220 - val_accuracy: 0.2367\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2821 - accuracy: 0.5029 - val_loss: 3.0868 - val_accuracy: 0.2400\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2825 - accuracy: 0.5029 - val_loss: 3.1544 - val_accuracy: 0.2467\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2825 - accuracy: 0.4971 - val_loss: 3.1132 - val_accuracy: 0.2367\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2823 - accuracy: 0.4971 - val_loss: 3.1163 - val_accuracy: 0.2400\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2826 - accuracy: 0.5014 - val_loss: 3.1122 - val_accuracy: 0.2433\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2818 - accuracy: 0.4971 - val_loss: 3.0875 - val_accuracy: 0.2400\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2824 - accuracy: 0.4957 - val_loss: 3.1102 - val_accuracy: 0.2433\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2825 - accuracy: 0.5000 - val_loss: 3.1335 - val_accuracy: 0.2300\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2819 - accuracy: 0.4986 - val_loss: 3.0971 - val_accuracy: 0.2500\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2818 - accuracy: 0.5029 - val_loss: 3.0733 - val_accuracy: 0.2400\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2825 - accuracy: 0.4986 - val_loss: 3.0775 - val_accuracy: 0.2367\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2817 - accuracy: 0.5043 - val_loss: 3.1085 - val_accuracy: 0.2367\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2820 - accuracy: 0.5029 - val_loss: 3.1343 - val_accuracy: 0.2433\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2816 - accuracy: 0.5014 - val_loss: 3.0903 - val_accuracy: 0.2467\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2820 - accuracy: 0.5029 - val_loss: 3.1120 - val_accuracy: 0.2400\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2808 - accuracy: 0.5057 - val_loss: 3.0776 - val_accuracy: 0.2400\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2817 - accuracy: 0.4986 - val_loss: 3.1057 - val_accuracy: 0.2367\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2818 - accuracy: 0.5057 - val_loss: 3.0877 - val_accuracy: 0.2400\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2811 - accuracy: 0.5029 - val_loss: 3.1109 - val_accuracy: 0.2433\n",
      "Epoch 2430/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2812 - accuracy: 0.4986 - val_loss: 3.0771 - val_accuracy: 0.2433\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2810 - accuracy: 0.5043 - val_loss: 3.1098 - val_accuracy: 0.2400\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2812 - accuracy: 0.5071 - val_loss: 3.1246 - val_accuracy: 0.2433\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2813 - accuracy: 0.5000 - val_loss: 3.1046 - val_accuracy: 0.2433\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2811 - accuracy: 0.4971 - val_loss: 3.0939 - val_accuracy: 0.2467\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2814 - accuracy: 0.5100 - val_loss: 3.1342 - val_accuracy: 0.2367\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2808 - accuracy: 0.4986 - val_loss: 3.1451 - val_accuracy: 0.2433\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2819 - accuracy: 0.4971 - val_loss: 3.1107 - val_accuracy: 0.2467\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2816 - accuracy: 0.4929 - val_loss: 3.1269 - val_accuracy: 0.2467\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.2919 - accuracy: 0.60 - 0s 61us/step - loss: 1.2818 - accuracy: 0.5057 - val_loss: 3.1426 - val_accuracy: 0.2433\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2816 - accuracy: 0.5043 - val_loss: 3.1438 - val_accuracy: 0.2433\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2804 - accuracy: 0.4943 - val_loss: 3.1001 - val_accuracy: 0.2400\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2814 - accuracy: 0.4971 - val_loss: 3.1627 - val_accuracy: 0.2367\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2809 - accuracy: 0.5071 - val_loss: 3.1425 - val_accuracy: 0.2433\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2803 - accuracy: 0.4986 - val_loss: 3.1182 - val_accuracy: 0.2467\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2812 - accuracy: 0.5014 - val_loss: 3.1150 - val_accuracy: 0.2400\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2806 - accuracy: 0.5029 - val_loss: 3.0977 - val_accuracy: 0.2500\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2805 - accuracy: 0.5029 - val_loss: 3.1491 - val_accuracy: 0.2400\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2805 - accuracy: 0.5000 - val_loss: 3.1152 - val_accuracy: 0.2433\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2809 - accuracy: 0.4971 - val_loss: 3.1356 - val_accuracy: 0.2367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2803 - accuracy: 0.5014 - val_loss: 3.1083 - val_accuracy: 0.2300\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2809 - accuracy: 0.5029 - val_loss: 3.1150 - val_accuracy: 0.2433\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2812 - accuracy: 0.5057 - val_loss: 3.1280 - val_accuracy: 0.2400\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2799 - accuracy: 0.4957 - val_loss: 3.1145 - val_accuracy: 0.2333\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2804 - accuracy: 0.4986 - val_loss: 3.1742 - val_accuracy: 0.2467\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2807 - accuracy: 0.5000 - val_loss: 3.1438 - val_accuracy: 0.2367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2799 - accuracy: 0.5071 - val_loss: 3.1672 - val_accuracy: 0.2467\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2810 - accuracy: 0.5029 - val_loss: 3.1377 - val_accuracy: 0.2433\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2801 - accuracy: 0.5014 - val_loss: 3.1105 - val_accuracy: 0.2467\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2800 - accuracy: 0.5014 - val_loss: 3.1196 - val_accuracy: 0.2433\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2800 - accuracy: 0.5000 - val_loss: 3.1112 - val_accuracy: 0.2400\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2801 - accuracy: 0.5043 - val_loss: 3.1097 - val_accuracy: 0.2500\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2795 - accuracy: 0.5000 - val_loss: 3.1391 - val_accuracy: 0.2367\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2802 - accuracy: 0.5029 - val_loss: 3.1201 - val_accuracy: 0.2400\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2795 - accuracy: 0.5000 - val_loss: 3.1227 - val_accuracy: 0.2467\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2796 - accuracy: 0.4971 - val_loss: 3.1461 - val_accuracy: 0.2433\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2793 - accuracy: 0.4971 - val_loss: 3.1242 - val_accuracy: 0.2433\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2797 - accuracy: 0.5014 - val_loss: 3.1273 - val_accuracy: 0.2300\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2795 - accuracy: 0.5043 - val_loss: 3.1188 - val_accuracy: 0.2500\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2794 - accuracy: 0.4986 - val_loss: 3.1380 - val_accuracy: 0.2333\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2795 - accuracy: 0.4943 - val_loss: 3.1465 - val_accuracy: 0.2467\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2798 - accuracy: 0.5000 - val_loss: 3.1114 - val_accuracy: 0.2500\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2792 - accuracy: 0.5029 - val_loss: 3.1518 - val_accuracy: 0.2367\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2793 - accuracy: 0.5043 - val_loss: 3.1767 - val_accuracy: 0.2333\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2801 - accuracy: 0.5000 - val_loss: 3.1371 - val_accuracy: 0.2300\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2791 - accuracy: 0.5000 - val_loss: 3.1544 - val_accuracy: 0.2400\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2789 - accuracy: 0.5029 - val_loss: 3.1561 - val_accuracy: 0.2433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2794 - accuracy: 0.4971 - val_loss: 3.1279 - val_accuracy: 0.2400\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2798 - accuracy: 0.4957 - val_loss: 3.1436 - val_accuracy: 0.2367\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2781 - accuracy: 0.5057 - val_loss: 3.0990 - val_accuracy: 0.2467\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2780 - accuracy: 0.5057 - val_loss: 3.1773 - val_accuracy: 0.2333\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2784 - accuracy: 0.5014 - val_loss: 3.1510 - val_accuracy: 0.2433\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2786 - accuracy: 0.4986 - val_loss: 3.1629 - val_accuracy: 0.2367\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2792 - accuracy: 0.5000 - val_loss: 3.1267 - val_accuracy: 0.2400\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2793 - accuracy: 0.4986 - val_loss: 3.1525 - val_accuracy: 0.2400\n",
      "Epoch 2485/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2791 - accuracy: 0.5029 - val_loss: 3.1348 - val_accuracy: 0.2333\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2784 - accuracy: 0.5043 - val_loss: 3.1273 - val_accuracy: 0.2467\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2785 - accuracy: 0.4971 - val_loss: 3.1741 - val_accuracy: 0.2433\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2786 - accuracy: 0.4957 - val_loss: 3.0929 - val_accuracy: 0.2467\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2799 - accuracy: 0.5014 - val_loss: 3.1603 - val_accuracy: 0.2400\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2783 - accuracy: 0.5029 - val_loss: 3.1238 - val_accuracy: 0.2500\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2789 - accuracy: 0.4986 - val_loss: 3.1475 - val_accuracy: 0.2367\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 60us/step - loss: 1.2796 - accuracy: 0.4986 - val_loss: 3.1347 - val_accuracy: 0.2467\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 58us/step - loss: 1.2787 - accuracy: 0.5029 - val_loss: 3.1816 - val_accuracy: 0.2400\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2785 - accuracy: 0.4943 - val_loss: 3.1316 - val_accuracy: 0.2433\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2784 - accuracy: 0.5014 - val_loss: 3.2034 - val_accuracy: 0.2433\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2791 - accuracy: 0.4986 - val_loss: 3.1675 - val_accuracy: 0.2433\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2789 - accuracy: 0.5014 - val_loss: 3.1644 - val_accuracy: 0.2400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2785 - accuracy: 0.5029 - val_loss: 3.1862 - val_accuracy: 0.2433\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2784 - accuracy: 0.5057 - val_loss: 3.1285 - val_accuracy: 0.2367\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2776 - accuracy: 0.5057 - val_loss: 3.1201 - val_accuracy: 0.2533\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2786 - accuracy: 0.5014 - val_loss: 3.2029 - val_accuracy: 0.2400\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2781 - accuracy: 0.4971 - val_loss: 3.1570 - val_accuracy: 0.2433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2779 - accuracy: 0.4971 - val_loss: 3.1660 - val_accuracy: 0.2400\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.2779 - accuracy: 0.5071 - val_loss: 3.1453 - val_accuracy: 0.2467\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2791 - accuracy: 0.4957 - val_loss: 3.1572 - val_accuracy: 0.2467\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2778 - accuracy: 0.5043 - val_loss: 3.1533 - val_accuracy: 0.2400\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2780 - accuracy: 0.4986 - val_loss: 3.1456 - val_accuracy: 0.2433\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2777 - accuracy: 0.5014 - val_loss: 3.1998 - val_accuracy: 0.2467\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2776 - accuracy: 0.5057 - val_loss: 3.1590 - val_accuracy: 0.2433\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2775 - accuracy: 0.5014 - val_loss: 3.1713 - val_accuracy: 0.2367\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2777 - accuracy: 0.4986 - val_loss: 3.1361 - val_accuracy: 0.2433\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2774 - accuracy: 0.5043 - val_loss: 3.1758 - val_accuracy: 0.2467\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2781 - accuracy: 0.5014 - val_loss: 3.1435 - val_accuracy: 0.2433\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.2770 - accuracy: 0.5000 - val_loss: 3.1296 - val_accuracy: 0.2400\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.2771 - accuracy: 0.5014 - val_loss: 3.1515 - val_accuracy: 0.2433\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.2771 - accuracy: 0.5000 - val_loss: 3.1822 - val_accuracy: 0.2433\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.2782 - accuracy: 0.5000 - val_loss: 3.1818 - val_accuracy: 0.2433\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2775 - accuracy: 0.5043 - val_loss: 3.1639 - val_accuracy: 0.2433\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2775 - accuracy: 0.5071 - val_loss: 3.1749 - val_accuracy: 0.2400\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.2769 - accuracy: 0.4971 - val_loss: 3.1710 - val_accuracy: 0.2367\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2771 - accuracy: 0.4986 - val_loss: 3.1643 - val_accuracy: 0.2367\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2778 - accuracy: 0.5014 - val_loss: 3.1515 - val_accuracy: 0.2367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2774 - accuracy: 0.5000 - val_loss: 3.1499 - val_accuracy: 0.2333\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2769 - accuracy: 0.4986 - val_loss: 3.1515 - val_accuracy: 0.2433\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2772 - accuracy: 0.5014 - val_loss: 3.1788 - val_accuracy: 0.2433\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2769 - accuracy: 0.4986 - val_loss: 3.1544 - val_accuracy: 0.2333\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2767 - accuracy: 0.5014 - val_loss: 3.1840 - val_accuracy: 0.2400\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2766 - accuracy: 0.5014 - val_loss: 3.1740 - val_accuracy: 0.2333\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2777 - accuracy: 0.5057 - val_loss: 3.1967 - val_accuracy: 0.2400\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2763 - accuracy: 0.5000 - val_loss: 3.1729 - val_accuracy: 0.2367\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2765 - accuracy: 0.5057 - val_loss: 3.1425 - val_accuracy: 0.2433\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2766 - accuracy: 0.5071 - val_loss: 3.1751 - val_accuracy: 0.2433\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2777 - accuracy: 0.5057 - val_loss: 3.1707 - val_accuracy: 0.2433\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2768 - accuracy: 0.5014 - val_loss: 3.1882 - val_accuracy: 0.2367\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2770 - accuracy: 0.5043 - val_loss: 3.1639 - val_accuracy: 0.2433\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2768 - accuracy: 0.5043 - val_loss: 3.1994 - val_accuracy: 0.2400\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2772 - accuracy: 0.5057 - val_loss: 3.1514 - val_accuracy: 0.2433\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2762 - accuracy: 0.5029 - val_loss: 3.1809 - val_accuracy: 0.2400\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2773 - accuracy: 0.4986 - val_loss: 3.2060 - val_accuracy: 0.2400\n",
      "Epoch 2540/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2770 - accuracy: 0.5014 - val_loss: 3.2081 - val_accuracy: 0.2467\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2764 - accuracy: 0.5057 - val_loss: 3.1819 - val_accuracy: 0.2367\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2760 - accuracy: 0.5057 - val_loss: 3.1716 - val_accuracy: 0.2433\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2766 - accuracy: 0.5043 - val_loss: 3.1804 - val_accuracy: 0.2333\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2768 - accuracy: 0.4986 - val_loss: 3.1759 - val_accuracy: 0.2333\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2763 - accuracy: 0.5086 - val_loss: 3.2089 - val_accuracy: 0.2400\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2768 - accuracy: 0.5057 - val_loss: 3.2078 - val_accuracy: 0.2400\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2767 - accuracy: 0.5043 - val_loss: 3.1964 - val_accuracy: 0.2433\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2759 - accuracy: 0.5029 - val_loss: 3.1845 - val_accuracy: 0.2433\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2761 - accuracy: 0.5000 - val_loss: 3.1644 - val_accuracy: 0.2367\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2762 - accuracy: 0.5043 - val_loss: 3.1715 - val_accuracy: 0.2367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2755 - accuracy: 0.4986 - val_loss: 3.2068 - val_accuracy: 0.2433\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2758 - accuracy: 0.5043 - val_loss: 3.1591 - val_accuracy: 0.2333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2754 - accuracy: 0.5000 - val_loss: 3.1693 - val_accuracy: 0.2367\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2756 - accuracy: 0.4986 - val_loss: 3.1594 - val_accuracy: 0.2333\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2763 - accuracy: 0.5000 - val_loss: 3.1993 - val_accuracy: 0.2433\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2762 - accuracy: 0.5000 - val_loss: 3.1612 - val_accuracy: 0.2400\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2754 - accuracy: 0.5000 - val_loss: 3.2042 - val_accuracy: 0.2433\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2757 - accuracy: 0.4986 - val_loss: 3.2016 - val_accuracy: 0.2433\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2758 - accuracy: 0.5043 - val_loss: 3.1937 - val_accuracy: 0.2400\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2762 - accuracy: 0.5000 - val_loss: 3.1953 - val_accuracy: 0.2400\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2757 - accuracy: 0.5057 - val_loss: 3.1768 - val_accuracy: 0.2333\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2751 - accuracy: 0.5000 - val_loss: 3.1692 - val_accuracy: 0.2433\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2753 - accuracy: 0.5029 - val_loss: 3.1907 - val_accuracy: 0.2467\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2761 - accuracy: 0.5029 - val_loss: 3.1934 - val_accuracy: 0.2400\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2755 - accuracy: 0.5043 - val_loss: 3.1817 - val_accuracy: 0.2400\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2760 - accuracy: 0.5014 - val_loss: 3.1976 - val_accuracy: 0.2400\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2759 - accuracy: 0.5057 - val_loss: 3.1804 - val_accuracy: 0.2433\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2754 - accuracy: 0.5043 - val_loss: 3.1809 - val_accuracy: 0.2333\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2742 - accuracy: 0.5000 - val_loss: 3.1647 - val_accuracy: 0.2433\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2750 - accuracy: 0.4986 - val_loss: 3.2062 - val_accuracy: 0.2433\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2750 - accuracy: 0.5043 - val_loss: 3.1963 - val_accuracy: 0.2400\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2752 - accuracy: 0.5086 - val_loss: 3.2094 - val_accuracy: 0.2433\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2743 - accuracy: 0.5043 - val_loss: 3.2451 - val_accuracy: 0.2433\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2754 - accuracy: 0.4971 - val_loss: 3.1492 - val_accuracy: 0.2433\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2748 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2433\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2747 - accuracy: 0.5071 - val_loss: 3.2081 - val_accuracy: 0.2433\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2749 - accuracy: 0.5029 - val_loss: 3.2051 - val_accuracy: 0.2433\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2746 - accuracy: 0.5014 - val_loss: 3.1948 - val_accuracy: 0.2433\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2749 - accuracy: 0.5029 - val_loss: 3.1872 - val_accuracy: 0.2367\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2746 - accuracy: 0.5014 - val_loss: 3.1996 - val_accuracy: 0.2433\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2741 - accuracy: 0.5029 - val_loss: 3.1650 - val_accuracy: 0.2367\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2747 - accuracy: 0.5043 - val_loss: 3.2219 - val_accuracy: 0.2367\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2749 - accuracy: 0.5043 - val_loss: 3.2027 - val_accuracy: 0.2433\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2745 - accuracy: 0.5086 - val_loss: 3.2029 - val_accuracy: 0.2400\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2741 - accuracy: 0.5014 - val_loss: 3.1934 - val_accuracy: 0.2400\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2742 - accuracy: 0.5071 - val_loss: 3.1815 - val_accuracy: 0.2433\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2744 - accuracy: 0.5057 - val_loss: 3.2214 - val_accuracy: 0.2400\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2745 - accuracy: 0.5014 - val_loss: 3.1965 - val_accuracy: 0.2367\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2743 - accuracy: 0.5014 - val_loss: 3.1901 - val_accuracy: 0.2367\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2736 - accuracy: 0.5014 - val_loss: 3.1920 - val_accuracy: 0.2333\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2738 - accuracy: 0.5029 - val_loss: 3.1714 - val_accuracy: 0.2433\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2743 - accuracy: 0.5071 - val_loss: 3.2311 - val_accuracy: 0.2400\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2740 - accuracy: 0.4986 - val_loss: 3.1688 - val_accuracy: 0.2433\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2739 - accuracy: 0.5043 - val_loss: 3.2245 - val_accuracy: 0.2400\n",
      "Epoch 2595/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2745 - accuracy: 0.4971 - val_loss: 3.2038 - val_accuracy: 0.2333\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2748 - accuracy: 0.5071 - val_loss: 3.1949 - val_accuracy: 0.2367\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2739 - accuracy: 0.5043 - val_loss: 3.1998 - val_accuracy: 0.2433\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2733 - accuracy: 0.4986 - val_loss: 3.2180 - val_accuracy: 0.2467\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2740 - accuracy: 0.5029 - val_loss: 3.1791 - val_accuracy: 0.2367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2734 - accuracy: 0.5057 - val_loss: 3.2008 - val_accuracy: 0.2433\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2734 - accuracy: 0.5029 - val_loss: 3.1994 - val_accuracy: 0.2433\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2745 - accuracy: 0.5086 - val_loss: 3.2144 - val_accuracy: 0.2433\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2737 - accuracy: 0.5057 - val_loss: 3.1867 - val_accuracy: 0.2433\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2734 - accuracy: 0.5057 - val_loss: 3.2175 - val_accuracy: 0.2400\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2739 - accuracy: 0.5014 - val_loss: 3.2092 - val_accuracy: 0.2367\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2739 - accuracy: 0.5014 - val_loss: 3.2013 - val_accuracy: 0.2333\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2733 - accuracy: 0.5000 - val_loss: 3.1853 - val_accuracy: 0.2400\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2736 - accuracy: 0.5000 - val_loss: 3.2379 - val_accuracy: 0.2400\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2734 - accuracy: 0.4986 - val_loss: 3.1981 - val_accuracy: 0.2400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2736 - accuracy: 0.5029 - val_loss: 3.1858 - val_accuracy: 0.2433\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2736 - accuracy: 0.5014 - val_loss: 3.1876 - val_accuracy: 0.2400\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2737 - accuracy: 0.5029 - val_loss: 3.2261 - val_accuracy: 0.2400\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2733 - accuracy: 0.5057 - val_loss: 3.2148 - val_accuracy: 0.2433\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2729 - accuracy: 0.5043 - val_loss: 3.2341 - val_accuracy: 0.2433\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2731 - accuracy: 0.5043 - val_loss: 3.2059 - val_accuracy: 0.2433\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2733 - accuracy: 0.5043 - val_loss: 3.2451 - val_accuracy: 0.2400\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2737 - accuracy: 0.5043 - val_loss: 3.2205 - val_accuracy: 0.2400\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2737 - accuracy: 0.4986 - val_loss: 3.1915 - val_accuracy: 0.2367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2733 - accuracy: 0.5043 - val_loss: 3.2209 - val_accuracy: 0.2367\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2732 - accuracy: 0.5057 - val_loss: 3.2249 - val_accuracy: 0.2367\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2730 - accuracy: 0.5057 - val_loss: 3.2217 - val_accuracy: 0.2333\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2736 - accuracy: 0.5000 - val_loss: 3.1888 - val_accuracy: 0.2400\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2729 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2400\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2723 - accuracy: 0.5029 - val_loss: 3.1944 - val_accuracy: 0.2333\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2725 - accuracy: 0.5043 - val_loss: 3.2388 - val_accuracy: 0.2433\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2729 - accuracy: 0.5000 - val_loss: 3.2409 - val_accuracy: 0.2433\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2727 - accuracy: 0.5014 - val_loss: 3.2240 - val_accuracy: 0.2367\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2724 - accuracy: 0.5043 - val_loss: 3.2312 - val_accuracy: 0.2367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2725 - accuracy: 0.5029 - val_loss: 3.2195 - val_accuracy: 0.2367\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2722 - accuracy: 0.5029 - val_loss: 3.1707 - val_accuracy: 0.2433\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2726 - accuracy: 0.5057 - val_loss: 3.2321 - val_accuracy: 0.2367\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2733 - accuracy: 0.4986 - val_loss: 3.2187 - val_accuracy: 0.2433\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2720 - accuracy: 0.5043 - val_loss: 3.2203 - val_accuracy: 0.2367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2718 - accuracy: 0.5086 - val_loss: 3.2083 - val_accuracy: 0.2367\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2730 - accuracy: 0.5043 - val_loss: 3.2457 - val_accuracy: 0.2367\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2725 - accuracy: 0.5014 - val_loss: 3.2223 - val_accuracy: 0.2367\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2727 - accuracy: 0.5057 - val_loss: 3.2285 - val_accuracy: 0.2400\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2721 - accuracy: 0.5000 - val_loss: 3.2379 - val_accuracy: 0.2433\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2724 - accuracy: 0.5043 - val_loss: 3.1877 - val_accuracy: 0.2467\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2721 - accuracy: 0.5071 - val_loss: 3.2542 - val_accuracy: 0.2467\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2720 - accuracy: 0.5086 - val_loss: 3.3056 - val_accuracy: 0.2467\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2719 - accuracy: 0.4986 - val_loss: 3.1854 - val_accuracy: 0.2400\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2720 - accuracy: 0.5129 - val_loss: 3.2231 - val_accuracy: 0.2433\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2720 - accuracy: 0.5000 - val_loss: 3.2263 - val_accuracy: 0.2433\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2718 - accuracy: 0.5029 - val_loss: 3.2218 - val_accuracy: 0.2433\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 62us/step - loss: 1.2724 - accuracy: 0.5057 - val_loss: 3.2380 - val_accuracy: 0.2467\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2722 - accuracy: 0.5043 - val_loss: 3.2414 - val_accuracy: 0.2467\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2719 - accuracy: 0.5029 - val_loss: 3.2479 - val_accuracy: 0.2433\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2721 - accuracy: 0.5043 - val_loss: 3.2017 - val_accuracy: 0.2400\n",
      "Epoch 2650/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2714 - accuracy: 0.5014 - val_loss: 3.2057 - val_accuracy: 0.2400\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2711 - accuracy: 0.5014 - val_loss: 3.2178 - val_accuracy: 0.2433\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2714 - accuracy: 0.5100 - val_loss: 3.2037 - val_accuracy: 0.2500\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2721 - accuracy: 0.5086 - val_loss: 3.2682 - val_accuracy: 0.2433\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2720 - accuracy: 0.5014 - val_loss: 3.2231 - val_accuracy: 0.2400\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2713 - accuracy: 0.5043 - val_loss: 3.2401 - val_accuracy: 0.2367\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2717 - accuracy: 0.5057 - val_loss: 3.2517 - val_accuracy: 0.2400\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2710 - accuracy: 0.5014 - val_loss: 3.1837 - val_accuracy: 0.2367\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2713 - accuracy: 0.5029 - val_loss: 3.2474 - val_accuracy: 0.2400\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2710 - accuracy: 0.4971 - val_loss: 3.2049 - val_accuracy: 0.2367\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2716 - accuracy: 0.5000 - val_loss: 3.2713 - val_accuracy: 0.2433\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2724 - accuracy: 0.5000 - val_loss: 3.2303 - val_accuracy: 0.2367\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2721 - accuracy: 0.5029 - val_loss: 3.2267 - val_accuracy: 0.2400\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2708 - accuracy: 0.5071 - val_loss: 3.2114 - val_accuracy: 0.2367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2708 - accuracy: 0.5043 - val_loss: 3.2271 - val_accuracy: 0.2367\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2715 - accuracy: 0.5043 - val_loss: 3.2102 - val_accuracy: 0.2367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2715 - accuracy: 0.5057 - val_loss: 3.2198 - val_accuracy: 0.2367\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2706 - accuracy: 0.5114 - val_loss: 3.2256 - val_accuracy: 0.2433\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2713 - accuracy: 0.5057 - val_loss: 3.2807 - val_accuracy: 0.2500\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2707 - accuracy: 0.5086 - val_loss: 3.2578 - val_accuracy: 0.2433\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2710 - accuracy: 0.5043 - val_loss: 3.2652 - val_accuracy: 0.2433\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2712 - accuracy: 0.5071 - val_loss: 3.2614 - val_accuracy: 0.2400\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2707 - accuracy: 0.5071 - val_loss: 3.2680 - val_accuracy: 0.2467\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2713 - accuracy: 0.5086 - val_loss: 3.2224 - val_accuracy: 0.2433\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2708 - accuracy: 0.5014 - val_loss: 3.2473 - val_accuracy: 0.2433\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2707 - accuracy: 0.5029 - val_loss: 3.2115 - val_accuracy: 0.2367\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2712 - accuracy: 0.5043 - val_loss: 3.2497 - val_accuracy: 0.2400\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2711 - accuracy: 0.5014 - val_loss: 3.2751 - val_accuracy: 0.2467\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2713 - accuracy: 0.5086 - val_loss: 3.2473 - val_accuracy: 0.2367\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2710 - accuracy: 0.5029 - val_loss: 3.2511 - val_accuracy: 0.2467\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2735 - accuracy: 0.5071 - val_loss: 3.2232 - val_accuracy: 0.2367\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2709 - accuracy: 0.4986 - val_loss: 3.2741 - val_accuracy: 0.2367\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2702 - accuracy: 0.5029 - val_loss: 3.2300 - val_accuracy: 0.2400\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2708 - accuracy: 0.5029 - val_loss: 3.2582 - val_accuracy: 0.2433\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2699 - accuracy: 0.5043 - val_loss: 3.2648 - val_accuracy: 0.2433\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2706 - accuracy: 0.5043 - val_loss: 3.2406 - val_accuracy: 0.2400\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2704 - accuracy: 0.5071 - val_loss: 3.2465 - val_accuracy: 0.2400\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2700 - accuracy: 0.5014 - val_loss: 3.2375 - val_accuracy: 0.2333\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2703 - accuracy: 0.5071 - val_loss: 3.2737 - val_accuracy: 0.2433\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2548 - val_accuracy: 0.2433\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2707 - accuracy: 0.5071 - val_loss: 3.1897 - val_accuracy: 0.2400\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2706 - accuracy: 0.5029 - val_loss: 3.2644 - val_accuracy: 0.2467\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2697 - accuracy: 0.5029 - val_loss: 3.2541 - val_accuracy: 0.2367\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2698 - accuracy: 0.5057 - val_loss: 3.2791 - val_accuracy: 0.2433\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2701 - accuracy: 0.5029 - val_loss: 3.2400 - val_accuracy: 0.2433\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2691 - accuracy: 0.5071 - val_loss: 3.2574 - val_accuracy: 0.2467\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2696 - accuracy: 0.5086 - val_loss: 3.2422 - val_accuracy: 0.2367\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2706 - accuracy: 0.5057 - val_loss: 3.2268 - val_accuracy: 0.2400\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2699 - accuracy: 0.5057 - val_loss: 3.2648 - val_accuracy: 0.2367\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2700 - accuracy: 0.5057 - val_loss: 3.2811 - val_accuracy: 0.2467\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2696 - accuracy: 0.5043 - val_loss: 3.2638 - val_accuracy: 0.2467\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2701 - accuracy: 0.5057 - val_loss: 3.2801 - val_accuracy: 0.2433\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2794 - val_accuracy: 0.2367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2693 - accuracy: 0.5057 - val_loss: 3.2559 - val_accuracy: 0.2433\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2691 - accuracy: 0.5043 - val_loss: 3.2291 - val_accuracy: 0.2433\n",
      "Epoch 2705/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2694 - accuracy: 0.5043 - val_loss: 3.2502 - val_accuracy: 0.2467\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2700 - accuracy: 0.5057 - val_loss: 3.2647 - val_accuracy: 0.2467\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2702 - accuracy: 0.5043 - val_loss: 3.2682 - val_accuracy: 0.2400\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2695 - accuracy: 0.5029 - val_loss: 3.2695 - val_accuracy: 0.2400\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2690 - accuracy: 0.5043 - val_loss: 3.2455 - val_accuracy: 0.2367\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2696 - accuracy: 0.5000 - val_loss: 3.2431 - val_accuracy: 0.2367\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2698 - accuracy: 0.5057 - val_loss: 3.2415 - val_accuracy: 0.2433\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2690 - accuracy: 0.5014 - val_loss: 3.2078 - val_accuracy: 0.2400\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2695 - accuracy: 0.5071 - val_loss: 3.2908 - val_accuracy: 0.2500\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2691 - accuracy: 0.5029 - val_loss: 3.2943 - val_accuracy: 0.2467\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2697 - accuracy: 0.5071 - val_loss: 3.2615 - val_accuracy: 0.2433\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2691 - accuracy: 0.5057 - val_loss: 3.2411 - val_accuracy: 0.2433\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2690 - accuracy: 0.5057 - val_loss: 3.2610 - val_accuracy: 0.2433\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2695 - accuracy: 0.5057 - val_loss: 3.2803 - val_accuracy: 0.2467\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2692 - accuracy: 0.5057 - val_loss: 3.2434 - val_accuracy: 0.2433\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2693 - accuracy: 0.5043 - val_loss: 3.2631 - val_accuracy: 0.2400\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2695 - accuracy: 0.4986 - val_loss: 3.2488 - val_accuracy: 0.2367\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2690 - accuracy: 0.5043 - val_loss: 3.2687 - val_accuracy: 0.2467\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2695 - accuracy: 0.5057 - val_loss: 3.2878 - val_accuracy: 0.2467\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2692 - accuracy: 0.5029 - val_loss: 3.2782 - val_accuracy: 0.2467\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2685 - accuracy: 0.5057 - val_loss: 3.2927 - val_accuracy: 0.2467\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2684 - accuracy: 0.5029 - val_loss: 3.3024 - val_accuracy: 0.2467\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2683 - accuracy: 0.5071 - val_loss: 3.2825 - val_accuracy: 0.2433\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2679 - accuracy: 0.5014 - val_loss: 3.2271 - val_accuracy: 0.2433\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2685 - accuracy: 0.5057 - val_loss: 3.2757 - val_accuracy: 0.2433\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2684 - accuracy: 0.5086 - val_loss: 3.2483 - val_accuracy: 0.2400\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2682 - accuracy: 0.5029 - val_loss: 3.2691 - val_accuracy: 0.2400\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2694 - accuracy: 0.5057 - val_loss: 3.2951 - val_accuracy: 0.2433\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2699 - accuracy: 0.5029 - val_loss: 3.2470 - val_accuracy: 0.2367\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2678 - accuracy: 0.5129 - val_loss: 3.2634 - val_accuracy: 0.2433\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2682 - accuracy: 0.5057 - val_loss: 3.2759 - val_accuracy: 0.2400\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2681 - accuracy: 0.5114 - val_loss: 3.2153 - val_accuracy: 0.2367\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2677 - accuracy: 0.5129 - val_loss: 3.3035 - val_accuracy: 0.2500\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2681 - accuracy: 0.5086 - val_loss: 3.2889 - val_accuracy: 0.2367\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2678 - accuracy: 0.5100 - val_loss: 3.3000 - val_accuracy: 0.2433\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2686 - accuracy: 0.5043 - val_loss: 3.2489 - val_accuracy: 0.2400\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2690 - accuracy: 0.5029 - val_loss: 3.3021 - val_accuracy: 0.2400\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2691 - accuracy: 0.5029 - val_loss: 3.2899 - val_accuracy: 0.2400\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2683 - accuracy: 0.5000 - val_loss: 3.2713 - val_accuracy: 0.2400\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2688 - accuracy: 0.5029 - val_loss: 3.2881 - val_accuracy: 0.2433\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2683 - accuracy: 0.5014 - val_loss: 3.2947 - val_accuracy: 0.2433\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2684 - accuracy: 0.5071 - val_loss: 3.2999 - val_accuracy: 0.2433\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2686 - accuracy: 0.5014 - val_loss: 3.2655 - val_accuracy: 0.2367\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2681 - accuracy: 0.5057 - val_loss: 3.3114 - val_accuracy: 0.2467\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2682 - accuracy: 0.5029 - val_loss: 3.2902 - val_accuracy: 0.2433\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2677 - accuracy: 0.5071 - val_loss: 3.3078 - val_accuracy: 0.2467\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2679 - accuracy: 0.5057 - val_loss: 3.2918 - val_accuracy: 0.2433\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2674 - accuracy: 0.5100 - val_loss: 3.2849 - val_accuracy: 0.2367\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2673 - accuracy: 0.5057 - val_loss: 3.2983 - val_accuracy: 0.2500\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2682 - accuracy: 0.5071 - val_loss: 3.2634 - val_accuracy: 0.2400\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2668 - accuracy: 0.5029 - val_loss: 3.2423 - val_accuracy: 0.2433\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2676 - accuracy: 0.5057 - val_loss: 3.3065 - val_accuracy: 0.2467\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2685 - accuracy: 0.5043 - val_loss: 3.2728 - val_accuracy: 0.2433\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2683 - accuracy: 0.5057 - val_loss: 3.2149 - val_accuracy: 0.2367\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2678 - accuracy: 0.5086 - val_loss: 3.3059 - val_accuracy: 0.2433\n",
      "Epoch 2760/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2676 - accuracy: 0.5071 - val_loss: 3.2988 - val_accuracy: 0.2467\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2672 - accuracy: 0.5014 - val_loss: 3.2880 - val_accuracy: 0.2467\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2672 - accuracy: 0.5129 - val_loss: 3.2748 - val_accuracy: 0.2367\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2680 - accuracy: 0.5057 - val_loss: 3.3126 - val_accuracy: 0.2400\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2662 - accuracy: 0.5000 - val_loss: 3.3193 - val_accuracy: 0.2467\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2673 - accuracy: 0.5029 - val_loss: 3.2818 - val_accuracy: 0.2433\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2666 - accuracy: 0.5100 - val_loss: 3.3025 - val_accuracy: 0.2433\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2676 - accuracy: 0.5129 - val_loss: 3.3060 - val_accuracy: 0.2400\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2670 - accuracy: 0.5114 - val_loss: 3.3141 - val_accuracy: 0.2467\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2664 - accuracy: 0.5071 - val_loss: 3.3091 - val_accuracy: 0.2433\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2668 - accuracy: 0.5071 - val_loss: 3.2770 - val_accuracy: 0.2367\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2662 - accuracy: 0.5100 - val_loss: 3.2704 - val_accuracy: 0.2367\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2694 - accuracy: 0.5071 - val_loss: 3.2732 - val_accuracy: 0.2400\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2670 - accuracy: 0.5057 - val_loss: 3.2934 - val_accuracy: 0.2400\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.3001 - val_accuracy: 0.2467\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.2830 - val_accuracy: 0.2400\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2671 - accuracy: 0.5071 - val_loss: 3.2994 - val_accuracy: 0.2433\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2674 - accuracy: 0.5057 - val_loss: 3.3273 - val_accuracy: 0.2467\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2672 - accuracy: 0.5043 - val_loss: 3.3110 - val_accuracy: 0.2400\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2660 - accuracy: 0.5100 - val_loss: 3.2880 - val_accuracy: 0.2433\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2666 - accuracy: 0.5029 - val_loss: 3.3233 - val_accuracy: 0.2467\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2675 - accuracy: 0.5014 - val_loss: 3.3073 - val_accuracy: 0.2433\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.0063 - accuracy: 0.60 - 0s 64us/step - loss: 1.2665 - accuracy: 0.5071 - val_loss: 3.2525 - val_accuracy: 0.2367\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2664 - accuracy: 0.5043 - val_loss: 3.3217 - val_accuracy: 0.2467\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2659 - accuracy: 0.5029 - val_loss: 3.3161 - val_accuracy: 0.2467\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2665 - accuracy: 0.5086 - val_loss: 3.2930 - val_accuracy: 0.2400\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2668 - accuracy: 0.5100 - val_loss: 3.2067 - val_accuracy: 0.2433\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2670 - accuracy: 0.5057 - val_loss: 3.3028 - val_accuracy: 0.2433\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2662 - accuracy: 0.5057 - val_loss: 3.3421 - val_accuracy: 0.2433\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2661 - accuracy: 0.5043 - val_loss: 3.3268 - val_accuracy: 0.2400\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2663 - accuracy: 0.5057 - val_loss: 3.3288 - val_accuracy: 0.2433\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2668 - accuracy: 0.5043 - val_loss: 3.2641 - val_accuracy: 0.2400\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2661 - accuracy: 0.5029 - val_loss: 3.2729 - val_accuracy: 0.2400\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2659 - accuracy: 0.5057 - val_loss: 3.2618 - val_accuracy: 0.2367\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2668 - accuracy: 0.5057 - val_loss: 3.3166 - val_accuracy: 0.2467\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2657 - accuracy: 0.5057 - val_loss: 3.2778 - val_accuracy: 0.2333\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2659 - accuracy: 0.5057 - val_loss: 3.3176 - val_accuracy: 0.2467\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2662 - accuracy: 0.5057 - val_loss: 3.3043 - val_accuracy: 0.2400\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2653 - accuracy: 0.5114 - val_loss: 3.3345 - val_accuracy: 0.2433\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2657 - accuracy: 0.5071 - val_loss: 3.2826 - val_accuracy: 0.2400\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2667 - accuracy: 0.5014 - val_loss: 3.3126 - val_accuracy: 0.2433\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2663 - accuracy: 0.5086 - val_loss: 3.3535 - val_accuracy: 0.2400\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2661 - accuracy: 0.5071 - val_loss: 3.3291 - val_accuracy: 0.2433\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2659 - accuracy: 0.5086 - val_loss: 3.3064 - val_accuracy: 0.2433\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2655 - accuracy: 0.5043 - val_loss: 3.3189 - val_accuracy: 0.2467\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2655 - accuracy: 0.5057 - val_loss: 3.3457 - val_accuracy: 0.2433\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2657 - accuracy: 0.5029 - val_loss: 3.3388 - val_accuracy: 0.2467\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2658 - accuracy: 0.5057 - val_loss: 3.3205 - val_accuracy: 0.2500\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2651 - accuracy: 0.5071 - val_loss: 3.2964 - val_accuracy: 0.2467\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2653 - accuracy: 0.5043 - val_loss: 3.3302 - val_accuracy: 0.2467\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2653 - accuracy: 0.5057 - val_loss: 3.3129 - val_accuracy: 0.2467\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2648 - accuracy: 0.5029 - val_loss: 3.3305 - val_accuracy: 0.2467\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2657 - accuracy: 0.5071 - val_loss: 3.3072 - val_accuracy: 0.2433\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2659 - accuracy: 0.5129 - val_loss: 3.3457 - val_accuracy: 0.2433\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2652 - accuracy: 0.5043 - val_loss: 3.3085 - val_accuracy: 0.2367\n",
      "Epoch 2815/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2656 - accuracy: 0.5071 - val_loss: 3.3446 - val_accuracy: 0.2433\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2658 - accuracy: 0.5071 - val_loss: 3.3064 - val_accuracy: 0.2433\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2651 - accuracy: 0.5057 - val_loss: 3.3311 - val_accuracy: 0.2433\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2654 - accuracy: 0.5057 - val_loss: 3.3211 - val_accuracy: 0.2433\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2651 - accuracy: 0.5071 - val_loss: 3.3147 - val_accuracy: 0.2467\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.7437 - accuracy: 0.40 - 0s 67us/step - loss: 1.2657 - accuracy: 0.5057 - val_loss: 3.2952 - val_accuracy: 0.2367\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2656 - accuracy: 0.5029 - val_loss: 3.3052 - val_accuracy: 0.2400\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2652 - accuracy: 0.5100 - val_loss: 3.3329 - val_accuracy: 0.2400\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2646 - accuracy: 0.5057 - val_loss: 3.3397 - val_accuracy: 0.2400\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2645 - accuracy: 0.5086 - val_loss: 3.3356 - val_accuracy: 0.2400\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2650 - accuracy: 0.5071 - val_loss: 3.3444 - val_accuracy: 0.2467\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2643 - accuracy: 0.5086 - val_loss: 3.3495 - val_accuracy: 0.2433\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2654 - accuracy: 0.5043 - val_loss: 3.3040 - val_accuracy: 0.2367\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2654 - accuracy: 0.5071 - val_loss: 3.3586 - val_accuracy: 0.2433\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2652 - accuracy: 0.5043 - val_loss: 3.3067 - val_accuracy: 0.2400\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2638 - accuracy: 0.5057 - val_loss: 3.3115 - val_accuracy: 0.2433\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2652 - accuracy: 0.5143 - val_loss: 3.2955 - val_accuracy: 0.2433\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2644 - accuracy: 0.5114 - val_loss: 3.3699 - val_accuracy: 0.2467\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2645 - accuracy: 0.5086 - val_loss: 3.3226 - val_accuracy: 0.2433\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2648 - accuracy: 0.5029 - val_loss: 3.3242 - val_accuracy: 0.2400\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2643 - accuracy: 0.5014 - val_loss: 3.3545 - val_accuracy: 0.2433\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2647 - accuracy: 0.5057 - val_loss: 3.3259 - val_accuracy: 0.2400\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2642 - accuracy: 0.5086 - val_loss: 3.3462 - val_accuracy: 0.2433\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2648 - accuracy: 0.5057 - val_loss: 3.2648 - val_accuracy: 0.2400\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2644 - accuracy: 0.5100 - val_loss: 3.3333 - val_accuracy: 0.2433\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2645 - accuracy: 0.5029 - val_loss: 3.3324 - val_accuracy: 0.2400\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2641 - accuracy: 0.5029 - val_loss: 3.3327 - val_accuracy: 0.2467\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2642 - accuracy: 0.5071 - val_loss: 3.3189 - val_accuracy: 0.2433\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2644 - accuracy: 0.5057 - val_loss: 3.3272 - val_accuracy: 0.2367\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2637 - accuracy: 0.5057 - val_loss: 3.3435 - val_accuracy: 0.2467\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2646 - accuracy: 0.5086 - val_loss: 3.3650 - val_accuracy: 0.2433\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2636 - accuracy: 0.5071 - val_loss: 3.3953 - val_accuracy: 0.2467\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2643 - accuracy: 0.5057 - val_loss: 3.3488 - val_accuracy: 0.2433\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2635 - accuracy: 0.5086 - val_loss: 3.3164 - val_accuracy: 0.2400\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2641 - accuracy: 0.5100 - val_loss: 3.3499 - val_accuracy: 0.2400\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2641 - accuracy: 0.5086 - val_loss: 3.3427 - val_accuracy: 0.2367\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3421 - val_accuracy: 0.2367\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2640 - accuracy: 0.5071 - val_loss: 3.3851 - val_accuracy: 0.2467\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2638 - accuracy: 0.5043 - val_loss: 3.3501 - val_accuracy: 0.2467\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 61us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3043 - val_accuracy: 0.2400\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2637 - accuracy: 0.5086 - val_loss: 3.3529 - val_accuracy: 0.2400\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2635 - accuracy: 0.5043 - val_loss: 3.3563 - val_accuracy: 0.2367\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2635 - accuracy: 0.5086 - val_loss: 3.3665 - val_accuracy: 0.2467\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2634 - accuracy: 0.5057 - val_loss: 3.3732 - val_accuracy: 0.2467\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2632 - accuracy: 0.5029 - val_loss: 3.3128 - val_accuracy: 0.2400\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2638 - accuracy: 0.5129 - val_loss: 3.2872 - val_accuracy: 0.2400\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2636 - accuracy: 0.5100 - val_loss: 3.3611 - val_accuracy: 0.2433\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2631 - accuracy: 0.5000 - val_loss: 3.3506 - val_accuracy: 0.2433\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2631 - accuracy: 0.5043 - val_loss: 3.3461 - val_accuracy: 0.2433\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2633 - accuracy: 0.5014 - val_loss: 3.3307 - val_accuracy: 0.2433\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2639 - accuracy: 0.5143 - val_loss: 3.3578 - val_accuracy: 0.2400\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2635 - accuracy: 0.5129 - val_loss: 3.3671 - val_accuracy: 0.2433\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2631 - accuracy: 0.5100 - val_loss: 3.3584 - val_accuracy: 0.2467\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2641 - accuracy: 0.5057 - val_loss: 3.3063 - val_accuracy: 0.2433\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2631 - accuracy: 0.5057 - val_loss: 3.3450 - val_accuracy: 0.2467\n",
      "Epoch 2870/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2627 - accuracy: 0.5057 - val_loss: 3.4149 - val_accuracy: 0.2467\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2637 - accuracy: 0.5086 - val_loss: 3.3790 - val_accuracy: 0.2467\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2632 - accuracy: 0.5057 - val_loss: 3.3612 - val_accuracy: 0.2433\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2630 - accuracy: 0.5129 - val_loss: 3.3120 - val_accuracy: 0.2400\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2633 - accuracy: 0.5186 - val_loss: 3.3161 - val_accuracy: 0.2433\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2629 - accuracy: 0.5086 - val_loss: 3.3516 - val_accuracy: 0.2467\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2643 - accuracy: 0.5057 - val_loss: 3.3909 - val_accuracy: 0.2467\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2633 - accuracy: 0.5043 - val_loss: 3.3774 - val_accuracy: 0.2433\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2627 - accuracy: 0.5086 - val_loss: 3.3443 - val_accuracy: 0.2433\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3599 - val_accuracy: 0.2467\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2623 - accuracy: 0.5071 - val_loss: 3.3822 - val_accuracy: 0.2400\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.2636 - accuracy: 0.5071 - val_loss: 3.3618 - val_accuracy: 0.2400\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2630 - accuracy: 0.5057 - val_loss: 3.3054 - val_accuracy: 0.2400\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2621 - accuracy: 0.5100 - val_loss: 3.2554 - val_accuracy: 0.2433\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2629 - accuracy: 0.5071 - val_loss: 3.3988 - val_accuracy: 0.2433\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2626 - accuracy: 0.5043 - val_loss: 3.3304 - val_accuracy: 0.2367\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2627 - accuracy: 0.5086 - val_loss: 3.3512 - val_accuracy: 0.2433\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2626 - accuracy: 0.5114 - val_loss: 3.3845 - val_accuracy: 0.2467\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2623 - accuracy: 0.5029 - val_loss: 3.3403 - val_accuracy: 0.2467\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2628 - accuracy: 0.5129 - val_loss: 3.3105 - val_accuracy: 0.2400\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2627 - accuracy: 0.5114 - val_loss: 3.3306 - val_accuracy: 0.2433\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.2628 - accuracy: 0.5043 - val_loss: 3.3622 - val_accuracy: 0.2467\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2626 - accuracy: 0.5043 - val_loss: 3.3681 - val_accuracy: 0.2467\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2636 - accuracy: 0.5057 - val_loss: 3.3630 - val_accuracy: 0.2433\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2626 - accuracy: 0.5057 - val_loss: 3.4042 - val_accuracy: 0.2467\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2620 - accuracy: 0.5086 - val_loss: 3.3810 - val_accuracy: 0.2400\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2625 - accuracy: 0.5086 - val_loss: 3.3710 - val_accuracy: 0.2433\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2627 - accuracy: 0.5114 - val_loss: 3.4127 - val_accuracy: 0.2400\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2622 - accuracy: 0.5071 - val_loss: 3.3813 - val_accuracy: 0.2400\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2624 - accuracy: 0.5100 - val_loss: 3.3686 - val_accuracy: 0.2433\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2616 - accuracy: 0.5100 - val_loss: 3.3612 - val_accuracy: 0.2433\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2619 - accuracy: 0.5114 - val_loss: 3.3752 - val_accuracy: 0.2400\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2625 - accuracy: 0.5100 - val_loss: 3.4206 - val_accuracy: 0.2467\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2625 - accuracy: 0.5086 - val_loss: 3.3530 - val_accuracy: 0.2400\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2620 - accuracy: 0.5100 - val_loss: 3.3491 - val_accuracy: 0.2400\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2617 - accuracy: 0.5114 - val_loss: 3.3764 - val_accuracy: 0.2433\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3757 - val_accuracy: 0.2467\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2611 - accuracy: 0.5057 - val_loss: 3.3800 - val_accuracy: 0.2467\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2615 - accuracy: 0.5171 - val_loss: 3.4058 - val_accuracy: 0.2400\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2618 - accuracy: 0.5029 - val_loss: 3.3454 - val_accuracy: 0.2433\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2617 - accuracy: 0.5143 - val_loss: 3.3665 - val_accuracy: 0.2433\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2620 - accuracy: 0.5029 - val_loss: 3.3131 - val_accuracy: 0.2333\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2621 - accuracy: 0.5057 - val_loss: 3.3230 - val_accuracy: 0.2367\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2621 - accuracy: 0.5043 - val_loss: 3.3574 - val_accuracy: 0.2433\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2616 - accuracy: 0.5057 - val_loss: 3.3507 - val_accuracy: 0.2400\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2620 - accuracy: 0.5071 - val_loss: 3.3117 - val_accuracy: 0.2367\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.4026 - val_accuracy: 0.2467\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2614 - accuracy: 0.5114 - val_loss: 3.3731 - val_accuracy: 0.2467\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2616 - accuracy: 0.5129 - val_loss: 3.3862 - val_accuracy: 0.2467\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2611 - accuracy: 0.5100 - val_loss: 3.3899 - val_accuracy: 0.2433\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2608 - accuracy: 0.5071 - val_loss: 3.3499 - val_accuracy: 0.2367\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2613 - accuracy: 0.5100 - val_loss: 3.3484 - val_accuracy: 0.2400\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2610 - accuracy: 0.5057 - val_loss: 3.3905 - val_accuracy: 0.2400\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2609 - accuracy: 0.5129 - val_loss: 3.3561 - val_accuracy: 0.2467\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3779 - val_accuracy: 0.2467\n",
      "Epoch 2925/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2608 - accuracy: 0.5100 - val_loss: 3.4046 - val_accuracy: 0.2433\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3811 - val_accuracy: 0.2433\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2618 - accuracy: 0.5086 - val_loss: 3.4173 - val_accuracy: 0.2467\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2611 - accuracy: 0.5100 - val_loss: 3.3681 - val_accuracy: 0.2433\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2606 - accuracy: 0.5086 - val_loss: 3.3886 - val_accuracy: 0.2467\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2604 - accuracy: 0.5057 - val_loss: 3.4308 - val_accuracy: 0.2467\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2609 - accuracy: 0.5071 - val_loss: 3.4096 - val_accuracy: 0.2433\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2608 - accuracy: 0.5043 - val_loss: 3.3770 - val_accuracy: 0.2433\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2604 - accuracy: 0.5129 - val_loss: 3.3914 - val_accuracy: 0.2400\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2614 - accuracy: 0.5100 - val_loss: 3.4000 - val_accuracy: 0.2467\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2613 - accuracy: 0.5114 - val_loss: 3.3797 - val_accuracy: 0.2400\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2602 - accuracy: 0.5129 - val_loss: 3.3810 - val_accuracy: 0.2467\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2610 - accuracy: 0.5114 - val_loss: 3.4107 - val_accuracy: 0.2433\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2619 - accuracy: 0.5086 - val_loss: 3.3753 - val_accuracy: 0.2467\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2610 - accuracy: 0.5086 - val_loss: 3.3962 - val_accuracy: 0.2467\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2604 - accuracy: 0.5100 - val_loss: 3.4034 - val_accuracy: 0.2400\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2597 - accuracy: 0.5071 - val_loss: 3.3383 - val_accuracy: 0.2400\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2626 - accuracy: 0.5100 - val_loss: 3.3910 - val_accuracy: 0.2433\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2603 - accuracy: 0.5114 - val_loss: 3.4167 - val_accuracy: 0.2433\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2603 - accuracy: 0.5114 - val_loss: 3.3795 - val_accuracy: 0.2433\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2602 - accuracy: 0.5114 - val_loss: 3.4175 - val_accuracy: 0.2467\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2602 - accuracy: 0.5071 - val_loss: 3.4193 - val_accuracy: 0.2433\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2605 - accuracy: 0.5100 - val_loss: 3.3645 - val_accuracy: 0.2433\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2601 - accuracy: 0.5071 - val_loss: 3.4020 - val_accuracy: 0.2433\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2612 - accuracy: 0.5114 - val_loss: 3.3740 - val_accuracy: 0.2367\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2602 - accuracy: 0.5157 - val_loss: 3.3758 - val_accuracy: 0.2433\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2606 - accuracy: 0.5114 - val_loss: 3.4402 - val_accuracy: 0.2400\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2603 - accuracy: 0.5100 - val_loss: 3.4025 - val_accuracy: 0.2367\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2600 - accuracy: 0.5100 - val_loss: 3.4009 - val_accuracy: 0.2467\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2619 - accuracy: 0.5071 - val_loss: 3.3987 - val_accuracy: 0.2433\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2600 - accuracy: 0.5086 - val_loss: 3.3483 - val_accuracy: 0.2400\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2604 - accuracy: 0.5071 - val_loss: 3.3517 - val_accuracy: 0.2367\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2601 - accuracy: 0.5129 - val_loss: 3.4081 - val_accuracy: 0.2433\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2607 - accuracy: 0.5086 - val_loss: 3.3981 - val_accuracy: 0.2433\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2602 - accuracy: 0.5057 - val_loss: 3.3814 - val_accuracy: 0.2433\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 65us/step - loss: 1.2604 - accuracy: 0.5143 - val_loss: 3.3939 - val_accuracy: 0.2400\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2596 - accuracy: 0.5171 - val_loss: 3.3864 - val_accuracy: 0.2400\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2601 - accuracy: 0.5071 - val_loss: 3.4121 - val_accuracy: 0.2433\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2595 - accuracy: 0.5114 - val_loss: 3.3911 - val_accuracy: 0.2433\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2598 - accuracy: 0.5057 - val_loss: 3.3788 - val_accuracy: 0.2400\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2599 - accuracy: 0.5129 - val_loss: 3.3494 - val_accuracy: 0.2400\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2597 - accuracy: 0.5086 - val_loss: 3.3748 - val_accuracy: 0.2367\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2599 - accuracy: 0.5057 - val_loss: 3.3782 - val_accuracy: 0.2433\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2596 - accuracy: 0.5043 - val_loss: 3.4237 - val_accuracy: 0.2433\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2599 - accuracy: 0.5143 - val_loss: 3.4195 - val_accuracy: 0.2433\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2588 - accuracy: 0.5129 - val_loss: 3.4507 - val_accuracy: 0.2433\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2598 - accuracy: 0.5086 - val_loss: 3.3750 - val_accuracy: 0.2467\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 63us/step - loss: 1.2598 - accuracy: 0.5129 - val_loss: 3.3832 - val_accuracy: 0.2433\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2595 - accuracy: 0.5086 - val_loss: 3.3602 - val_accuracy: 0.2400\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3969 - val_accuracy: 0.2433\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2595 - accuracy: 0.5100 - val_loss: 3.4095 - val_accuracy: 0.2433\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2595 - accuracy: 0.5100 - val_loss: 3.4135 - val_accuracy: 0.2433\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2589 - accuracy: 0.5100 - val_loss: 3.4090 - val_accuracy: 0.2400\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2587 - accuracy: 0.5143 - val_loss: 3.4170 - val_accuracy: 0.2467\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3656 - val_accuracy: 0.2467\n",
      "Epoch 2980/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2588 - accuracy: 0.5071 - val_loss: 3.4359 - val_accuracy: 0.2467\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2594 - accuracy: 0.5114 - val_loss: 3.4116 - val_accuracy: 0.2467\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2595 - accuracy: 0.5114 - val_loss: 3.3728 - val_accuracy: 0.2433\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2593 - accuracy: 0.5114 - val_loss: 3.4204 - val_accuracy: 0.2433\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2587 - accuracy: 0.5129 - val_loss: 3.4150 - val_accuracy: 0.2467\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2592 - accuracy: 0.5114 - val_loss: 3.4272 - val_accuracy: 0.2467\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2587 - accuracy: 0.5129 - val_loss: 3.4170 - val_accuracy: 0.2433\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2592 - accuracy: 0.5114 - val_loss: 3.4234 - val_accuracy: 0.2433\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2591 - accuracy: 0.5143 - val_loss: 3.4228 - val_accuracy: 0.2400\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2587 - accuracy: 0.5071 - val_loss: 3.4008 - val_accuracy: 0.2433\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2586 - accuracy: 0.5129 - val_loss: 3.4220 - val_accuracy: 0.2433\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2596 - accuracy: 0.5143 - val_loss: 3.3987 - val_accuracy: 0.2433\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.2594 - accuracy: 0.5114 - val_loss: 3.4029 - val_accuracy: 0.2467\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2589 - accuracy: 0.5086 - val_loss: 3.4200 - val_accuracy: 0.2433\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2589 - accuracy: 0.5100 - val_loss: 3.3714 - val_accuracy: 0.2467\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2583 - accuracy: 0.5071 - val_loss: 3.4406 - val_accuracy: 0.2467\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2586 - accuracy: 0.5114 - val_loss: 3.4515 - val_accuracy: 0.2467\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2585 - accuracy: 0.5100 - val_loss: 3.3971 - val_accuracy: 0.2400\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2587 - accuracy: 0.5114 - val_loss: 3.4285 - val_accuracy: 0.2433\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2585 - accuracy: 0.5071 - val_loss: 3.4221 - val_accuracy: 0.2433\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2591 - accuracy: 0.5086 - val_loss: 3.4185 - val_accuracy: 0.2467\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000, batch_size=10, validation_data=(xVal,yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU1d348c93JpM9gSSEfQkoVfYgEVEqYLUoWrdHanFDrY9Ltbauj7jUan36WPfdulR5sOL2oP6q1bq1AmqVPQgIsghIkC2B7PvM+f1xbkgIWSZhbiaT+b5fr3nNnXvPvfO9mSTfOefce44YY1BKKRW9POEOQCmlVHhpIlBKqSiniUAppaKcJgKllIpymgiUUirKxYQ7gLbq0aOHycrKCncYSikVUZYtW5ZvjMlsalvEJYKsrCyWLl0a7jCUUiqiiMjW5rZp05BSSkU51xKBiMSLyGIRWSkia0Tk7ibKXCIie0Qk13n8p1vxKKWUapqbTUNVwE+MMaUi4gM+F5F/GGO+alTudWPMr12MQymlVAtcSwTGjl1R6rz0OQ9XxrOoqakhLy+PyspKNw4fFeLj4+nfvz8+ny/coSilOpirncUi4gWWAYcDTxljFjVR7BwRmQSsB643xmxr4jhXAFcADBw48KAD5OXlkZKSQlZWFiISylOICsYYCgoKyMvLY/DgweEORynVwVztLDbG+I0x2UB/YLyIjGxU5F0gyxgzGvgEmNPMcZ4zxuQYY3IyMw+++qmyspKMjAxNAu0kImRkZGiNSqko1SFXDRljCoH5wCmN1hcYY6qcl88D49r7HpoEDo3+/JSKXm5eNZQpIt2d5QTgJGBdozJ9Grw8A1jrVjxKKRVxFiyAvXuhpATmznXtbdysEfQBPhWRr4ElwMfGmL+LyB9E5AynzG+cS0tXAr8BLnExHtcUFhby9NNPt2vfU089lcLCwqDL33XXXTz44IPtei+lVIT45BPYuBGmTIHTToOrroILLwSXbqZ186qhr4GxTay/s8HyrcCtbsXQUeoSwdVXX33QNr/fj9frbXbf999/383QlFKRwhi4/3447zz46U/r13/1lX0AFBe78tZ6Z3EIzJo1i02bNpGdnc3NN9/M/PnzOeGEEzj//PMZNWoUAGeddRbjxo1jxIgRPPfcc/v3zcrKIj8/ny1btjBs2DAuv/xyRowYwdSpU6moqGjxfXNzc5kwYQKjR4/m7LPPZt++fQA8/vjjDB8+nNGjRzNjxgwAFixYQHZ2NtnZ2YwdO5aSkhKXfhpKqVbt2mX/8QM8+KBtAvr2W5g1CwYNan6/G25wJZyIG2uoNRs2XEdpaW5Ij5mcnM3QoY82u/1Pf/oTq1evJjfXvu/8+fNZvHgxq1ev3n855osvvkh6ejoVFRUcffTRnHPOOWRkZDSKfQOvvvoqzz//POeeey5vvvkmF154YbPvO3PmTJ544gkmT57MnXfeyd13382jjz7Kn/70JzZv3kxcXNz+ZqcHH3yQp556iokTJ1JaWkp8fPyh/liUUu2xZg2MHAlPPw2BANx8s10/YULr+65c6UpIWiNwyfjx4w+4Jv/xxx9nzJgxTJgwgW3btrFhw4aD9hk8eDDZ2dkAjBs3ji1btjR7/KKiIgoLC5k8eTIAF198MQsXLgRg9OjRXHDBBbz88svExNhcP3HiRG644QYef/xxCgsL969XSnWQbdtg0SKo+9u/+mr4dYNBFb5qPOhCE+6915XQutx/g5a+uXekpKSk/cvz58/nk08+4csvvyQxMZEpU6Y0ec1+XFzc/mWv19tq01Bz3nvvPRYuXMg777zDPffcw5o1a5g1axannXYa77//PhMmTOCTTz7hyCOPbNfxlVLtMGQI1NbamkB7XXBB6OJpQGsEIZCSktJim3tRURFpaWkkJiaybt06vgom87eiW7dupKWl8dlnnwHw17/+lcmTJxMIBNi2bRsnnHAC999/P4WFhZSWlrJp0yZGjRrFLbfcQk5ODuvWrWvlHZRSIVNZaZMA2JpAew0YEJp4GulyNYJwyMjIYOLEiYwcOZJp06Zx2mmnHbD9lFNO4ZlnnmH06NEcccQRTAimLTAIc+bM4aqrrqK8vJwhQ4Ywe/Zs/H4/F154IUVFRRhjuP766+nevTu/+93v+PTTT/F6vQwfPpxp06aFJAalVCtqaiAhIdxRtEiMcWUcONfk5OSYxhPTrF27lmHDhoUpoq5Df45KhUhtLdx+u+0I/v3vD605CGwHc+/ekJ7e7kOIyDJjTE5T27RGoJRSofTtt/YGsPnz7X0BbZGQAI37BgsLoVu3kIXXFO0jUEqpUCkshCOPtEkgWKeeWr+cn2+fTzgB1q61w0u4nARAawRKKRUar78Ozg2cbdK/f/1yYiLs2wdJSdCBc4NojUAppRqrqoIlS1ovV1MDjz0GIu1LAgBpaQe+7t69Q5MAaI1AKaUO9utfw1/+Aps3Q1bWwdu/+QZOOgl27Dj097rtNsjIsLWBMNEagVJKNbbImUyxqMiOCeT329eBgO3MHTGifUngkkvsc8Mbw1JT7dVF11xzSCEfCk0EYZKcnNym9UqpDhQI2OfaWhg4EGJi4PDDwett2zf39ettInEGn+Tyy2HaNPjv/w59zIdAm4aUUqqxuhpAToPL7jdtavtxhg61z3X3ayUnQyccel5rBCFwyy23HDAxzV133cVDDz1EaWkpJ554IkcddRSjRo3ib3/7W9DHNMZw8803M3LkSEaNGsXrr78OwI4dO5g0aRLZ2dmMHDmSzz77DL/fzyWXXLK/7COPPBLyc1QqqtTVCNrqiSfqlxvOKTB7Npx8sr20tBPqejWC666D3NAOQ012Njza/GB2M2bM4Lrrrts/Mc0bb7zBBx98QHx8PG+//Tapqank5+czYcIEzjjjjKDmB37rrbfIzc1l5cqV5Ofnc/TRRzNp0iReeeUVTj75ZG6//Xb8fj/l5eXk5uayfft2Vq9eDdCmGc+UilqrV8PUqbBiBfTqZS/bnDTJdg6vX9++Y86cCddea5c/+qh+fU4OfPDBgWXnzDnw0tEw6nqJIAzGjh3L7t27+eGHH9izZw9paWkMHDiQmpoabrvtNhYuXIjH42H79u3s2rWL3r17t3rMzz//nPPOOw+v10uvXr2YPHkyS5Ys4eijj+aXv/wlNTU1nHXWWWRnZzNkyBC+++47rr32Wk477TSmTp3aAWetVIR74AHb4Tt7tr0M9E5n8kTnC1W7pKQEX3bmzPa/T4h1vUTQwjd3N02fPp158+axc+fO/bOCzZ07lz179rBs2TJ8Ph9ZWVlNDj/dlObGgJo0aRILFy7kvffe46KLLuLmm29m5syZrFy5kg8//JCnnnqKN954gxdffDFk56ZUl7Rtm32+NYSz5QZR2++MtI8gRGbMmMFrr73GvHnzmD59OmCHn+7Zsyc+n49PP/2UrVu3Bn28SZMm8frrr+P3+9mzZw8LFy5k/PjxbN26lZ49e3L55Zdz2WWXsXz5cvLz8wkEApxzzjncc889LF++3K3TVCqylJcf+HrxYtsM9PDDsGpV+4552WX2+aKL6tcde2z7jtVJdL0aQZiMGDGCkpIS+vXrR58+fQC44IILOP3008nJySE7O7tNE8GcffbZfPnll4wZMwYR4f7776d3797MmTOHBx54AJ/PR3JyMi+99BLbt2/n0ksvJeB0cN3r0ixGSkWUJUtg/Hi7/Oqr0LcvODP6ceONbTvWGWfAO+/Y5QsvhBdesH0BDz1kawFxcbBzp90+ZQpE2HwfOgy12k9/jqpLefrp0N2kZQwcc4ytUTR3t3Enp8NQK6W6vuJi+609O9tOBF9WFprj1l3Z8/bb9hGBSaA1mgiUUpFvyxYYOfLQ/vn/4hfw2mu2aWfBAlsLqKmp7wDu2zesw0C4qct0FkdaE1dnoz8/FXHefx+efNIu/+hHh5YE7r8fXnnFLr/3HmzYYJd9Pju8RBfXJc4wPj6egoICMjIygrpZSx3IGENBQQHx8fHhDkWp4OTmQt3c4OecY7+5B+vqq23iyM623/7nzDnwmv6kJDuuUBTpEomgf//+5OXlsWfPnnCHErHi4+Pp30nuclTqIDt22Ilffvtb2L0bxo6t39a3b3DHGDHC7vfUU/Xrtm61g8pFuS6RCHw+H4MHDw53GEopt5x3nm23nzrV/kNvj7ffrh8Ero4mAaAL9REopbqAVavgvvsOXl9UZJ/ffbftx7zuOtvx2zgJqP00ESilOo9x42DWrPphm2+4AT7+uH7qxlmzWj9G48nedTTeVmkiUEqFR0HBwevqOn23b7fX7z/yiG0OCmb+YLB39BYWwoMP2td6g2RQNBEopTrem29Cjx7w7383vX3AAJsM2sIYOOIIu3zjjbBxI3z11aHFGSU0ESilOt78+fZ54kR7w9ahjs3zwgsHrzvsMDsfsGpVl7hqSCkVQcrK6m8Eq9PeJpxAwNYEPPqd9lDoT08p1bF+97tD2z8nxzb5FBba2oQmgUOmP0GlVMcpKIB//CP48k1dJfSf/2lHAm18dZBqN9cSgYjEi8hiEVkpImtE5O4mysSJyOsislFEFolIllvxKKXC4C9/sd/aRexQDscf37b+gHvvtU0/O3ZAXp5dvvJK9+KNUm72EVQBPzHGlIqID/hcRP5hjGnYjX8ZsM8Yc7iIzADuA37hYkxKKbf5/bB3L2RmwuWX16+/5JL2HzOIeb5V+7lWIzBWqfPS5zwaD3F5JjDHWZ4HnCg6apxSkS0mBnr2hBNOaPu+xxwT+nhUq1ztIxARr4jkAruBj40xixoV6QdsAzDG1AJFQEYTx7lCRJaKyFIdWE6pTmLv3vrlbdtss03DZp+6S0TborbWPn/xBVRWHlJ4KniuJgJjjN8Ykw30B8aLyMhGRZr69n/QwPjGmOeMMTnGmJzMzEw3QlVKBePFF217/3PPQUYGLFpkXw8caCeEb+tloLffDs88AzfdZIeT+M1v7Pphw+w8wKpDdMh9BMaYQhGZD5wCrG6wKQ8YAOSJSAzQDdh78BGUUp3CbbfZ5zvvtM9//nP9tptuatuxmpsMqeHcAKpDuHnVUKaIdHeWE4CTgMaXC7wDXOwsTwf+ZXSqLKU6h4cegk2bDlxX14W3a5d9njOHdgkE2h+XCjk3m4b6AJ+KyNfAEmwfwd9F5A8icoZT5gUgQ0Q2AjcAQQwtqJRy3d699hv+SSfZ1+vWwZ499QmgLZ59tn758MPtUNN6TUinIpH2BTwnJ8csXbo03GEo1bXt2WOv/AkFY+x8AtdeC48/Dt27h+a4qk1EZJkxJqepbXpnsVLqQL/9bWiSwEcfwf/8j13u1g1eekmTQCeliUApdaDHH2/7Pq+8cuDrl1+Gn/4Ubr01NDEpV2kiUEpZ+/a1ve1+yBDb5HPeebYJaPZsu/6UU0Ifn3KNJgKlotk779h//vfeC+npwe3z6qv1y5s2HViDuOQSmxAyDrovVHVimgiUilZffAFnnmmX6+4PaM26dXDuuXD++bBihXuxqQ6lE9MoFa1+/OO271M3FeTcuaGNRYWV1giU6uoKC+1YQAsW2Gagr79ue1/A9dfb/VWXpDUCpbqyyZNh4cID140Z0/bj/OpXMHRoaGJSnY4mAqW6ivffh/feg//4D0hKgv79D04CbbFiBWRnhy4+1WlpIlAq0i1fbq/4Oe00+/rpp9t3nCuvhLPOgmnT4I47NAlEEU0ESkUaETvz13PPQXk5jBvXvuP06AG7d9shn4cOtcNBQ/OjgqouSzuLlYpEzz9v5/Ft69DPDU2bZpPKunXw7ruhi01FHK0RKBWp+vZt+z4pKVBQALNm6fAPaj9NBEpFitdea//0jdnZdu6A0aPt64ceCl1cKuJpIlCqM1u7Fu66y975e955bd+/psbOAxwfH/LQVNehiUCpzmTnTtt0s2GDvQdg+HC7/o03gj/Gj34E69fb5ZgY+1CqBfobolRnMmCA/QbfHv3722v/U1JsDSAhIbSxqS5LrxpSKtyMgc8/t8vtTQIVFfDdd/aS0Lg4eOopWLYsdDGqLk1rBEqFyxdfHDjw29VXt+84/fsf3AfQ3mOpqKQ1AqXCpfHon225I/jmm+3z9Om2JqDUIdAagVIdraLC/gNvqwsvhH/+0879O2GC7VB+9FHw+UIfo4oqmgiU6mgvv2wHiAvG88/b4SQA/vrXA7e9/XZo41JRS5uGlHLbxo12KAcR+PZbuOKKlsvPng1r1sDhh8MZZ9h1v/qV+3GqqKU1AqVCbft22Ly5vg+g4Tj+Rx7Z/H6LFsH48fWvN2ywz35/2yeSUaoNtEagVKj4/fDYYzB4MBx/vB0Z9PjjW9/vyittu3/DJNCQx6OJQLlKawRKhUJNDbzwAlx3Xf26ww6zdwq35skn9e5fFVZaI1AqFG666eB2/NaSwMyZUFysSUCFnf4GKtVeu3ZB9+7tG9Bt7lw4//zQx6RUO2iNQKmWBAKwevXB64uLoXfv4JPA88/b2cCWL7d3/c6YEdo4lToEmgiUasn//A+MGgVff12/7ve/r58fOFjx8ZCZCWPH2nGAPPqnpzoPbRpSqiXz59vnMWPatl9Wlp1Q/qqr4MYb4aSTQh2ZUiGjiUCplrRlRrDcXFi1CpKT4ayz6tfX3RmsVCeliUCpxvbsgU8/tUNCf/FF8PslJ9vxgJSKMJoIlPrwQ5g40Q4Gl5lpm3Iaj+vTnHXr7GQwHo+9b0CpCKSJQEW3hQvhlFPqX+fkwNKlwe27ebPtCzjiCFdCU6qj6KULKrrt3n3g62CSwK232stKs7JcCUmpjuZaIhCRASLyqYisFZE1IvLbJspMEZEiEcl1Hne6FY9S+337rW0GAnjggZbL7t4N33xT//ryy+GPf9Sxf1SX4mbTUC1wozFmuYikAMtE5GNjzDeNyn1mjPmZi3GoaLd+vW3LP+MMWLKk+cHdmpKZaR/5+fDBB3DBBe7FqVSYuJYIjDE7gB3OcomIrAX6AY0TgVLuqmvD/9e/4Cc/CX6/hnf/ZmRoElBdVod0FotIFjAWWNTE5mNFZCXwA3CTMWZNE/tfAVwBMHDgQPcCVV2LMfYS0DrBJoFNm2DIEHdiUqoTcr2zWESSgTeB64wxxY02LwcGGWPGAE8A/6+pYxhjnjPG5BhjcjIzM90NWEW+8nL46iv4+c8hNja4fQIB2/xTXKxJQEUdV2sEIuLDJoG5xpi3Gm9vmBiMMe+LyNMi0sMYk+9mXKqL2rgRCgrssA65ua2Xv/Zaewfw4MG28zcjw/0YleqEXEsEIiLAC8BaY8zDzZTpDewyxhgRGY+toRS4FZPq4hpOCdmSqVPh+usPvH9AqSjmZo1gInARsEpE6r6e3QYMBDDGPANMB34lIrVABTDDGGNcjEl1JeXlkJQEZ58Nb78d3D5XXAHPPutuXEpFGIm0/7s5OTlmabB3fqquqT3X8OflQb9+oY9FqQghIsuMMTlNbdM7i1Vk2LQJ9u61d/UG47rr4M9/tstDhmgSUKoFQTUNOXcFzwZKgL9gLwWdZYz5yMXYlKp3+OHBlROBc8+Fu+6Cbt1sP0D37q6GplSkC7aP4JfGmMdE5GQgE7gUmxg0ESj3FBVBdTU89lhw5QOBg5uNdDwgpVoVbCKo++s6FZhtjFnpXBWkVOgZY+f4vfLK4Pd5+GEd/0epdgq2j2CZiHyETQQfOmMHBdwLS0WtN9+EefNaTwKPPFK/fM89tk9AKdUuwdYILgOyge+MMeUiko5tHlIqdH7yEzszWGsef9zeDHbttXZO4RNPdD00pbqyYGsExwLfGmMKReRC4A6gyL2wVFR46ilbAxCBzz4LLgn89Kc2AQB4vZoElAqBYBPBn4FyERkD/BewFXjJtahU11ddDb/+NUyfbl9PmtR82enTbb/Be+/ZxKGUCqlgE0Gtc8fvmcBjxpjHgBT3wlJd0oYN9tv/l19CXFzr5d94A37zG5g7174+9VRI0V87pUIt2D6CEhG5FTtkxPEi4gV87oWluqR337XPxx3XcrlLL7X9AMnJdgRRpZSrgq0R/AKowt5PsBM7wUwrc/wp5aiutpO63Hhj62Vnz4YXX7RJQCnVIYKqERhjdorIXOBoEfkZsNgYo30EqmXGwM6d0LdvcOVuvFFrAEqFQVA1AhE5F1gM/Bw4F1gkItPdDExFqBUr7LhAWVkQE9N8Epg61c4BXF1tX/fubfsCkpI6LFSllBVsH8HtwNHGmN0AIpIJfALMcyswFWGWLIHERDjqqODKf/ihu/EopYIWbCLw1CUBRwE6cql66y17Fc+jj8L77we/X69e7sWklGqzYBPBByLyIfCq8/oXQBv+8sMvP/8d1q+/kuzsBSQm/ijc4USmqiqIj4d774VZs+Ccc4Lb77774LDD7AiisbGg804r1akE21l8s4icg511TIDnjDFBTgnVORjjp7p6J35/ebhDiVylpfb5vvts+38wVq2CkSPdi0kpdciCnqrSGPMmdiL6iOQp85O4BcyIEr0Vrr38fvtcWAg339xy2ZISO5m8JgGlOr0WE4GIlABNzWUpgDHGpLoSlQvi/vU14y+D4i+/g8zjwx1O5KipsXcDr1hhL/EMxqBB9j6A7Gx3Y1NKhUSLicAY02W+O0uSPRVTVhzmSCJIcbGd5as1Tz4JRx9tLwedNcv2AyilIkbQTUORrj4RlIY5kk6uttY2Aa1YAcce23LZ0tIDr/sfP97d2JRSroiaS0AlyWnFKi8JbyCd2cMPg89nrwxqKQncfbdtJtKbv5TqEqKoRmCbOEyp1gia9MEHwY0F1LgWoJSKeFFYI9BEcIBPPoF+/WDatNbLXnWVJgGluqDoqREkp9mFcr2PALD9AGPGwJo1LZdbuBDGjgWPBxISOiY2pVSHippE4NFEYBkDy5dDTk7L5T77zE4Mc9xxdkpIpVSXFTWJwJuSYRei9aohY+wNXj9qZXiNE06Ad96x9wH8+McdE5tSKqyip48gNp6AF0x5WbhDCY/LLms5CVxxBTz7LPzznzopjFJRJmpqBACBeEHKorBpSKTl7d98A8OGdUwsSqlOJ2pqBAD+JA9SEiU1Ar8fvvgChg5tevsNN9j+koICTQJKRbmoqhH4U31IUReuEZSV2RvC/v1v29bfnO3b7ZwAXq9eCaSUirZEEIenuDLcYYTeokX2Ms//+q/Wy5qmxhBUSkWzqGoaCqTG4y2uDncYh+7dd2H1aru8fDlMmNByEvjf/7VNRbW1HRKeUiqyRFUiMN0S8JbUhDuMQ3fGGTBqFNx5J4wb13SZhx6y3/6NgYsvtjeE6f0ASqkmRFXTUKBbMt4Sf7jDaJ+PPoIePQ6cHP6ee5ouW1xs5xJWSqkgRFeNoHsKMWWmfqatSHLyyfbb/x//2HyZn//c1gA0CSil2sC1RCAiA0TkUxFZKyJrROS3TZQREXlcRDaKyNciclRTxwpZTGnpAPjzd7j5NqFjDNxxh70juM4ddxxcrrraln3jjY6LTSnVZbhZI6gFbjTGDAMmANeIyPBGZaYBQ53HFcCfXYwHevezgeWtdfVtQuKee+C112wNoLl7AcDODubzdVxcSqkux7U+AmPMDmCHs1wiImuBfsA3DYqdCbxkjDHAVyLSXUT6OPuGnKf/YABqv19H3LifuvEWh6agADZvhhEjbEdwS2prtfNXKRUSHdJZLCJZwFhgUaNN/YBtDV7nOesOSAQicgW2xsDAgQPbHYd34BEAmLxN7T6Gq3r0aL1Mfr69cUyTgFIqRFzvLBaRZOBN4DpjTOOZ45saBOegO56MMc8ZY3KMMTmZmZntjiVmgG2ZMt9vafcxXPHyy7BtW/PbR4yACy+EvXshIwMOIRkqpVRjrtYIRMSHTQJzjTFvNVEkDxjQ4HV/4Ae34olNHUBlT5BNW916i7b77ju46KKWy9TdPKaUUi5w86ohAV4A1hpjHm6m2DvATOfqoQlAkVv9AwBebyIVA73EbOwEVw3l5cHPfgaHHdZyudaShFJKHSI3awQTgYuAVSKS66y7DRgIYIx5BngfOBXYCJQDl7oYDwDVWamkflBgL7dsbXhmNxgDt9wCDzzQ9PZHHoELLoCSEhg0yN4RrJRSLnLzqqHPaboPoGEZA1zjVgxNqf1Rf7zzVtmrc4YM6cA3roV//cveGNaUn/0MXngBeva0rw+hL0QppdoiqoaYAPAfNwZYhfniC6QjE0FKClQ2M/LppZfCiy92XCxKKdVA1LU7eEYeTU0KBP72fx3zhq+/bpugmkoCs2fbpiJNAkqpMIq6RJCQ/CMKJoDnvQ+hqir0bzBvHlxzjf3nLwIzZhxc5tZbYd8+uOSS0L+/Ukq1UdQ1DSUnj2bD8dD74+rWZ/Jqqy1b7MBvzVm27MDRQ5VSqhOIuhpBbGwfysbawec4/fTQHPTJJ20n8ODBTW+fNw+2btUkoJTqlKKuRiAixPUfC/zTDtVQXAypqW07yObNUFgIo0fbJp5rr22+bEEBpKcfUsxKKeWmqKsRAKSmTmD13c6pH3dcy4WNgfXr7XIgAA8/bC87PeooiIlp+jLPOXNsP8HSpZoElFKdXlQmgu7djyd/UoBAr3RYswYmT26+8BNPwBFHwJIlMGkS3Hhj82U/+MDWFGbOtM1FzU0jqZRSnUhUJoLU1GMBDzueP8euWLgQHn304IKBAPzWmU9n/Hj44oumD/j557bmcPLJ0K2bKzErpZRbojIRxMSkkpo6nh19ltWvvP76+ks+6x4tDfU8Z45NFMbAxInuB62UUi6JykQAkJk5ndLS5VTsXAGxscHvuHq1/ec/c2Z4xipSSqkQi+pEALC78gN7Y1l5efOFhw6FtWvtQHAjRnRQhEop1TGi7vLROvHxg0hJGc+ePf/HoEGzICHBftMH2LXLNgsFM2OYUkpFuKitEQD07HkupaXLKS/feOCGXr00CSilokaUJ4IZgJcdO54NdyhKKRU2UZ0I4uL60bPnz9m+/c9UV+eHOxyllAqLqE4EAIMG3UkgUM62bc3MGKaUUl1c1CeCpKRh9Ox5Ptu3P0FlZSea1F4ppTpI1CcCgCFD/ggI69dfg6m7ckgppaKEJgLspaSDB/83e/e+pyQDlE8AABHISURBVE1ESqmoo4nA0b//b0hIOILvvruF4uKl4Q5HKaU6jCYCh4iX4cNfA2Dlyp9QVbU9zBEppVTH0ETQQEpKNiNH/g2/v4RVq86kpqYw3CEppZTrNBE00qPHGYwa9XfKyr5m5cqTqKkpCHdISinlKk0ETcjIOI2RI9+mrGw1K1YcT3n5+nCHpJRSrtFE0IyMjNMYNervVFR8x+LFR7Br19xwh6SUUq7QRNCC9PSTGDv2cwDWrr2QTZtmhTkipZQKPU0ErUhNzeGYY77D40li27b7WLnyFGpq9oU7LKWUChlNBEFISBjM8ccXM2jQHezb9yFffJHOsmXH6F3ISqkuQRNBkEQ8DB58D0OG3A9AScliFizwUFi4MMyRKaXUodFE0EYDB97MxIl7ATuxfW7uZDZuvImqqh3hDUwppdpJE0E7+HxpTJlSy7HHbqdnz/PIy3uEL7/sy4oVUygrWxfu8JRSqk00ERyCuLi+DB/+Cjk5KwEoKlrAkiXDmD9fyM9/R/sQlFIRQRNBCCQnj2TKFMPRR6/Zv2716jNZsMDDli33UF29O4zRKaVUyyTSvrXm5OSYpUs79+ig1dW72bjxenbvfg0I7F+fnn4aw4e/QkxMaviCU0pFJRFZZozJaXKbJgL3GGMoK/uaLVvuJj//7QZbvPTteyVZWXcRG5sZtviUUtGjpUTgWtOQiLwoIrtFZHUz26eISJGI5DqPO92KJVxEhOTkMYwc+RbHHLOJXr0udrb4+eGHp/n3v3syf76watUZVFbmhTVWpVT0cq1GICKTgFLgJWPMyCa2TwFuMsb8rC3HjaQaQXP8/kpycydRUrLkoG3duh3P6NEf4PUmhiEypVRX1VKNIMatNzXGLBSRLLeOH8m83njGjVsMgN9fxoYN17Jz52wAioo+47PPksjI+BlVVTsYMWIeCQlZYYxWKdXVudpH4CSCv7dQI3gTyAN+wNYO1jQu55S9ArgCYODAgeO2bt3qUsThFQhUs23bAxQXL6ag4J0DtqWk5DBo0B2kp5+Gx+Na/lZKdVFh6yxuJRGkAgFjTKmInAo8ZowZ2toxu0LTUDACgSq2bPkD1dU7KCh4l5qafAC83mR8vp54vYn07n0pmZk/Jz5+QJijVUp1dp0yETRRdguQY4zJb6lctCSCxqqrd1FQ8D4lJUv54YenD9iWkHAEFRXfAjBq1N9JTz8FEW84wlRKdVJh6SNojYj0BnYZY4yIjMdewaTzQjYjNrYXffpcSp8+lzJ06JNUV+9g3bpLKCtbQ8N7FVatqu9779HjHNLSTiQ19ViSk8cgImGIXCnV2bmWCETkVWAK0ENE8oDfAz4AY8wzwHTgVyJSC1QAM0yk3dQQJiJCXFxfxoz5aP+66upd5OU9SnHxYiorN1NZuZn8/DfJz3/zgH3T0k5i375POOywh0hLO4nk5NEdHb5SqpPRG8q6sNraUkpKFrN37z/Yvfs1qqqavlfB600lNrY3IjH07fsr+vT5pV6+qlQXo3cWq/0CgVqKi7+koOAdSkqWUly8mECgvNnyycnZxMb2JjV1Ij16nE5i4jA8ntgOjFgpFQqaCFSrAoFqdux4nqqq7RhTy7ZtDzRbNiYmjdraffTqdRG1tfuIiUknI+N00tN/itebqn0RSnVCmghUuxkToLR0BRUVGwkEKikvX0dJyVL27fsErzcFv7+kyf2Skkbi8/UgJiaD5ORsUlKOIjFxOPHxAxHRQW+V6mid8qohFRlEPKSkjCMlZVyT26uqfmD37tepqNhIdfUO8vPfJiYmg9raYsrK7DBTDTusRXzExfUnLq4fgUANSUnDiYsbSFxcP5KSRiDiIylpOF5vUoecn1JKE4E6RHFxfRkw4Ppmt9fU7KOiYj3l5eupqcmnpmY3lZXfU1GxgZKSJZSULGp23+TkbHy+XlRVbSM+fjDp6afg8fiIiUnD58uke/dJgEebopQ6RJoIlKt8vjR8vmNITT2mye1+fyXV1dspK1tDdfVOdu16maKiz4iLG4BIHGVlX1NdvYPy8m/Yu/e9Jo/h8STQrdvxxMUNID7e7ldSsoiMjNNJSDiMxMQj8XgSiYlJcfNUlYpY2kegOj1jDH5/MVVVNiF8//19lJTYQfvi4wcDEBOTTlVVHjU1u1o4koe6m++Sk48iIeEw4uOHUF7+Dampx5GcPAqRWCBAYuII4uL66B3aqsvQzmIVNQKBKiorv6e8fB0VFevx+XpRXr6OvXvfIzl5LCUlS6iu3klNzT7AH/RxU1KOobR0OcnJY/D7K0hPn0pi4pFUVGwgI+N0qqrySE4+itjYXng8sdrHoTodTQRKNcEYgzHVVFVtx+8vp7p6J2VlqygtXUFMTDqBQBn79n1KZeUmEhNHUF7e5OC4TYqJySAurh+xsX0oKvps/70a/fr9BoC9ez8gPX0aaWknERubSVLSSAKBGny+7q6cq1KaCJQKEWP8GBMgEKiivHwdRUWfEx8/gPz8/4fP1xNj/BQVLSQlZTyVlZuprS3c34wVjNjY3tTU7CU5OZuYmFRqa4upqtpGSsp4jKklLe1EYmK6OfdreIiL64/HE+88J+L1xrt49iqSaSJQqhMwxhAIVOH3l1Bc/CWBQDU1NXvYteuv1NQUUFGxnszM6VRUbMTn64HfX0Zl5Vaqq39o83t5vcnExw8mPn4wPl8PfL4eeL0plJWtwutNolu3ScTF9cOYarzeZBIShiISS0xMKuDROS+6IE0ESkU4YwJUVW3H602ktrYEv7+E8vJvAA9VVd8TCFQCHgoL/+Xc7NcNj8eHMX5EYqipKaDhKLUt8XgSiInphkgcPl8PPJ44amsLKS//huTko+je/QQ8njhiYrrj9SZSWbmF5OSxxMR0p7JyM8nJ2cTFDSQmJhURH+DRmkonoDeUKRXhRDz7JyDy+TIASE4edVC5QYNubXL/QKAaMFRX76GycgtgAKGy8jsqK7/H602mqOgz4uMHYUwt1dU7qKz8Hp8vw0ky9gtjaelyysvXtTg+VWsSE48EPJSXf0NKytGIxBAb24vY2L54PLGIxGGv3DqSQKCC6uo9xMSkkpg4nJiY7sTF9XM65LtpggkRTQRKRYG6gQLj4/sTH9+/wZYf718aMOC6oI8XCFRTW1tIbe0+qqp24PHEEQiUU1qaC3gRiaG2ttB5bQgEyp3+ju8xxo/XmwBAefla/P7Sdp+XSBzGVDn9I4l4vanExw/E5+uFMTWAwZhaEhKG4vWm4PHEO4+62lIs8fGD8HqT8HqT8HiS8HoTEYnF44nF40lAxIuIj9raffh86e2OtTPTRKCUajOPJ5bY2J7ExvYkMfGI/evT0k5s87EaNk8HAhXOJcCb8XpTqK7eRWnpMjyeJMrL1+H3l5KUNIyKik3U1hYSG9ub6updgBAIlBEIVFFTs5fS0uWAAIaKig2HfsIOr7cbPl8GIj48nnjA79RgoKzsa8DQq9dFTplYRHx4vckUFn5K9+5TnLvi06iu3onP15PY2D54PHF4vcl4vSmICDU1Bc4NlTEddhOk9hEopaJC3dVegUClk3Cqqa7eDnjw+8sIBMrw+8ud5QqM8eP3l2BMNdXVe9i580UyM6djjB8I4PeXUV6+lri4gRQXf+nUQCyPJ8Fpjgv+XpXmeL2peDzxiHjo1+9aBg26rV3H0T4CpVTUE/Hg9SY4zVJpACQkZAW9/xFHPNPm9zQmQG1tMbW1BYDg95dhTA2Vld9TU5NPXFxfAoFKamsLnavI8snPfwufL9OpdfVrkGACJCYOa3MMwdBEoJRSLhHx4PN1P+hGwZSUo5rdJyvrDrfDOogODK+UUlFOE4FSSkU5TQRKKRXlNBEopVSU00SglFJRThOBUkpFOU0ESikV5TQRKKVUlIu4ISZEZA+wtZ279wDyQxhOOOm5dE5d5Vy6ynmAnkudQcaYzKY2RFwiOBQisrS5sTYijZ5L59RVzqWrnAfouQRDm4aUUirKaSJQSqkoF22J4LlwBxBCei6dU1c5l65yHqDn0qqo6iNQSil1sGirESillGpEE4FSSkW5qEkEInKKiHwrIhtFZFa44wmGiGwRkVUikisiS5116SLysYhscJ7TnPUiIo875/e1iDQ/84X7cb8oIrtFZHWDdW2OW0QudspvEJGLO9G53CUi253PJVdETm2w7VbnXL4VkZMbrA/775+IDBCRT0VkrYisEZHfOusj6rNp4Twi7nMRkXgRWSwiK51zudtZP1hEFjk/39dFJNZZH+e83uhsz2rtHINijOnyD8ALbAKGALHASmB4uOMKIu4tQI9G6+4HZjnLs4D7nOVTgX9gZ+yeACwKY9yTgKOA1e2NG0gHvnOe05zltE5yLncBNzVRdrjzuxUHDHZ+57yd5fcP6AMc5SynAOudmCPqs2nhPCLuc3F+tsnOsg9Y5Pys3wBmOOufAX7lLF8NPOMszwBeb+kcg40jWmoE44GNxpjvjDHVwGvAmWGOqb3OBOY4y3OAsxqsf8lYXwHdRaRPOAI0xiwE9jZa3da4TwY+NsbsNcbsAz4GTnE/+gM1cy7NORN4zRhTZYzZDGzE/u51it8/Y8wOY8xyZ7kEWAv0I8I+mxbOozmd9nNxfralzkuf8zDAT4B5zvrGn0ndZzUPOFFEhObPMSjRkgj6AdsavM6j5V+czsIAH4nIMhG5wlnXyxizA+wfBNDTWd/Zz7GtcXf28/m101zyYl1TChF0Lk6TwljsN9CI/WwanQdE4OciIl4RyQV2Y5PqJqDQGFPbRFz7Y3a2FwEZHOK5REsikCbWRcJ1sxONMUcB04BrRGRSC2Uj9Rybi7szn8+fgcOAbGAH8JCzPiLORUSSgTeB64wxxS0VbWJdpzmfJs4jIj8XY4zfGJMN9Md+ix/WVDHn2ZVziZZEkAcMaPC6P/BDmGIJmjHmB+d5N/A29pdkV12Tj/O82yne2c+xrXF32vMxxuxy/ngDwPPUV8E7/bmIiA/7z3OuMeYtZ3XEfTZNnUckfy4AxphCYD62j6C7iMQ0Edf+mJ3t3bBNl4d0LtGSCJYAQ52e+FhsJ8s7YY6pRSKSJCIpdcvAVGA1Nu66qzQuBv7mLL8DzHSu9JgAFNVV9zuJtsb9ITBVRNKcKv5UZ13YNep7ORv7uYA9lxnOlR2DgaHAYjrJ75/TlvwCsNYY83CDTRH12TR3HpH4uYhIpoh0d5YTgJOwfR6fAtOdYo0/k7rPajrwL2N7i5s7x+B0ZA95OB/YKyDWY9vfbg93PEHEOwR7FcBKYE1dzNj2wH8CG5zndFN/9cFTzvmtAnLCGPur2Kp5DfabymXtiRv4JbbTayNwaSc6l786sX7t/AH2aVD+dudcvgWmdabfP+DH2OaCr4Fc53FqpH02LZxHxH0uwGhghRPzauBOZ/0Q7D/yjcD/AXHO+njn9UZn+5DWzjGYhw4xoZRSUS5amoaUUko1QxOBUkpFOU0ESikV5TQRKKVUlNNEoJRSUU4TgVIdSESmiMjfwx2HUg1pIlBKqSiniUCpJojIhc448bki8qwzMFipiDwkIstF5J8ikumUzRaRr5zBzt6W+vH8DxeRT5yx5peLyGHO4ZNFZJ6IrBORuc6dskqFjSYCpRoRkWHAL7CD/mUDfuACIAlYbuxAgAuA3zu7vATcYowZjb2ztW79XOApY8wY4DjsHcpgR8u8DjuG/BBgousnpVQLYlovolTUOREYByxxvqwnYAdiCwCvO2VeBt4SkW5Ad2PMAmf9HOD/nHGi+hlj3gYwxlQCOMdbbIzJc17nAlnA5+6fllJN00Sg1MEEmGOMufWAlSK/a1SupfFZWmruqWqw7Ef/DlWYadOQUgf7JzBdRHrC/jl9B2H/XupGhDwf+NwYUwTsE5HjnfUXAQuMHR8/T0TOco4RJyKJHXoWSgVJv4ko1Ygx5hsRuQM7O5wHO/LoNUAZMEJElmFnhvqFs8vFwDPOP/rvgEud9RcBz4rIH5xj/LwDT0OpoOnoo0oFSURKjTHJ4Y5DqVDTpiGllIpyWiNQSqkopzUCpZSKcpoIlFIqymkiUEqpKKeJQCmlopwmAqWUinL/HxVmkwh7JbeoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val accuracy')\n",
    "\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 9us/step\n",
      "cost:3.706244239425659\n",
      "accuracy:0.2597000002861023\n"
     ]
    }
   ],
   "source": [
    "res=model.evaluate(xTest,yTest,batch_size=32) # training을 너무 과하게 함\n",
    "print(\"cost:\"+str(res[0]))\n",
    "print(\"accuracy:\"+str(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(학습) 조기종료(:earlystopping)에 관한 것\n",
    "#콜백함수: 어떤 상황이 되었을 떄(val_lost가 떨어지다 올라가는 시점) \n",
    "#함수 내에서 또 다른 함수를 호출하는 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*함수 설명(keras.io에서 earlystop검색 후)\n",
    "keras.callbacks.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                        min_delta=0, #변화량\n",
    "                                        patience=0,  # 개선이 안되어도 몇 epoch까지 참을지\n",
    "                                        verbose=0, # 출력모드\n",
    "                                        mode='auto', \n",
    "                                        baseline=None, \n",
    "                                        restore_best_weights=False)\n",
    "\"\"\"\n",
    "-min_delta: minimum change in the monitored quantity to qualify as an improvement, \n",
    "    i.e. an absolute change of less than min_delta, will count as no improvement\n",
    "-patience: number of epochs that produced the monitored quantity with no improvement \n",
    "    after which training will be stopped. Validation quantities may not be produced \n",
    "    for every epoch, if the validation frequency (model.fit(validation_freq=5)) is \n",
    "    greater than one.\n",
    "-mode: one of {auto, min, max}. In min mode, training will stop when the quantity \n",
    "    monitored has stopped decreasing; in max mode it will stop when the quantity \n",
    "    monitored has stopped increasing; in auto mode, the direction is automatically \n",
    "    inferred from the name of the monitored quantity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3829 - val_accuracy: 0.2433\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 69us/step - loss: 1.2582 - accuracy: 0.5114 - val_loss: 3.4305 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000,\n",
    "               batch_size=10,\n",
    "               validation_data=(xVal,yVal),\n",
    "              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYU0lEQVR4nO3dfZhV5X3u8e/NMDAiCAijUF4EE2MUkIGihxwVTI1GwCipRPH4Eo0NV2KaKCZGo03UaJs01pp41KA9kqKFiAc1cCKJCQ0GPSoKZPANrcRqGUQZUJAJojD8+sfeURxmYDPM2pvZz/25rrlYe69nrfV7Blj3Xi/7WYoIzMwsXR1KXYCZmZWWg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEds1qxpCpgEdA5v505EXFNkzYXADcCq/Nv3RoR/2dX6+3du3cMGjSozes1MytnS5cuXRcR1c3NyywIgPeAv4qIBkmVwGOSfhURTzZpNzsi/rbQlQ4aNIglS5a0aaFmZuVO0mstzcssCCL3TbWG/MvK/I+/vWZmto/J9BqBpApJtcBa4LcRsbiZZmdIekbSHEkDsqzHzMx2lmkQRERjRNQA/YFjJA1t0uT/AYMi4ihgATCjufVImiJpiaQl9fX1WZZsZpYcFWusIUnXAH+KiH9qYX4F8FZEdN/VekaNGhVNrxFs3bqVuro6tmzZ0mb1pqaqqor+/ftTWVlZ6lLMLAOSlkbEqObmZXnXUDWwNSI2SNoP+Azwj03a9I2INfmXpwErWrOturo6unXrxqBBg5C0V3WnKCJYv349dXV1DB48uNTlmFmRZXnXUF9gRv6Tfgfgvoj4paTvA0siYh7wDUmnAduAt4ALWrOhLVu2OAT2giR69eqFT7uZpSnLu4aeAUY08/73dpj+DvCdttieQ2Dv+Pdnlq4sjwjMzNq37duhsRG2bfvwz5amdze/LdZx3HFw0klt3k0HQRvYsGEDs2bN4uKLL97jZcePH8+sWbPo0aNHQe2vvfZaunbtyre+9a093pZZi7ZvL97OrJQ70j1dx7724K4rrnAQ7Ks2bNjA7bff3mwQNDY2UlFR0eKy8+fPz7I021FE4Tu81HaI+5qOHXM/FRW7nt7V/E6doEuXPV+uLbadxXIdOkBGp3AdBG3gyiuv5I9//CM1NTWcdNJJTJgwgeuuu46+fftSW1vLCy+8wMSJE1m1ahVbtmzhkksuYcqUKcCHQ2Y0NDQwbtw4jjvuOB5//HH69evH3Llz2W+//Vrcbm1tLV/5ylfYvHkzH/vYx5g+fTo9e/bklp/8hGl33EHHjh058ogjuHfmTH6/aBGXTJ0K5K4HLFqwgG5du374iScC3n8fFi9uvzuzQpbbl0hts0Opqir+TinLHWIHj4VZbGUXBC+/fCkNDbU7z4jY4TAvmhnsIj7yx47vd60aymF9bvjoenbYgf5w6lSeq62l9qGHIIJHHn+cpxYv5rnf/IbBAwbAq68y/dprObB7d959912OnjiRM0aOpFePHrkd1MqVsHkzL7/8Mj//h3/gXy67jDOnTuX+W27h3FNP/eh233wTNm2C5cs5/8wz+d/f/jZjR47kez/9Kdd97Wv8+LLL+OENN/Cfc+fSuVMnNmzaBLW1/NM113DbN77BscOH07B5M1UrV+b+0+1o3ToYN65Vv/dd6tChbXYo5fTprqLCOzzbZ5RdELSosRHefbd1y77/DrzX4nhNuZ3z1q2wZk3uU96GDRwzZAiD998f3n4bJG654w4e/N3vAFi1Zg0v/8d/0Gv48A9PV2zfzuB+/ag58kiQ+MuhQ3n1jTegc+cPDwel3OFu585slNjwpz8x9uSTQeKL55/PFy6+GPr25aihQznn7/+eiePGMXHcONh/f44dO5bLbruNcyZN4q8nTKB/v3659e24bgkeeqjtd4i+I8lsn1Z2QXDYYT9ufsb770NDw4c7vOZ2gjtO78nrXr1gv/1gVP5Le5s2sf/BB8OI3N2zjzzyCAuefZYn/vAHunTpwgknnMCWv/gLGDIEKivhE5+AhgY6d+sGhx8OQEWfPrzb0AAf//hH+9GzJ3TtCoccktvJDhz4Yf8qK6FfPx5asIBFixYxb948rh8/nueff54rb7iBCWedxfz58xk9YQILFizgk5/85EfX3aULjB/fml+7mbVjZRcELerUCQ48MJNVdzvgADZt2tTi/I0bN9KzZ0+6dOnCiy++yJNPNh2Je891796dnj178uijj3L88cdzzz33MHbsWLZv386qVav49Kc/zXHHHcesWbNoaGhg/fr1DBs2jGHDhvHEE0/w4osv7hwEZpakdIIgQ7169eLYY49l6NChjBs3jgkTJnxk/imnnMK0adM46qijOPzwwxk9enSbbHfGjBkfXCw+9NBD+dnPfkZjYyPnnnsuGzduJCKYOnUqPXr04Lvf/S4LFy6koqKCI488knFZXAsws3apaIPOtZXmBp1bsWIFRxxxRIkqKh/+PZqVr10NOufbFszMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLnIOgRLp27bpH75uZZcVBYGaWOAdBG7jiiiu4/fbbP3h97bXXctNNN9HQ0MCJJ57IyJEjGTZsGHPnzi14nRHB5ZdfztChQxk2bBizZ88GYM2aNYwZM4aamhqGDh3Ko48+SmNjIxdccMEHbW+++eY276OZla/yG2Li0kuhtplhqPdGTQ38uIXB7IDJkydz6aWXfvBgmvvuu49f//rXVFVV8eCDD3LAAQewbt06Ro8ezWmnnVbQ84EfeOABamtrWb58OevWrePoo49mzJgxzJo1i89+9rNcffXVNDY2snnzZmpra1m9ejXPPfcckHtQjplZocovCEpgxIgRrF27ltdff536+np69uzJwIED2bp1K1dddRWLFi2iQ4cOrF69mjfffJM+ffrsdp2PPfYYZ599NhUVFRx88MGMHTuWp59+mqOPPpovfelLbN26lYkTJ1JTU8Ohhx7KK6+8wte//nUmTJjAySefXIRem1m5KL8g2MUn9yxNmjSJOXPm8MYbbzB58mQAZs6cSX19PUuXLqWyspJBgwaxZcuWgtbX0hhQY8aMYdGiRTz00EOcd955XH755Zx//vksX76chx9+mNtuu4377ruP6dOnt1nfzKy8+RpBG5k8eTL33nsvc+bMYdKkSUBu+OmDDjqIyspKFi5cyGuv7eLhNk2MGTOG2bNn09jYSH19PYsWLeKYY47htdde46CDDuLLX/4yF110EcuWLWPdunVs376dM844g+uvv55ly5Zl1U0zK0Pld0RQIkOGDGHTpk3069ePvn37AnDOOefwuc99jlGjRlFTU7NH4/9//vOf54knnmD48OFI4kc/+hF9+vRhxowZ3HjjjVRWVtK1a1fuvvtuVq9ezYUXXsj27dsB+MEPfpBJH82sPHkYavuAf49m5cvDUJuZWYscBGZmiSubIGhvp7j2Nf79maWrLIKgqqqK9evXe2fWShHB+vXrqaqqKnUpZlYCZXHXUP/+/amrq6O+vr7UpbRbVVVV9O/fv9RlmFkJlEUQVFZWMnjw4FKXYWbWLpXFqSEzM2s9B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIyCwJJVZKekrRc0vOSrmumTWdJsyWtlLRY0qCs6jEzs+ZleUTwHvBXETEcqAFOkTS6SZuLgLcj4uPAzcA/ZliPmZk1I7MgiJyG/MvK/E/TMSBOB2bkp+cAJ6qQB/qamVmbyfQagaQKSbXAWuC3EbG4SZN+wCqAiNgGbAR6NbOeKZKWSFriYSTMzNpWpkEQEY0RUQP0B46RNLRJk+Y+/e80clxE3BkRoyJiVHV1dRalmpklqyh3DUXEBuAR4JQms+qAAQCSOgLdgbeKUZOZmeVkeddQtaQe+en9gM8ALzZpNg/4Yn56EvC78FjSZmZFleXoo32BGZIqyAXOfRHxS0nfB5ZExDzgLuAeSSvJHQlMzrAeMzNrRmZBEBHPACOaef97O0xvAb6QVQ1mZrZ7/maxmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWuMyCQNIASQslrZD0vKRLmmlzgqSNkmrzP9/Lqh4zM2texwzXvQ34ZkQsk9QNWCrptxHxQpN2j0bEqRnWYWZmu5DZEUFErImIZfnpTcAKoF9W2zMzs9YpyjUCSYOAEcDiZmZ/StJySb+SNKQY9ZiZ2YeyPDUEgKSuwP3ApRHxTpPZy4BDIqJB0njgF8BhzaxjCjAFYODAgRlXbGaWlkyPCCRVkguBmRHxQNP5EfFORDTkp+cDlZJ6N9PuzogYFRGjqqursyzZzCw5Wd41JOAuYEVE/HMLbfrk2yHpmHw967OqyczMdpblqaFjgfOAZyXV5t+7ChgIEBHTgEnAVyVtA94FJkdEZFiTmZk1kVkQRMRjgHbT5lbg1qxqMDOz3fM3i83MEucgMDNLXEFBIOkSSQco5y5JyySdnHVxZmaWvUKPCL6U/w7AyUA1cCHww8yqMjOzoik0CP580Xc88LOIWM5uLgSbmVn7UGgQLJX0G3JB8HB+ELnt2ZVlZmbFUujtoxcBNcArEbFZ0oHkTg+ZmVk7V+gRwaeAlyJig6Rzgb8DNmZXlpmZFUuhQfBTYLOk4cC3gdeAuzOryszMiqbQINiWH/rhdOAnEfEToFt2ZZmZWbEUeo1gk6TvkBs76HhJFUBldmWZmVmxFHpEcBbwHrnvE7xB7kljN2ZWlZmZFU1BQZDf+c8Euks6FdgSEb5GYGZWBgodYuJM4CngC8CZwGJJk7IszMzMiqPQawRXA0dHxFoASdXAAmBOVoWZmVlxFHqNoMOfQyBv/R4sa2Zm+7BCjwh+Lelh4Of512cB87MpyczMiqmgIIiIyyWdQe7xkwLujIgHM63MzMyKouBHVUbE/cD9GdZiZmYlsMsgkLQJaO5h8gIiIg7IpCozMyuaXQZBRHgYCTOzMuc7f8zMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNLnIPAzCxxDgIzs8RlFgSSBkhaKGmFpOclXdJMG0m6RdJKSc9IGplVPWZm1ryCn1ncCtuAb0bEMkndgKWSfhsRL+zQZhxwWP7nfwA/zf9pZmZFktkRQUSsiYhl+elNwAqgX5NmpwN3R86TQA9JfbOqyczMdlaUawSSBgEjgMVNZvUDVu3wuo6dwwJJUyQtkbSkvr4+qzLNzJKUeRBI6grcD1waEe80nd3MIrHTGxF3RsSoiBhVXV2dRZlmZsnKNAgkVZILgZkR8UAzTeqAATu87g+8nmVNZmb2UVneNSTgLmBFRPxzC83mAefn7x4aDWyMiDVZ1WRmZjvL8q6hY4HzgGcl1ebfuwoYCBAR04D5wHhgJbAZuDDDeszMrBmZBUFEPEbz1wB2bBPA17KqwczMds/fLDYzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBKXWRBImi5praTnWph/gqSNkmrzP9/LqhYzM2tZxwzX/a/ArcDdu2jzaEScmmENZma2G5kdEUTEIuCtrNZvZmZto9TXCD4labmkX0kaUuJazMySlOWpod1ZBhwSEQ2SxgO/AA5rrqGkKcAUgIEDBxavQjOzBJTsiCAi3omIhvz0fKBSUu8W2t4ZEaMiYlR1dXVR6zQzK3clCwJJfSQpP31Mvpb1parHzCxVmZ0akvRz4ASgt6Q64BqgEiAipgGTgK9K2ga8C0yOiMiqHjMza15mQRARZ+9m/q3kbi81M7MSKvVdQ2ZmVmIOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0tcKR9eX1Tr1s3lpZf+ppVLq10sl3/yZ9G217rlyrlvrV/O/WvL7ZVv3/r2/RsGDLisldtrWTJB0LnzAKqrz2zFkq19embrlmv90zr3/eXKuW/g/rX19lq3XDn3DTp1OriV29u1ZIKgW7eRdOs2stRlmJntc3yNwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4CM7PEOQjMzBLnIDAzS5xa/4260pBUD7zWysV7A+vasJz2wH1Og/uchr3p8yERUd3cjHYXBHtD0pKIGFXqOorJfU6D+5yGrPrsU0NmZolzEJiZJS61ILiz1AWUgPucBvc5DZn0OalrBGZmtrPUjgjMzKyJsgwCSadIeknSSklXNjO/s6TZ+fmLJQ0qfpVtq4A+XybpBUnPSPp3SYeUos62tLs+79BukqSQ1O7vMCmkz5LOzP9dPy9pVrFrbGsF/NseKGmhpD/k/32PL0WdbUXSdElrJT3XwnxJuiX/+3hG0t4/aCUiyuoHqAD+CBwKdAKWA0c2aXMxMC0/PRmYXeq6i9DnTwNd8tNfTaHP+XbdgEXAk8CoUtddhL/nw4A/AD3zrw8qdd1F6POdwFfz00cCr5a67r3s8xhgJPBcC/PHA78i96zL0cDivd1mOR4RHAOsjIhXIuJ94F7g9CZtTgdm5KfnACeq9Q8e3Rfsts8RsTAiNudfPgn0L3KNba2Qv2eA64EfAVuKWVxGCunzl4HbIuJtgIhYW+Qa21ohfQ7ggPx0d+D1ItbX5iJiEfDWLpqcDtwdOU8CPST13ZttlmMQ9ANW7fC6Lv9es20iYhuwEehVlOqyUUifd3QRuU8U7dlu+yxpBDAgIn5ZzMIyVMjf8yeAT0j6/5KelHRK0arLRiF9vhY4V1IdMB/4enFKK5k9/f++W+X4zOLmPtk3vTWqkDbtScH9kXQuMAoYm2lF2dtlnyV1AG4GLihWQUVQyN9zR3Knh04gd9T3qKShEbEh49qyUkifzwb+NSJukvQp4J58n7dnX15JtPn+qxyPCOqAATu87s/Oh4oftJHUkdzh5K4OxfZ1hfQZSZ8BrgZOi4j3ilRbVnbX527AUOARSa+SO5c6r51fMC703/bciNgaEf8JvEQuGNqrQvp8EXAfQEQ8AVSRG5OnXBX0/31PlGMQPA0cJmmwpE7kLgbPa9JmHvDF/PQk4HeRvwrTTu22z/nTJHeQC4H2ft4YdtPniNgYEb0jYlBEDCJ3XeS0iFhSmnLbRCH/tn9B7sYAJPUmd6rolaJW2bYK6fN/AScCSDqCXBDUF7XK4poHnJ+/e2g0sDEi1uzNCsvu1FBEbJP0t8DD5O44mB4Rz0v6PrAkIuYBd5E7fFxJ7khgcukq3nsF9vlGoCvwf/PXxf8rIk4rWdF7qcA+l5UC+/wwcLKkF4BG4PKIWF+6qvdOgX3+JvAvkqaSO0VyQXv+YCfp5+RO7fXOX/e4BqgEiIhp5K6DjAdWApuBC/d6m+3492VmZm2gHE8NmZnZHnAQmJklzkFgZpY4B4GZWeIcBGZmiXMQmBWRpBMklcuQF1YmHARmZolzEJg1Q9K5kp6SVCvpDkkVkhok3SRpWf6ZDtX5tjX5Ad6ekfSgpJ759z8uaYGk5fllPpZffVdJcyS9KGlmOx/51sqAg8CsifwwBWcBx0ZEDblv6J4D7A8si4iRwO/JfeMT4G7giog4Cnh2h/dnkhsSejjwP4E/DwMwAriU3Nj5hwLHZt4ps10ouyEmzNrAicBfAk/nP6zvB6wFtgOz823+DXhAUnegR0T8Pv/+DHLDeHQD+kXEgwARsQUgv76nIqIu/7oWGAQ8ln23zJrnIDDbmYAZEfGdj7wpfbdJu12Nz7Kr0z07jvzaiP8fWon51JDZzv4dmCTpIABJB+af8dyB3Gi1AP8LeCwiNgJvSzo+//55wO8j4h2gTtLE/Do6S+pS1F6YFcifRMyaiIgXJP0d8Jv8A262Al8D/gQMkbSU3FPtzsov8kVgWn5H/wofjgZ5HnBHfqTMrcAXitgNs4J59FGzAklqiIiupa7DrK351JCZWeJ8RGBmljgfEZiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWuP8GgrfrU6US8NMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2585 - accuracy: 0.5114 - val_loss: 3.4252 - val_accuracy: 0.2433\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.2583 - accuracy: 0.5143 - val_loss: 3.4071 - val_accuracy: 0.2433\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 64us/step - loss: 1.2588 - accuracy: 0.5114 - val_loss: 3.3381 - val_accuracy: 0.2400\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2589 - accuracy: 0.5086 - val_loss: 3.3982 - val_accuracy: 0.2433\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 66us/step - loss: 1.2585 - accuracy: 0.5100 - val_loss: 3.4151 - val_accuracy: 0.2367\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2581 - accuracy: 0.5143 - val_loss: 3.4095 - val_accuracy: 0.2433\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2587 - accuracy: 0.5171 - val_loss: 3.3927 - val_accuracy: 0.2367\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2587 - accuracy: 0.5157 - val_loss: 3.4531 - val_accuracy: 0.2467\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2578 - accuracy: 0.5143 - val_loss: 3.4132 - val_accuracy: 0.2433\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2585 - accuracy: 0.5114 - val_loss: 3.4323 - val_accuracy: 0.2367\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2579 - accuracy: 0.5143 - val_loss: 3.4505 - val_accuracy: 0.2433\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2577 - accuracy: 0.5086 - val_loss: 3.4505 - val_accuracy: 0.2467\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.2580 - accuracy: 0.5057 - val_loss: 3.4440 - val_accuracy: 0.2400\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2581 - accuracy: 0.5086 - val_loss: 3.4225 - val_accuracy: 0.2433\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2576 - accuracy: 0.5086 - val_loss: 3.4250 - val_accuracy: 0.2400\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2586 - accuracy: 0.5057 - val_loss: 3.4298 - val_accuracy: 0.2467\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.2576 - accuracy: 0.5129 - val_loss: 3.4208 - val_accuracy: 0.2367\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 68us/step - loss: 1.2587 - accuracy: 0.5100 - val_loss: 3.4510 - val_accuracy: 0.2433\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2578 - accuracy: 0.5057 - val_loss: 3.4008 - val_accuracy: 0.2433\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 67us/step - loss: 1.2580 - accuracy: 0.5014 - val_loss: 3.4282 - val_accuracy: 0.2400\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.2570 - accuracy: 0.5071 - val_loss: 3.4172 - val_accuracy: 0.2433\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2582 - accuracy: 0.5071 - val_loss: 3.3821 - val_accuracy: 0.2433\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 70us/step - loss: 1.2581 - accuracy: 0.5071 - val_loss: 3.3811 - val_accuracy: 0.2367\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.2584 - accuracy: 0.5057 - val_loss: 3.4647 - val_accuracy: 0.2467\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.2574 - accuracy: 0.5057 - val_loss: 3.4375 - val_accuracy: 0.2400\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2571 - accuracy: 0.5086 - val_loss: 3.4656 - val_accuracy: 0.2400\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.2580 - accuracy: 0.5086 - val_loss: 3.4427 - val_accuracy: 0.2467\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2583 - accuracy: 0.5114 - val_loss: 3.4186 - val_accuracy: 0.2400\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.2578 - accuracy: 0.5071 - val_loss: 3.4367 - val_accuracy: 0.2433\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.2568 - accuracy: 0.5100 - val_loss: 3.4315 - val_accuracy: 0.2433\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.2574 - accuracy: 0.5157 - val_loss: 3.4621 - val_accuracy: 0.2433\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 1.2573 - accuracy: 0.5114 - val_loss: 3.4327 - val_accuracy: 0.2467\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.2579 - accuracy: 0.5114 - val_loss: 3.4361 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000,\n",
    "               batch_size=10,\n",
    "               validation_data=(xVal,yVal),\n",
    "              callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val accuracy')\n",
    "\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.loadtxt(\"C:/Users/김경한/jupyter notebook data/dataset/ThoraricSurgery.csv\",\n",
    "          delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset[:,0:17] # <- 0번부터 16번까지\n",
    "y=dataset[:,17] # 1:수술후 생존, 0:사망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n위 model은 layer가 2개인 상태\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add(Dense(30, # <- 출력이 30개\n",
    "                input_dim=17,  # <- node: 17개\n",
    "                activation='relu'))  # <- keras.io에서 dense 검색\n",
    "model.add(Dense(1,activation='sigmoid')) #<-0 or 1이니까 1로 지정(2가지경우라 2라고 착각할 수 있음,\n",
    "#0또는1값을 갖는 node가 1개라는의미)\n",
    "#input_dim을 30지정해줘야하는데 함수가 알아서 맞춰줘서 안해줘도됨\n",
    "\"\"\"\n",
    "위 model은 layer가 2개인 상태\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When feeding symbolic tensors to a model, we expect the tensors to have a static batch size. Got tensor with shape: (None, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-38c6fc2707b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;34m'When feeding symbolic tensors to a model, we expect the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;34m'tensors to have a static batch size. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When feeding symbolic tensors to a model, we expect the tensors to have a static batch size. Got tensor with shape: (None, 8)"
     ]
    }
   ],
   "source": [
    "model.fit(x,y,epochs=30,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 53us/step\n",
      "[0.1484501694111114, 0.8510638475418091]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x,y)) # Output: [cost, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy=np.loadtxt('C:/Users/김경한/jupyter notebook data/실습데이터/실습데이터/data-03-diabetes.csv',\n",
    "          delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=xy[:,0:-1] #<- 전체행에서 열이 맨 마지막에 있는거 앞까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata=xy[:,[-1]] # 맨마지막 열, 당뇨병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape, ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(tf.random_normal([8,1])) #<-y의 갯수와 1의 자리가 같아야함, 그래야 matmul가능\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "x=tf.placeholder(tf.float32,shape=[None,8])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nXdata: \\n*xn:혈당량 등등의 특성\\n*행: 환자 한명의 데이터\\n     x1  x2 ...                      x8    weight              yhat(0~1)\\n    [                                     [  0.1             [\\n                                            ...\\nNone                                                 + bias = \\n\\n                                       ]     0.5  ]                   ]\\n \\n\\n=>데이터를 한번 읽어서 yhat과 실제 y값의 차가 있을 경우\\nbackpropagation을 통해 weight들을 업데이트 해줌 = 한번 다 할 경우 batch_size=1\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Xdata: \n",
    "*xn:혈당량 등등의 특성\n",
    "*행: 환자 한명의 데이터\n",
    "     x1  x2 ...                      x8    weight              yhat(0~1)\n",
    "    [                                     [  0.1             [\n",
    "                                            ...\n",
    "None                                                 + bias = \n",
    "\n",
    "                                       ]     0.5  ]                   ]\n",
    " \n",
    "\n",
    "=>데이터를 한번 읽어서 yhat과 실제 y값의 차가 있을 경우\n",
    "backpropagation을 통해 weight들을 업데이트 해줌 = 한번 다 할 경우 batch_size=1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#설명 후 이어서\n",
    "w=tf.Variable(tf.random_normal([8,1])) #<-y의 갯수와 1의 자리가 같아야함, 그래야 matmul가능\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "x=tf.placeholder(tf.float32,shape=[None,8])\n",
    "y=tf.placeholder(tf.float32,shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.sigmoid(tf.matmul(x,w) + b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hf>0.5,dtype=tf.float32) # <-hf>0.5가 boolen값으로 나와서 cast해줌\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),\n",
    "                                  dtype=tf.float32)) #<-얘도 boolen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0686553\n",
      "200 0.6408585\n",
      "400 0.5791498\n",
      "600 0.5638329\n",
      "800 0.55512637\n",
      "1000 0.54806894\n",
      "1200 0.54187816\n",
      "1400 0.53635705\n",
      "1600 0.53140694\n",
      "1800 0.5269537\n",
      "2000 0.52293557\n",
      "2200 0.5193\n",
      "2400 0.5160014\n",
      "2600 0.51300114\n",
      "2800 0.5102653\n",
      "3000 0.50776476\n",
      "3200 0.5054743\n",
      "3400 0.5033717\n",
      "3600 0.50143766\n",
      "3800 0.49965534\n",
      "4000 0.49800983\n",
      "4200 0.4964881\n",
      "4400 0.49507836\n",
      "4600 0.4937705\n",
      "4800 0.4925553\n",
      "5000 0.49142465\n",
      "5200 0.4903711\n",
      "5400 0.48938853\n",
      "5600 0.48847076\n",
      "5800 0.48761255\n",
      "6000 0.48680934\n",
      "6200 0.48605657\n",
      "6400 0.48535052\n",
      "6600 0.48468766\n",
      "6800 0.48406476\n",
      "7000 0.48347884\n",
      "7200 0.48292732\n",
      "7400 0.4824077\n",
      "7600 0.48191783\n",
      "7800 0.48145565\n",
      "8000 0.48101923\n",
      "8200 0.48060694\n",
      "8400 0.480217\n",
      "8600 0.47984815\n",
      "8800 0.47949898\n",
      "9000 0.47916824\n",
      "9200 0.47885466\n",
      "9400 0.47855735\n",
      "9600 0.4782752\n",
      "9800 0.47800744\n",
      "10000 0.47775295\n",
      "[[0.39503556]\n",
      " [0.92584455]\n",
      " [0.2682017 ]\n",
      " [0.9374617 ]\n",
      " [0.20025137]\n",
      " [0.7908606 ]\n",
      " [0.9392321 ]\n",
      " [0.59571975]\n",
      " [0.22430554]\n",
      " [0.54732454]\n",
      " [0.7088856 ]\n",
      " [0.17492011]\n",
      " [0.3393364 ]\n",
      " [0.21336707]\n",
      " [0.76910806]\n",
      " [0.45135245]\n",
      " [0.758441  ]\n",
      " [0.8126842 ]\n",
      " [0.80933964]\n",
      " [0.59900886]\n",
      " [0.68536997]\n",
      " [0.1002683 ]\n",
      " [0.6693069 ]\n",
      " [0.66132665]\n",
      " [0.3429362 ]\n",
      " [0.93773496]\n",
      " [0.56571156]\n",
      " [0.6648413 ]\n",
      " [0.66368777]\n",
      " [0.4632696 ]\n",
      " [0.949273  ]\n",
      " [0.9070134 ]\n",
      " [0.6022688 ]\n",
      " [0.85742056]\n",
      " [0.39306062]\n",
      " [0.6612996 ]\n",
      " [0.81802535]\n",
      " [0.5955794 ]\n",
      " [0.40861842]\n",
      " [0.37817162]\n",
      " [0.8331213 ]\n",
      " [0.13039446]\n",
      " [0.42645603]\n",
      " [0.06726649]\n",
      " [0.5991931 ]\n",
      " [0.9360641 ]\n",
      " [0.6734334 ]\n",
      " [0.7280164 ]\n",
      " [0.9442955 ]\n",
      " [0.93215805]\n",
      " [0.9363376 ]\n",
      " [0.22319594]\n",
      " [0.35895032]\n",
      " [0.95750946]\n",
      " [0.17854488]\n",
      " [0.5339708 ]\n",
      " [0.16323984]\n",
      " [0.69119203]\n",
      " [0.8713438 ]\n",
      " [0.5150399 ]\n",
      " [0.9617938 ]\n",
      " [0.7396112 ]\n",
      " [0.6685767 ]\n",
      " [0.8447957 ]\n",
      " [0.6207609 ]\n",
      " [0.5836735 ]\n",
      " [0.95958316]\n",
      " [0.69270986]\n",
      " [0.8551103 ]\n",
      " [0.6829277 ]\n",
      " [0.2709582 ]\n",
      " [0.6849569 ]\n",
      " [0.91648567]\n",
      " [0.9176742 ]\n",
      " [0.8957555 ]\n",
      " [0.77161866]\n",
      " [0.38694173]\n",
      " [0.86144114]\n",
      " [0.8808583 ]\n",
      " [0.92069304]\n",
      " [0.8845036 ]\n",
      " [0.83333784]\n",
      " [0.332103  ]\n",
      " [0.822564  ]\n",
      " [0.54474425]\n",
      " [0.85159385]\n",
      " [0.38944697]\n",
      " [0.8869313 ]\n",
      " [0.95215404]\n",
      " [0.7485842 ]\n",
      " [0.78421146]\n",
      " [0.69363403]\n",
      " [0.7326915 ]\n",
      " [0.5407622 ]\n",
      " [0.89047945]\n",
      " [0.9778021 ]\n",
      " [0.8964361 ]\n",
      " [0.5623177 ]\n",
      " [0.2670797 ]\n",
      " [0.6689644 ]\n",
      " [0.6877148 ]\n",
      " [0.95981306]\n",
      " [0.78833735]\n",
      " [0.7653743 ]\n",
      " [0.9203739 ]\n",
      " [0.6680411 ]\n",
      " [0.9195434 ]\n",
      " [0.81030977]\n",
      " [0.4689327 ]\n",
      " [0.30743885]\n",
      " [0.93519807]\n",
      " [0.88279635]\n",
      " [0.42211363]\n",
      " [0.47101212]\n",
      " [0.63595974]\n",
      " [0.85269433]\n",
      " [0.8620143 ]\n",
      " [0.92240494]\n",
      " [0.13368174]\n",
      " [0.71560556]\n",
      " [0.851948  ]\n",
      " [0.64795154]\n",
      " [0.655694  ]\n",
      " [0.74182427]\n",
      " [0.6552961 ]\n",
      " [0.83295244]\n",
      " [0.7989565 ]\n",
      " [0.67969203]\n",
      " [0.46019003]\n",
      " [0.46409875]\n",
      " [0.40403935]\n",
      " [0.7562974 ]\n",
      " [0.94141215]\n",
      " [0.7927984 ]\n",
      " [0.7962774 ]\n",
      " [0.86138767]\n",
      " [0.5117006 ]\n",
      " [0.7692527 ]\n",
      " [0.7800015 ]\n",
      " [0.68780816]\n",
      " [0.8700268 ]\n",
      " [0.65051126]\n",
      " [0.5346254 ]\n",
      " [0.6795118 ]\n",
      " [0.90919507]\n",
      " [0.79333675]\n",
      " [0.44404   ]\n",
      " [0.9223232 ]\n",
      " [0.64273   ]\n",
      " [0.82379305]\n",
      " [0.2867679 ]\n",
      " [0.37106207]\n",
      " [0.08595875]\n",
      " [0.19644812]\n",
      " [0.91038066]\n",
      " [0.88573015]\n",
      " [0.9404249 ]\n",
      " [0.11469695]\n",
      " [0.53013223]\n",
      " [0.7668109 ]\n",
      " [0.5558415 ]\n",
      " [0.8498683 ]\n",
      " [0.48148224]\n",
      " [0.8048776 ]\n",
      " [0.56966823]\n",
      " [0.6867565 ]\n",
      " [0.74874085]\n",
      " [0.86434114]\n",
      " [0.7892134 ]\n",
      " [0.59678984]\n",
      " [0.8881484 ]\n",
      " [0.8754515 ]\n",
      " [0.95032525]\n",
      " [0.24366343]\n",
      " [0.8396455 ]\n",
      " [0.18104586]\n",
      " [0.33933517]\n",
      " [0.4250096 ]\n",
      " [0.9064287 ]\n",
      " [0.65171254]\n",
      " [0.9200025 ]\n",
      " [0.92365205]\n",
      " [0.6239798 ]\n",
      " [0.12168556]\n",
      " [0.18488032]\n",
      " [0.6871455 ]\n",
      " [0.78098077]\n",
      " [0.6442069 ]\n",
      " [0.8537989 ]\n",
      " [0.6398779 ]\n",
      " [0.37752604]\n",
      " [0.17294016]\n",
      " [0.8927481 ]\n",
      " [0.370547  ]\n",
      " [0.88056296]\n",
      " [0.90589887]\n",
      " [0.7535012 ]\n",
      " [0.60298514]\n",
      " [0.60935   ]\n",
      " [0.54802954]\n",
      " [0.7183106 ]\n",
      " [0.94967383]\n",
      " [0.7398176 ]\n",
      " [0.82610625]\n",
      " [0.11195806]\n",
      " [0.30862492]\n",
      " [0.89436245]\n",
      " [0.1851036 ]\n",
      " [0.9292754 ]\n",
      " [0.27411735]\n",
      " [0.22251913]\n",
      " [0.4125453 ]\n",
      " [0.7020294 ]\n",
      " [0.2004334 ]\n",
      " [0.7611054 ]\n",
      " [0.7275634 ]\n",
      " [0.82899046]\n",
      " [0.65727466]\n",
      " [0.13876158]\n",
      " [0.38427135]\n",
      " [0.74146736]\n",
      " [0.53103745]\n",
      " [0.9296146 ]\n",
      " [0.93159616]\n",
      " [0.7067394 ]\n",
      " [0.34080762]\n",
      " [0.04628032]\n",
      " [0.5995023 ]\n",
      " [0.35194588]\n",
      " [0.38150507]\n",
      " [0.95799553]\n",
      " [0.64620966]\n",
      " [0.9514214 ]\n",
      " [0.20526105]\n",
      " [0.11474764]\n",
      " [0.27443817]\n",
      " [0.83142567]\n",
      " [0.90056473]\n",
      " [0.8863193 ]\n",
      " [0.6868284 ]\n",
      " [0.6993188 ]\n",
      " [0.5589081 ]\n",
      " [0.14556402]\n",
      " [0.5736327 ]\n",
      " [0.0922474 ]\n",
      " [0.5464959 ]\n",
      " [0.8508886 ]\n",
      " [0.6876012 ]\n",
      " [0.74066687]\n",
      " [0.95085156]\n",
      " [0.7956038 ]\n",
      " [0.76271373]\n",
      " [0.7470836 ]\n",
      " [0.77732366]\n",
      " [0.8403605 ]\n",
      " [0.35741416]\n",
      " [0.35566235]\n",
      " [0.56281805]\n",
      " [0.82144535]\n",
      " [0.57899576]\n",
      " [0.6923161 ]\n",
      " [0.8125624 ]\n",
      " [0.35305095]\n",
      " [0.4989528 ]\n",
      " [0.69061035]\n",
      " [0.6489568 ]\n",
      " [0.4136647 ]\n",
      " [0.90619206]\n",
      " [0.8036915 ]\n",
      " [0.93984354]\n",
      " [0.5655955 ]\n",
      " [0.79678696]\n",
      " [0.8084215 ]\n",
      " [0.8285495 ]\n",
      " [0.7329601 ]\n",
      " [0.8627239 ]\n",
      " [0.34676   ]\n",
      " [0.5560276 ]\n",
      " [0.6474409 ]\n",
      " [0.37616608]\n",
      " [0.83336896]\n",
      " [0.28333583]\n",
      " [0.59302336]\n",
      " [0.9408982 ]\n",
      " [0.78785324]\n",
      " [0.8485304 ]\n",
      " [0.69561493]\n",
      " [0.49574435]\n",
      " [0.6378248 ]\n",
      " [0.43463615]\n",
      " [0.45135653]\n",
      " [0.6538851 ]\n",
      " [0.6427139 ]\n",
      " [0.6228277 ]\n",
      " [0.69390863]\n",
      " [0.23363802]\n",
      " [0.67522943]\n",
      " [0.91010094]\n",
      " [0.43980375]\n",
      " [0.68019235]\n",
      " [0.7417939 ]\n",
      " [0.46297604]\n",
      " [0.69331414]\n",
      " [0.53928393]\n",
      " [0.71251106]\n",
      " [0.90111554]\n",
      " [0.6628233 ]\n",
      " [0.68628925]\n",
      " [0.84522116]\n",
      " [0.5649008 ]\n",
      " [0.8383739 ]\n",
      " [0.94594693]\n",
      " [0.31826776]\n",
      " [0.7687913 ]\n",
      " [0.2678172 ]\n",
      " [0.7519661 ]\n",
      " [0.7977525 ]\n",
      " [0.6742485 ]\n",
      " [0.41100258]\n",
      " [0.7528366 ]\n",
      " [0.72284055]\n",
      " [0.7438237 ]\n",
      " [0.17720646]\n",
      " [0.785279  ]\n",
      " [0.84835756]\n",
      " [0.6237326 ]\n",
      " [0.93148255]\n",
      " [0.21568322]\n",
      " [0.7443069 ]\n",
      " [0.9494226 ]\n",
      " [0.18061116]\n",
      " [0.5142783 ]\n",
      " [0.70832354]\n",
      " [0.34880918]\n",
      " [0.16634828]\n",
      " [0.8387761 ]\n",
      " [0.92376554]\n",
      " [0.85690904]\n",
      " [0.6357411 ]\n",
      " [0.6753997 ]\n",
      " [0.5588148 ]\n",
      " [0.75807416]\n",
      " [0.84301615]\n",
      " [0.9374272 ]\n",
      " [0.702178  ]\n",
      " [0.75571984]\n",
      " [0.61117166]\n",
      " [0.9285358 ]\n",
      " [0.93950385]\n",
      " [0.72536385]\n",
      " [0.2920653 ]\n",
      " [0.71436185]\n",
      " [0.3118732 ]\n",
      " [0.7697179 ]\n",
      " [0.20139489]\n",
      " [0.24246362]\n",
      " [0.42637867]\n",
      " [0.6715373 ]\n",
      " [0.36455452]\n",
      " [0.52809423]\n",
      " [0.83738506]\n",
      " [0.6917895 ]\n",
      " [0.84681535]\n",
      " [0.94832563]\n",
      " [0.74358416]\n",
      " [0.12615296]\n",
      " [0.51269966]\n",
      " [0.8266251 ]\n",
      " [0.85754263]\n",
      " [0.69414234]\n",
      " [0.27416468]\n",
      " [0.88536376]\n",
      " [0.8973737 ]\n",
      " [0.25037223]\n",
      " [0.6454496 ]\n",
      " [0.8580637 ]\n",
      " [0.8560618 ]\n",
      " [0.8619158 ]\n",
      " [0.9211084 ]\n",
      " [0.8766146 ]\n",
      " [0.9151757 ]\n",
      " [0.67804724]\n",
      " [0.5712857 ]\n",
      " [0.5269599 ]\n",
      " [0.84761834]\n",
      " [0.87248003]\n",
      " [0.2050825 ]\n",
      " [0.7867116 ]\n",
      " [0.87662554]\n",
      " [0.36590916]\n",
      " [0.66968226]\n",
      " [0.8921053 ]\n",
      " [0.5375486 ]\n",
      " [0.93623435]\n",
      " [0.23232019]\n",
      " [0.8424064 ]\n",
      " [0.6293303 ]\n",
      " [0.869913  ]\n",
      " [0.34992957]\n",
      " [0.65600085]\n",
      " [0.7477114 ]\n",
      " [0.8354195 ]\n",
      " [0.13294524]\n",
      " [0.20757791]\n",
      " [0.69966686]\n",
      " [0.8159893 ]\n",
      " [0.42999235]\n",
      " [0.77582884]\n",
      " [0.47860512]\n",
      " [0.3259769 ]\n",
      " [0.86053973]\n",
      " [0.42365104]\n",
      " [0.94656265]\n",
      " [0.8186596 ]\n",
      " [0.6491617 ]\n",
      " [0.9186089 ]\n",
      " [0.6650152 ]\n",
      " [0.77024764]\n",
      " [0.29627237]\n",
      " [0.2575561 ]\n",
      " [0.766641  ]\n",
      " [0.38857692]\n",
      " [0.4687215 ]\n",
      " [0.8833165 ]\n",
      " [0.9154371 ]\n",
      " [0.9075986 ]\n",
      " [0.9471598 ]\n",
      " [0.72228795]\n",
      " [0.89434946]\n",
      " [0.33540756]\n",
      " [0.32972783]\n",
      " [0.51640916]\n",
      " [0.9385259 ]\n",
      " [0.63574326]\n",
      " [0.15250221]\n",
      " [0.9287771 ]\n",
      " [0.7994989 ]\n",
      " [0.64422023]\n",
      " [0.7679807 ]\n",
      " [0.02759653]\n",
      " [0.9218894 ]\n",
      " [0.78906393]\n",
      " [0.771936  ]\n",
      " [0.7503273 ]\n",
      " [0.9662802 ]\n",
      " [0.67729735]\n",
      " [0.7568517 ]\n",
      " [0.79099035]\n",
      " [0.84073913]\n",
      " [0.16383052]\n",
      " [0.66168684]\n",
      " [0.91259825]\n",
      " [0.62379974]\n",
      " [0.78107536]\n",
      " [0.95809984]\n",
      " [0.86436653]\n",
      " [0.8838197 ]\n",
      " [0.631128  ]\n",
      " [0.7793021 ]\n",
      " [0.936398  ]\n",
      " [0.7570527 ]\n",
      " [0.6598755 ]\n",
      " [0.28939688]\n",
      " [0.4468019 ]\n",
      " [0.51494634]\n",
      " [0.5618947 ]\n",
      " [0.55187565]\n",
      " [0.7956065 ]\n",
      " [0.5558183 ]\n",
      " [0.8104181 ]\n",
      " [0.8363725 ]\n",
      " [0.7607127 ]\n",
      " [0.6456139 ]\n",
      " [0.4478666 ]\n",
      " [0.57341075]\n",
      " [0.93504333]\n",
      " [0.8344642 ]\n",
      " [0.24239329]\n",
      " [0.4138436 ]\n",
      " [0.45851445]\n",
      " [0.09383622]\n",
      " [0.8798994 ]\n",
      " [0.16780475]\n",
      " [0.8988352 ]\n",
      " [0.8673556 ]\n",
      " [0.8251318 ]\n",
      " [0.6992129 ]\n",
      " [0.8956234 ]\n",
      " [0.37762007]\n",
      " [0.8077451 ]\n",
      " [0.9373039 ]\n",
      " [0.30048755]\n",
      " [0.46463948]\n",
      " [0.8728248 ]\n",
      " [0.85806036]\n",
      " [0.65398645]\n",
      " [0.8137983 ]\n",
      " [0.7980337 ]\n",
      " [0.8238934 ]\n",
      " [0.24670267]\n",
      " [0.7557451 ]\n",
      " [0.90305424]\n",
      " [0.66826296]\n",
      " [0.79013306]\n",
      " [0.690978  ]\n",
      " [0.8378978 ]\n",
      " [0.89088523]\n",
      " [0.9276365 ]\n",
      " [0.55945855]\n",
      " [0.44407928]\n",
      " [0.787845  ]\n",
      " [0.75361544]\n",
      " [0.97128916]\n",
      " [0.7650988 ]\n",
      " [0.7037496 ]\n",
      " [0.43796867]\n",
      " [0.7234944 ]\n",
      " [0.9214219 ]\n",
      " [0.95314705]\n",
      " [0.8834762 ]\n",
      " [0.7104514 ]\n",
      " [0.72602564]\n",
      " [0.8051983 ]\n",
      " [0.4740711 ]\n",
      " [0.8405465 ]\n",
      " [0.82665694]\n",
      " [0.91151667]\n",
      " [0.62628824]\n",
      " [0.734243  ]\n",
      " [0.92392063]\n",
      " [0.5160643 ]\n",
      " [0.5934209 ]\n",
      " [0.66273874]\n",
      " [0.71976733]\n",
      " [0.6660435 ]\n",
      " [0.8887857 ]\n",
      " [0.92445433]\n",
      " [0.20131403]\n",
      " [0.11765611]\n",
      " [0.72489345]\n",
      " [0.5301906 ]\n",
      " [0.24887744]\n",
      " [0.82636344]\n",
      " [0.91001016]\n",
      " [0.72359025]\n",
      " [0.9362726 ]\n",
      " [0.9061533 ]\n",
      " [0.768992  ]\n",
      " [0.82320976]\n",
      " [0.7207172 ]\n",
      " [0.49498308]\n",
      " [0.7938909 ]\n",
      " [0.60431355]\n",
      " [0.09983021]\n",
      " [0.8999953 ]\n",
      " [0.8825414 ]\n",
      " [0.7581785 ]\n",
      " [0.9197755 ]\n",
      " [0.8494987 ]\n",
      " [0.87473077]\n",
      " [0.57018924]\n",
      " [0.6694314 ]\n",
      " [0.89385647]\n",
      " [0.7723217 ]\n",
      " [0.8630147 ]\n",
      " [0.89006305]\n",
      " [0.61802685]\n",
      " [0.80701303]\n",
      " [0.8405926 ]\n",
      " [0.54132754]\n",
      " [0.56326866]\n",
      " [0.14051348]\n",
      " [0.2400024 ]\n",
      " [0.8288114 ]\n",
      " [0.60554755]\n",
      " [0.66912484]\n",
      " [0.5437405 ]\n",
      " [0.93152857]\n",
      " [0.43063077]\n",
      " [0.8424054 ]\n",
      " [0.28498816]\n",
      " [0.92278576]\n",
      " [0.3248089 ]\n",
      " [0.77973485]\n",
      " [0.58767784]\n",
      " [0.8909789 ]\n",
      " [0.622454  ]\n",
      " [0.218375  ]\n",
      " [0.7701152 ]\n",
      " [0.9326403 ]\n",
      " [0.35509247]\n",
      " [0.9181046 ]\n",
      " [0.8655574 ]\n",
      " [0.87574685]\n",
      " [0.80720276]\n",
      " [0.40782058]\n",
      " [0.32824126]\n",
      " [0.660017  ]\n",
      " [0.19994643]\n",
      " [0.95840704]\n",
      " [0.3145215 ]\n",
      " [0.9169167 ]\n",
      " [0.8673737 ]\n",
      " [0.3834583 ]\n",
      " [0.21080202]\n",
      " [0.7092346 ]\n",
      " [0.41227168]\n",
      " [0.8583046 ]\n",
      " [0.73941255]\n",
      " [0.98033404]\n",
      " [0.58703077]\n",
      " [0.64500546]\n",
      " [0.7804368 ]\n",
      " [0.8457513 ]\n",
      " [0.08778873]\n",
      " [0.7008441 ]\n",
      " [0.81049824]\n",
      " [0.85811436]\n",
      " [0.66893035]\n",
      " [0.48669437]\n",
      " [0.6010695 ]\n",
      " [0.89463544]\n",
      " [0.69143   ]\n",
      " [0.7879548 ]\n",
      " [0.84240156]\n",
      " [0.8449962 ]\n",
      " [0.8287165 ]\n",
      " [0.61105186]\n",
      " [0.806656  ]\n",
      " [0.8997369 ]\n",
      " [0.70546246]\n",
      " [0.9569839 ]\n",
      " [0.80570316]\n",
      " [0.63203835]\n",
      " [0.5060546 ]\n",
      " [0.8604487 ]\n",
      " [0.86734223]\n",
      " [0.41902298]\n",
      " [0.6506258 ]\n",
      " [0.21954516]\n",
      " [0.5827945 ]\n",
      " [0.8011292 ]\n",
      " [0.9484478 ]\n",
      " [0.8191861 ]\n",
      " [0.7355039 ]\n",
      " [0.7865086 ]\n",
      " [0.87518644]\n",
      " [0.41780657]\n",
      " [0.9399589 ]\n",
      " [0.61912376]\n",
      " [0.87488663]\n",
      " [0.3340559 ]\n",
      " [0.09134197]\n",
      " [0.27797306]\n",
      " [0.36940974]\n",
      " [0.6829535 ]\n",
      " [0.8357357 ]\n",
      " [0.51778245]\n",
      " [0.7268207 ]\n",
      " [0.80406165]\n",
      " [0.4826501 ]\n",
      " [0.35456908]\n",
      " [0.88661885]\n",
      " [0.8870946 ]\n",
      " [0.34936282]\n",
      " [0.6913594 ]\n",
      " [0.19283554]\n",
      " [0.43104506]\n",
      " [0.7526736 ]\n",
      " [0.6966247 ]\n",
      " [0.9031682 ]\n",
      " [0.98012733]\n",
      " [0.14909598]\n",
      " [0.7028341 ]\n",
      " [0.6462042 ]\n",
      " [0.4646833 ]\n",
      " [0.71587956]\n",
      " [0.7745991 ]\n",
      " [0.8732375 ]\n",
      " [0.75755394]\n",
      " [0.4526733 ]\n",
      " [0.73310596]\n",
      " [0.15418181]\n",
      " [0.68302906]\n",
      " [0.54114956]\n",
      " [0.9251018 ]\n",
      " [0.5276425 ]\n",
      " [0.5304459 ]\n",
      " [0.82641107]\n",
      " [0.6921832 ]\n",
      " [0.47683704]\n",
      " [0.73548424]\n",
      " [0.654968  ]\n",
      " [0.3143187 ]\n",
      " [0.5907756 ]\n",
      " [0.8757863 ]\n",
      " [0.8208953 ]\n",
      " [0.6029783 ]\n",
      " [0.7373872 ]\n",
      " [0.2908986 ]\n",
      " [0.8438116 ]\n",
      " [0.5299475 ]\n",
      " [0.76059824]\n",
      " [0.37243903]\n",
      " [0.6277989 ]\n",
      " [0.8482741 ]\n",
      " [0.16241574]\n",
      " [0.32442805]\n",
      " [0.80873066]\n",
      " [0.8251631 ]\n",
      " [0.7640871 ]\n",
      " [0.8988223 ]\n",
      " [0.7629226 ]\n",
      " [0.6868603 ]\n",
      " [0.69945836]\n",
      " [0.7855839 ]\n",
      " [0.6691354 ]\n",
      " [0.78369284]\n",
      " [0.47203973]\n",
      " [0.5033935 ]\n",
      " [0.89233434]\n",
      " [0.791188  ]\n",
      " [0.686311  ]\n",
      " [0.26555353]\n",
      " [0.8795178 ]\n",
      " [0.8521049 ]\n",
      " [0.8163404 ]\n",
      " [0.68185556]\n",
      " [0.87986547]\n",
      " [0.8361715 ]\n",
      " [0.7644186 ]\n",
      " [0.41230533]\n",
      " [0.88207453]\n",
      " [0.90163374]\n",
      " [0.37608236]\n",
      " [0.17553777]\n",
      " [0.74721843]\n",
      " [0.3450796 ]\n",
      " [0.810062  ]\n",
      " [0.2746966 ]\n",
      " [0.47534359]\n",
      " [0.5087665 ]\n",
      " [0.76211745]\n",
      " [0.8616333 ]\n",
      " [0.12127075]\n",
      " [0.35878193]\n",
      " [0.6451475 ]\n",
      " [0.51128066]\n",
      " [0.51228285]\n",
      " [0.7868624 ]\n",
      " [0.15309021]\n",
      " [0.92646253]\n",
      " [0.14472647]\n",
      " [0.87608814]\n",
      " [0.7343048 ]\n",
      " [0.689041  ]\n",
      " [0.8275478 ]\n",
      " [0.7276245 ]\n",
      " [0.89279145]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.77470356\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv,_= sess.run([cost,train],\n",
    "                        feed_dict={x:xdata,y:ydata})\n",
    "        if step%200==0:\n",
    "            print(step,cv)\n",
    "    hv,pv,av= sess.run([hf,predicted,accuracy],feed_dict={x:xdata, y:ydata})\n",
    "    print(hv,pv,av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
